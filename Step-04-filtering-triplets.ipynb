{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0aee4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyB4yd8dxsYDCAKfr83HJnpteeoA5WF-HGU\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "#AIzaSyCVA0yvSlhp2XrqBT4GAJDaLkwTFEcXiOg\n",
    "#AIzaSyBCA0bwdFWNuhiAX6wJHDS1c0Ge9WGqDJ8\n",
    "#AIzaSyApyUbOHOFWvDwU_sUDAwtX-hGPsn5vmgk\n",
    "#AIzaSyB7tLgy-ehjYCuIIUkEo8VnI1uA7s7hHYU\n",
    "#AIzaSyBPysJJdt0qBKSZISKeLmvStdiMEpSvYSo\n",
    "#AIzaSyBcgfsyxg0ZKxloGC4gCgnA5VL2v7s4DnU\n",
    "#AIzaSyC5MC6nujEpk4Miq4o_SsoNY_tiIxrrcqU\n",
    "#AIzaSyAFMjhAdqXKCnp3_OhO3E_kNF-iVOD_BRg\n",
    "#AIzaSyB8whGPLgQXaHXklvvr78lJHm78jqdbzko\n",
    "\n",
    "\n",
    "#AIzaSyCVYSUmoalRUdUU82_8siKrM8P1pT8bEuY\n",
    "#AIzaSyA-nNCWA-qTcRqRTGl__fU-oO4hya7uqjU\n",
    "#AIzaSyBxXX4llZykoVOlPxfXwKp2lZ92atvaqSs\n",
    "#AIzaSyAJdBZbqB5GC5G-WYD6GkUiDpiTlyy8yMQ\n",
    "#AIzaSyC4968ONCIRwP4Gio9G9TUzcw6yl-1ESVg\n",
    "#AIzaSyAZiJtURGKgdTFoekPqys5gJJigRhWuySs\n",
    "#AIzaSyCSdSqiR4Gyh5X8Wmo37zFchIyk9f5cCw4\n",
    "#AIzaSyApYe4a_A751QsCDjb_dF_gUpOCn0Rr3r8\n",
    "\n",
    "\n",
    "\n",
    "#AIzaSyBS7DEcpYj4SaNIMpeFxEyKIJYNue0qvrs\n",
    "#AIzaSyDQ-4U6esd78wD9XjFhQgxgttI8nQdoSK4\n",
    "#AIzaSyBX0cbxSEfPCAQU0cW3RH9u5jco30x3tRU\n",
    "#AIzaSyCy_BTh3kM67SNavKG0tGeOJOZH03PnZQs\n",
    "#AIzaSyA4Nip_MQ9Rpgs4edGENLwIkcPE5GkGUNs\n",
    "#AIzaSyAsl4Z1QauRVoHidO7U81GtGbtAkFSz3gI\n",
    "#AIzaSyCX2QH9K3brwVftIfcEj9xy3EssCFfh9E8\n",
    "#AIzaSyCzuv59MFH61wbsFkb_zKtRI8M-eg-47fE\n",
    "#AIzaSyBR2YztjJp3GCAgMj-TlZ7B1EabmQNFMFg\n",
    "#AIzaSyDXAdRAbR5WTWujJ_dB8__SCpPdoKmxsDg\n",
    "#AIzaSyB4yd8dxsYDCAKfr83HJnpteeoA5WF-HGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db94502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry logic settings\n",
    "max_retries = 5\n",
    "initial_backoff = 10\n",
    "def call_gemini_with_backoff(prompt):\n",
    "    \"\"\"Call Gemini API with exponential backoff on rate limits.\"\"\"\n",
    "    backoff = initial_backoff\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip()\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):  # Rate limit hit\n",
    "                print(f\"Rate limit hit. Backing off for {backoff}s (attempt {attempt+1}/{max_retries})...\")\n",
    "                time.sleep(backoff)\n",
    "                backoff *= 2  # exponential backoff\n",
    "            else:\n",
    "                print(f\"Gemini API error: {e}\")\n",
    "                return None\n",
    "    return None  # If all retries fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6978e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompt template\n",
    "with open(\"prompts/prompt_filtering.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_template = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c234a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385\n"
     ]
    }
   ],
   "source": [
    "# Load triplets\n",
    "input_file = \"output/step-03-fusion-unique.jsonl\"\n",
    "output_file = \"output/step-04-filtered.jsonl\"\n",
    "triplets = [json.loads(line) for line in open(input_file, \"r\", encoding=\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_triplets = []\n",
    "\n",
    "# Filtering loop\n",
    "for triplet in tqdm(triplets):\n",
    "    # Insert triplet into prompt safely\n",
    "    prompt = prompt_template.replace(\"{triplet}\", json.dumps(triplet, ensure_ascii=False))\n",
    "\n",
    "    # Call Gemini with retries\n",
    "    decision = call_gemini_with_backoff(prompt)\n",
    "\n",
    "    if decision == \"KEEP\":\n",
    "        filtered_triplets.append(triplet)\n",
    "\n",
    "# Save results\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for t in filtered_triplets:\n",
    "        f.write(json.dumps(t, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Filtering complete. Kept {len(filtered_triplets)} out of {len(triplets)} triplets.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
