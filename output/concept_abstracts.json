{
    "nan": {
        "abstracts": [],
        "label": 0
    },
    "end end": {
        "abstracts": [
            "pseudocode which is language independent and provides for easy porting to most\n",
            "O(1) constant: the operation doesn’t depend on the size of its input, e.g. adding\n",
            "of a managed environment. In C++ you should interpret the reference as a\n",
            "4. All primitive language constructs are explicitly begun and ended\n",
            "Because everything we describe is language independent you will need to\n",
            "quickly look at Appendix E which contains a table listing the various symbols\n",
            "Appendix D which describes testing in more depth.\n",
            "2. we simply need to append our node onto the end of the list updating the\n",
            "12) end Add\n",
            "Pre: head is the head node in the list\n",
            "13) end Contains\n",
            "3. we are removing the head node; or\n",
            "Pre: head is the head node in the list\n",
            "35) end Remove\n",
            "Pre: head is the head node in the list\n",
            "16) end ReverseTraversal\n",
            "13) end Add\n",
            "Pre: head is the head node in the list\n",
            "32) end Remove\n",
            "9) end ReverseTraversal\n",
            "We recommend the use of a doubly linked list when you require forwards\n",
            "9) end Insert\n",
            "17) end InsertNode\n",
            "14) end Contains\n",
            "named FindParent, and FindNode which are described in §3.4 and §3.5 re-\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "45) end Remove\n",
            "25) end FindParent\n",
            "15) end FindNode\n",
            "we are returning a reference to a node not true or false. Given FindNode,\n",
            "9) end FindMin\n",
            "9) end FindMax\n",
            "tree; the choice of strategy depends on which node visitation order you require.\n",
            "9) end Preorder\n",
            "9) end Inorder\n",
            "19) end BreadthFirst\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "1. (index −1)/2 (parent index)\n",
            "8) end Add\n",
            "10) end MinHeapify\n",
            "27) end Remove\n",
            "15) end Contains\n",
            "end ←nodes + start\n",
            "26) end Contains\n",
            "Figure 4.8: Living and dead space in the heap backing array\n",
            "Often deﬁning a set by manually stating its members is tiresome, and more\n",
            "11) end Union\n",
            "15) end Intersection\n",
            "The above depends on how good the hashing algorithm of the hash table\n",
            "is, but most hash tables employ incredibly eﬃcient general purpose hashing\n",
            "next node of the old head node. The run time complexity for searching a queue\n",
            "Double Ended Queue\n",
            "queue. A double ended queue is commonly known as a deque which is the name\n",
            "normal queues, e.g. EnqueueBack may simply be called Enqueue an so on. Some\n",
            "9) end LeftRotation\n",
            "23) end CheckBalance\n",
            "violated then we need not rebalance the tree, the opposite is true if the\n",
            "9) end Insert\n",
            "19) end InsertNode\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "61) end Remove\n",
            "19) end Mergesort\n",
            "16) end Insertionsort\n",
            "20) end ShellSort\n",
            "16) end Radix\n",
            "8) end GreatestCommonDenominator\n",
            "12) end SequentialSearch\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "few markers to deﬁne where words start and end we can easily reverse them.\n",
            "33) end ReverseWords\n",
            "rithm uses two pointers at opposite ends of string we are checking is a palindrome\n",
            "Of the previously listed index keeps track of the current index we are at in\n",
            "white space we are in a word, the opposite is true if at the present index we are\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "10) end RepeatedWordCount\n",
            "18) end Any\n",
            "simple Google search on string nuances between languages and encodings will\n",
            "you are unfamiliar with just browse to Appendix E which descirbes each key-\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "Appendix D\n",
            "APPENDIX D. TESTING\n",
            "APPENDIX D. TESTING\n",
            "APPENDIX D. TESTING\n",
            "We can also use things like inheritance etc when deﬁning classes of tests.\n",
            "Appendix E\n"
        ],
        "label": 0
    },
    "using tdd": {
        "abstracts": [
            "using mathematical proofs.\n",
            "rithms presented in this book can be confusing to follow even for experienced\n",
            "store. Using a data structure like an array would require you to specify the size\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "Another key property of sets implemented using the approach we describe is\n",
            "Shell sort is fairly straight forward but may seem somewhat confusing at\n",
            "using the base 10 system the maximum number we can have\n",
            "factorial of a number using the form N! where N is the number we wish to\n",
            "works on the principal that words are all delimited by white space, and using a\n",
            "listed points can be managed by using three variables:\n",
            "considered using a double loop and check, discarding punctuation, the equality\n",
            "Learning how to design good algorithms can be assisted greatly by using a\n",
            "recursive algorithms using the technique outlined.\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "restructuring when appropriate you will ﬁnd that using TDD you can implement\n",
            "code that your units tests cover. Using TDD it is likely that your code coverage\n"
        ],
        "label": 0
    },
    "set member ordered": {
        "abstracts": [
            "Unordered\n",
            "ordered set.\n",
            "Ordered\n",
            "members to produce a set whose members are ordered appropriately.\n",
            "Sets provide a way of having a collection of unique objects, either ordered or\n",
            "unordered.\n",
            "When implementing a set (either ordered or unordered) it is key to select\n",
            "return MergeOrdered(left, right)\n"
        ],
        "label": 0
    },
    "chapter 11 string": {
        "abstracts": [
            "Chapter 1\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Sorting\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "CHAPTER 10. SEARCHING\n",
            "CHAPTER 10. SEARCHING\n",
            "Chapter 11\n",
            "Strings\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "CHAPTER 11. STRINGS\n"
        ],
        "label": 0
    },
    "end index list count": {
        "abstracts": [
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "variable that tracks how many items are contained in the list so that accessing\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "count ←0\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "while unsorted < list.Count\n",
            "while current < list.Count\n",
            "end if\n",
            "list\n",
            "end if\n",
            "end if\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index < list.Count and list[index] = item\n",
            "end if\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index ≥list.Count or list[index] ̸= item\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "index\n",
            "index\n",
            "index\n",
            "end if\n",
            "end if\n"
        ],
        "label": 0
    },
    "list sorted": {
        "abstracts": [
            "essentially spin up everything that is required when the application is started.\n",
            "tail of the list; or\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "Traversing a singly linked list is the same as that of traversing a doubly linked\n",
            "1. node = ∅, we have exhausted all nodes in the linked list; or\n",
            "variable that tracks how many items are contained in the list so that accessing\n",
            "the value we just inserted.\n",
            "merging the sorted lists back together.\n",
            "- in which case the list is implicitly sorted.\n",
            "while unsorted < list.Count\n",
            "hold ←list[unsorted]\n",
            "i ←unsorted −1\n",
            "items within a list to sort we do so by isolating a speciﬁc key, e.g. in the example\n",
            "lists, some are very eﬃcient (e.g. quick sort deﬁned in §8.3), some are not (e.g.\n",
            "list\n",
            "return anything. The third item from the list is our recursive case.\n"
        ],
        "label": 0
    },
    "end end end end": {
        "abstracts": [
            "few markers to deﬁne where words start and end we can easily reverse them.\n"
        ],
        "label": 0
    },
    "set enforces predeﬁned comparison": {
        "abstracts": [
            "distinct, but an ordered set enforces some predeﬁned comparison on each of its\n"
        ],
        "label": 0
    },
    "recursive algorithm": {
        "abstracts": [
            "themselves based on the concepts by which the respective algorithms are based\n",
            "choose an eﬃcient algorithm. For the sanity of our graph we have omitted cubic\n",
            "algorithms.\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "with just reading the section of a chapter that describes the algorithm you are\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "up front; exceeding that size involves invoking a resizing algorithm which has\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "that upon each insertion and deletion we invoke algorithms that have logarithmic\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "incur the expense of invoking a resizing algorithm which would most likely be\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "Algorithms\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "implementing recursive algorithms see Appendix C.\n",
            "Although not a frequent algorithm that will be applied in real-life scenarios\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "variables whose values change during the algorithm. We recommend that you\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "much simple to follow when you draw out the recursive calls rather than using\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "recursive calls out so you can visualise the call/return chain.\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n"
        ],
        "label": 0
    },
    "numberbase algorithm maxvalue": {
        "abstracts": [
            "algorithms.\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "value\n",
            "value\n"
        ],
        "label": 0
    },
    "queue enqueue root left": {
        "abstracts": [
            "q.Enqueue(root.Left)\n",
            "Queues\n",
            "queue;\n",
            "• EnqueueFront\n",
            "Left\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "final message summary summary": {
        "abstracts": [
            "Final messages\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n"
        ],
        "label": 0
    },
    "10 11 11 11": {
        "abstracts": [],
        "label": 0
    },
    "pivot list": {
        "abstracts": [
            "of the OO concepts listed above. As a ﬁnal note it is also desirable that the\n",
            "The previous list represents what we believe in the vast majority of cases to\n",
            "adds a node to the list, you can assume that you are adding the node to the tail\n",
            "Pre: value is the value to add to the list\n",
            "quence of integers to the list: 1, 45, 60, and 12, the resulting list is that of\n",
            "algorithm listed in this section is very similar to that used for traversal in §2.1.4.\n",
            "not the ﬁrst node to be inserted into the list.\n",
            "Pre: value is the value to add to the list\n",
            "list.\n",
            "Post: list has been sorted into values of ascending order\n",
            "merging the sorted lists back together.\n",
            "Post: list has been sorted into values of ascending order\n",
            "right ←list(list.Count −m)\n",
            "Choosing an appropriate pivot, as for example the median element is funda-\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Figure 8.3: Quick Sort Example (pivot median strategy)\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted\n",
            "list\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "it would be somewhat of an injustice to not list, and describe the mantra that\n"
        ],
        "label": 0
    },
    "height current left": {
        "abstracts": [
            "Left\n",
            "current.Height = Max(Height(current.Left),Height(current.Right)) + 1\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "if Height(current.Left.Left) - Height(current.Left.Right) > 0\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "solution need represent type": {
        "abstracts": [
            "A binary search tree is a good solution when you need to represent types that are\n",
            "Solutions\n"
        ],
        "label": 0
    },
    "end end end inword": {
        "abstracts": [
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "Inorder\n",
            "end if\n",
            "9) end Inorder\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "3. inWord\n",
            "end if\n",
            "end if\n",
            "if inWord\n",
            "end if\n",
            "Word\n",
            "end if\n",
            "word\n",
            "word\n",
            "end if\n",
            "word.\n"
        ],
        "label": 0
    },
    "understand algorithm": {
        "abstracts": [
            "data structures and algorithms.\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "O(n log n) just n log n: usually associated with an algorithm that breaks the problem\n",
            "algorithms.\n",
            "quadratic algorithm.\n",
            "n) end AlgorithmName\n",
            "n) end AlgorithmName\n",
            "The example above describes an algorithm by the name of AlgorithmName,\n",
            "For all readers we recommend that before looking at any algorithm you\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "all the test cases have been progressively satisﬁed we consider that algorithm\n",
            "will hinder your ability to design an algorithm greatly. When you are bom-\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "1. Understand how the algorithm works ﬁrst in an abstract sense; and\n",
            "2. Always work through the algorithms on paper to understand how they\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "count during the insertion and deletion algorithms.\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "The base case in both FindMin, and FindMax algorithms is when the Left\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "The right and left rotation algorithms are symmetric.\n",
            "Algorithms\n",
            "Merge sort is an algorithm that has a fairly eﬃcient space time complexity -\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "With the help of an unordered set, and an algorithm that can split the words\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "Understanding algorithms can be hard at times, particularly from an implemen-\n",
            "tation perspective. In order to understand an algorithm try and work through\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "Using recursion should always be reserved for fast algorithms, you should\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "implementation of algorithms. At any one stage you only have a single goal, to\n",
            "and\n"
        ],
        "label": 0
    },
    "complexity deque deque": {
        "abstracts": [
            "constant run time complexity. Ordered sets cost a little more for this check,\n",
            "With respect to algorithmic run time complexities a deque is the same as\n"
        ],
        "label": 0
    },
    "enqueue root left enqueue": {
        "abstracts": [
            "q.Enqueue(root.Left)\n",
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "• EnqueueBack\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "custom type check": {
        "abstracts": [
            "Pre: value has passed custom type checks for type T\n",
            "Pre: value has passed custom type checks for type T\n"
        ],
        "label": 0
    },
    "postorder root left": {
        "abstracts": [
            "Preorder(root.Left)\n",
            "Postorder\n",
            "1) algorithm Postorder(root)\n",
            "Postorder(root.Left)\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "message summary summary summary": {
        "abstracts": [
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n"
        ],
        "label": 0
    },
    "left height current": {
        "abstracts": [
            "traversal where the value of the current node is yielded in between traversing\n",
            "of eight.\n",
            "Left\n",
            "current.Height = Max(Height(current.Left),Height(current.Right)) + 1\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "if Height(current.Left.Left) - Height(current.Left.Right) > 0\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "if Height(current.Right.Left) - Height(current.Right.Right) < 0\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "set ordered": {
        "abstracts": [
            "Traversing the list in reverse order\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "Post: the items in the list have been traversed in reverse order\n",
            "As you may of guessed the cases that we use for deletion in a doubly linked\n",
            "Post: the list has been traversed in reverse order\n",
            "Postorder\n",
            "9) end Postorder\n",
            "Traversing a tree in breadth ﬁrst order yields the values of all nodes of a par-\n",
            "sizeable array, etc) to store the values of the nodes visited in breadth ﬁrst order\n",
            "Post: the nodes in the BST have been visited in breadth ﬁrst order\n",
            "to the selected ordering strategy. These strategies are referred to as min-heap,\n",
            "Unordered\n",
            "Most libraries provide implementations of unordered sets and so DSA does\n",
            "not; we simply mention it here to disambiguate between an unordered set and\n",
            "We will only look at insertion for an unordered set and cover brieﬂy why a\n",
            "An unordered set can be eﬃciently implemented using a hash table as its backing\n",
            "Ordered\n",
            "An ordered set is similar to an unordered set in the sense that its members are\n",
            "distinct, but an ordered set enforces some predeﬁned comparison on each of its\n",
            "members to produce a set whose members are ordered appropriately.\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "The ordered set has its order realised by performing an inorder traversal\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "Sets provide a way of having a collection of unique objects, either ordered or\n",
            "When implementing a set (either ordered or unordered) it is key to select\n",
            "this check to be as quick as possible. For unordered sets we can rely on the use\n",
            "constant run time complexity. Ordered sets cost a little more for this check,\n",
            "tion, for a hash table this run time complexity should be near constant. Ordered\n",
            "less clear in their implementation. For example in §11.4 we use an unordered\n",
            "Unlike a standard queue where items are ordered in terms of who arrived ﬁrst,\n",
            "priority queue being ordered by priority it remains the same as a normal queue:\n",
            "Note: the function MergeOrdered simply takes two ordered lists and makes\n",
            "return MergeOrdered(left, right)\n",
            "the intent of building up an ordered set of cards in your hand.\n",
            "string, rather it reverses the order of words within a string. This algorithm\n",
            "With the help of an unordered set, and an algorithm that can split the words\n",
            "as well as the order in which methods return to their callers. In Figure A.3 the\n",
            "bar when it comes to quality. Of course in order to attain such a standard you\n"
        ],
        "label": 0
    },
    "chapter introduction chapter": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "lot simpler": {
        "abstracts": [
            "traversal simple and eﬃcient, as shown in §2.2.3.\n",
            "make reverse traversal as simple as forward traversal (deﬁned in §2.1.4) except\n",
            "bi-directional traversal much simpler and quicker than that of a singly linked\n",
            "Searching a BST is even simpler than insertion. The pseudocode is self-explanatory\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "Traditionally breadth ﬁrst traversal is implemented using a list (vector, re-\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "result of simply adding values in a top-to-bottom, left-to-right fashion. Figure\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "Set union can be implemented as a simple traversal of both sets adding each\n",
            "Set intersection is also trivial to implement. The only major thing worth\n",
            "a scenario you can safely assume that the Add method will simply enqueue an\n",
            "they can make many problems a lot simpler.\n",
            "One of the most simple forms of sorting is that of comparing each item with\n",
            "of sorting is not particularly eﬀecient O(n2). In it’s most simple form bubble\n",
            "O(n log n) and is fairly trivial to implement. The algorithm is based on splitting\n",
            "Impera\n",
            "0..9 each of which has their own bucket. Before we show you this ﬁrst simple\n",
            "solution is presented because it too is trivial to implement and doesn’t suﬀer\n",
            "are simply here because they were fun to design. Perhaps the message that\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "We have found this approach both simple, and powerful. By combining a\n",
            "domain and keeping track of changing data makes problems a lot easier to solve.\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "cause your algorithm to run a lot slower than expected, or worse, you will run\n"
        ],
        "label": 0
    },
    "uniques set figure 11": {
        "abstracts": [
            "uniques ←Set\n"
        ],
        "label": 0
    },
    "one ten hundred clariﬁcation": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "tions.\n"
        ],
        "label": 0
    },
    "code coverage": {
        "abstracts": [
            "Code Coverage\n",
            "Something that you can get as a product of unit testing are code coverage\n",
            "statistics. Code coverage is merely an indicator as to the portions of production\n",
            "code that your units tests cover. Using TDD it is likely that your code coverage\n"
        ],
        "label": 0
    },
    "rotation rotation algorithm": {
        "abstracts": [
            "algorithms.\n",
            "quadratic algorithm.\n",
            "count during the insertion and deletion algorithms.\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "set to assist in the construction of an algorithm that determines the number of\n",
            "Rotation\n",
            "Rotation\n",
            "The right and left rotation algorithms are symmetric.\n",
            "Algorithms\n",
            "Iterative algorithms\n"
        ],
        "label": 0
    },
    "bst root": {
        "abstracts": [
            "that root is a reference to the root node of the tree.\n",
            "1. the root = ∅in which case value is not in the BST; or\n",
            "root is the root node of the BST and is ! = ∅\n",
            "root is the root node of the BST\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "1) algorithm BreadthFirst(root)\n",
            "that is ≤than its children. For example, the node at the root of the tree will\n",
            "the shape of a tree while preserving standard BST properties. There are left and\n",
            "BST properties are preserved\n",
            "BST properties are preserved\n",
            "Stackpath ←root\n",
            "CheckBalance(path.Pop()) // we trackback to the root node check balance\n"
        ],
        "label": 0
    },
    "test unit": {
        "abstracts": [
            "collection passed in must contain at least n items. The post-condition mainly\n",
            "then transcribe these tests into unit tests satisfying them one by one. When\n",
            "software is on those within the company who hold test centric roles.\n",
            "What constitutes a unit test?\n",
            "have a test suite consisting of thousands of tests you want those tests to execute\n",
            "the suite of tests not being ran that often by the developers on your team. This\n",
            "Building up a test suite can help greatly in a team scenario, particularly\n",
            "How seriously should I view my test suite?\n",
            "Now that you have a sense of the importance of your test suite you will inevitably\n"
        ],
        "label": 0
    },
    "index list count list": {
        "abstracts": [
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "list\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index < list.Count and list[index] = item\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index ≥list.Count or list[index] ̸= item\n",
            "index\n",
            "index\n",
            "index\n"
        ],
        "label": 0
    },
    "sorted value ascending order": {
        "abstracts": [
            "might be “The list has been sorted in ascending order”\n",
            "Inorder\n",
            "Ordered\n",
            "order):\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "value\n",
            "value\n"
        ],
        "label": 0
    },
    "list pivot": {
        "abstracts": [
            "Figure 2.2: A singly linked list populated with integers\n",
            "of the list not the head.\n",
            "2. we simply need to append our node onto the end of the list updating the\n",
            "quence of integers to the list: 1, 45, 60, and 12, the resulting list is that of\n",
            "Searching a linked list is straightforward: we simply traverse the list checking\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "Traversing a singly linked list is the same as that of traversing a doubly linked\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "Pre: tail is the tail node of the list to traverse\n",
            "variable that tracks how many items are contained in the list so that accessing\n",
            "Traditionally breadth ﬁrst traversal is implemented using a list (vector, re-\n",
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "ability to construct a priority queue where the items with the highest priority\n",
            "of EnqueueFront. The following list identiﬁes operations that are commonly\n",
            "linked list as its baking data structure. While a node that has two pointers\n",
            "picking an item, called pivot, and moving all smaller items before it, while all\n",
            "Choosing an appropriate pivot, as for example the median element is funda-\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Figure 8.3: Quick Sort Example (pivot median strategy)\n",
            "if list[i] = pivot\n",
            "if list[i] < pivot\n",
            "if list[i] > pivot\n",
            "specify the maximum key size in the list is that we need a way to isolate a\n",
            "list\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "1) algorithm ProbabilitySearch(list, item)\n",
            "listed points can be managed by using three variables:\n",
            "return anything. The third item from the list is our recursive case.\n",
            "The following list identiﬁes testing frameworks which are popular:\n",
            "Don’t worry if you think that the list is very sparse, there are far more on\n",
            "possible. The last point is very important as TDD is a progressive methodology\n"
        ],
        "label": 0
    },
    "ascending order post": {
        "abstracts": [
            "might be “The list has been sorted in ascending order”\n",
            "Inorder\n",
            "ordered set.\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n"
        ],
        "label": 0
    },
    "summary summary summary": {
        "abstracts": [
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n"
        ],
        "label": 0
    },
    "ten hundred clariﬁcation": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "tions.\n"
        ],
        "label": 0
    },
    "list return": {
        "abstracts": [
            "If an algorithm has a return type it will often be presented in the post-\n",
            "condition, but where the return type is suﬃciently obvious it may be omitted\n",
            "they return to. This approach is a far cleaner way than drawing out an elaborate\n",
            "The previous list represents what we believe in the vast majority of cases to\n",
            "to point out here is yield. You can think of yield in the same light as return.\n",
            "The return keyword causes the method to exit and returns control to the caller,\n",
            "whereas yield returns each value to the caller. With yield control only returns\n",
            "to the caller when all values to return to the caller have been exhausted.\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "What linked lists are not very good for is random insertion, accessing nodes\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "itself. Again, ∅is returned if the value isn’t found.\n",
            "return ∅\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "Post: return index of item if found, otherwise −1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "Post: the number of repeated words in value is returned\n",
            "between any characters thus returning a non-negative index that represents the\n",
            "return −1\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "return 0\n",
            "return 1\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "A.3 shows the call chain annotated with the return values of each method call\n",
            "as well as the order in which methods return to their callers. In Figure A.3 the\n",
            "• The return address is pushed onto the stack\n",
            "2. The return address is popped oﬀthe stack\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n",
            "veriﬁed that a particular value V is returned from a speciﬁc input I then your\n",
            "Like return but builds a sequence.\n"
        ],
        "label": 0
    },
    "summary summary": {
        "abstracts": [
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n"
        ],
        "label": 0
    },
    "unit test": {
        "abstracts": [
            "then transcribe these tests into unit tests satisfying them one by one. When\n",
            "provided in this book are unit tests. Because unit tests contribute such a core\n",
            "Primality Test\n",
            "Testing is an essential part of software development. Testing has often been\n",
            "a suite of unit tests that verify certain boundary conditions of your software.\n",
            "A great thing about testing is that you build up progressively a safety net. If\n",
            "Unit testing which will be the subject of the vast majority of this chapter\n",
            "for unit testing.\n",
            "What constitutes a unit test?\n",
            "A unit test should focus on a single atomic property of the subject being tested.\n",
            "given I. A unit test should be simple and self describing.\n",
            "As well as a unit test being relatively atomic you should also make sure that\n",
            "your unit tests execute quickly. If you can imagine in the future when you may\n",
            "incredibly tedious waiting several minutes to run tests on a developers local\n",
            "One of the founding principles of TDD is to write the unit test ﬁrst, watch\n",
            "unit test. A popular approach - the three A’s is described in the following list:\n",
            "duction code, e.g. all unit tests for a Person type may be contained within\n",
            "Something that you can get as a product of unit testing are code coverage\n",
            "code that your units tests cover. Using TDD it is likely that your code coverage\n"
        ],
        "label": 0
    },
    "root node bst": {
        "abstracts": [
            "that root is a reference to the root node of the tree.\n",
            "the tree is empty then we simply create our root node and ﬁnish. In all other\n",
            "Pre: root is the root node of the tree, value is what we would like to locate\n",
            "Pre: value is the value of the node to remove, root is the root node of the BST\n",
            "root is the root node of the BST and is ! = ∅\n",
            "root is the root node of the BST\n",
            "Pre: root is the root node of the BST\n",
            "Pre: root is the root node of the BST\n",
            "Pre: root is the root node of the BST\n",
            "Pre: root is the root node of the BST\n",
            "Pre: root is the root node of the BST\n",
            "Pre: root is the root node of the BST\n",
            "Pre: value is the value of the node to remove, root is the root node\n",
            "CheckBalance(path.Pop()) // we trackback to the root node check balance\n"
        ],
        "label": 0
    },
    "tree avl tree": {
        "abstracts": [
            "properties see AVL tree deﬁned in §7).\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "AVL Tree\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "The AVL tree is a sophisticated self balancing tree. It can be thought of as\n",
            "the AVL tree avoids worst case linear complexity runtimes for its operations.\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n"
        ],
        "label": 0
    },
    "34 35": {
        "abstracts": [],
        "label": 0
    },
    "list return list return": {
        "abstracts": [
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "detail final message summary": {
        "abstracts": [
            "Final messages\n",
            "tail ←n\n",
            "tail ←n\n",
            "tail ←n\n",
            "tail ←n\n",
            "tail ←n\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n"
        ],
        "label": 0
    },
    "number compute factorial post": {
        "abstracts": [
            "Pre: n is the value to compute the factorial of\n",
            "Numeric\n",
            "Pre: n ≥0, n is the number to compute the factorial of\n",
            "factorial ←1\n"
        ],
        "label": 0
    },
    "figure show step inserting": {
        "abstracts": [
            "1. Insertion\n",
            "Insertion\n",
            "Searching\n",
            "Insertion\n",
            "Insertion\n",
            "Searching\n",
            "Insertion\n",
            "Searching\n",
            "Insertion\n",
            "Insertion\n",
            "Sorting\n",
            "Searching\n"
        ],
        "label": 0
    },
    "singly linked list": {
        "abstracts": [
            "a node to the tail of a linked list where we always maintain a pointer to\n",
            "use pointers for certain things. For example, when we describe a linked list\n",
            "Linked Lists\n",
            "linked list.\n",
            "In DSA our implementations of linked lists always maintain head and tail\n",
            "operation. As such, linked lists in DSA have the following characteristics:\n",
            "the head nor tail in a singly linked list. When the node we are inserting before\n",
            "traverse the linked list to ﬁnd that node’s current predecessor. This traversal\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "Singly Linked List\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "Figure 2.1: Singly linked list node\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "Adding a node to a singly linked list has only two cases:\n",
            "Searching a linked list is straightforward: we simply traverse the list checking\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "Post: the item is either in the linked list, true; otherwise false\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "6. the item to remove doesn’t exist in the linked list\n",
            "Traversing a singly linked list is the same as that of traversing a doubly linked\n",
            "1. node = ∅, we have exhausted all nodes in the linked list; or\n",
            "Traversing a singly linked list in a forward manner (i.e. left to right) is simple\n",
            "characteristics of the nodes that make up a singly linked list make this an\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "as you will soon see that doubly linked lists (deﬁned in §2.2) make reverse list\n",
            "Doubly Linked List\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "Figure 2.3: Reverse traveral of a singly linked list\n",
            "Figure 2.4: Doubly linked list node\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "those listed previously for the singly linked list:\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "Singly linked lists have a forward only design, which is why the reverse traversal\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "a linear run time. You should also use linked lists when you will only remove\n",
            "Singly linked lists should be used when you are only performing basic in-\n",
            "sertions. In general doubly linked lists are more accommodating for non-trivial\n",
            "operations on a linked list.\n",
            "We recommend the use of a doubly linked list when you require forwards\n",
            "In this scenario a doubly linked list is best as its design makes\n",
            "bi-directional traversal much simpler and quicker than that of a singly linked\n",
            "list.\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "item at the head of a singly linked list, removal is simply a case of returning\n",
            "remains the same as that of a singly linked list: O(n).\n",
            "list\n",
            "to search a BST than it is a linked list. If you are going to search for data fairly\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n"
        ],
        "label": 0
    },
    "increment list increment": {
        "abstracts": [
            "increment ←list.Count / 2\n",
            "i−= increment\n",
            "list\n"
        ],
        "label": 0
    },
    "recursive algorithm appendix use": {
        "abstracts": [
            "algorithms.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Algorithms\n",
            "implementing recursive algorithms see Appendix C.\n",
            "Appendix A\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "Recursive Algorithms\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "Appendix B\n",
            "Appendix C\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "zero tolerance policy for recursive algorithms.\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "Appendix D\n",
            "Appendix E\n"
        ],
        "label": 0
    },
    "product unit testing": {
        "abstracts": [
            "Testing\n",
            "Sorting\n",
            "Strings\n",
            "Testing\n",
            "for unit testing.\n",
            "Something that you can get as a product of unit testing are code coverage\n"
        ],
        "label": 0
    },
    "return list": {
        "abstracts": [
            "If an algorithm has a return type it will often be presented in the post-\n",
            "condition, but where the return type is suﬃciently obvious it may be omitted\n",
            "they return to. This approach is a far cleaner way than drawing out an elaborate\n",
            "to the caller when all values to return to the caller have been exhausted.\n",
            "return false\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "list.\n",
            "return false\n",
            "return true\n",
            "return Contains(root.Left, value)\n",
            "return Contains(root.Right, value)\n",
            "return false // value not in BST\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return FindParent(value, root.Left)\n",
            "return ∅\n",
            "return root\n",
            "return FindParent(value, root.Right)\n",
            "itself. Again, ∅is returned if the value isn’t found.\n",
            "return ∅\n",
            "return root\n",
            "return FindNode(root.Left, value)\n",
            "return FindNode(root.Right, value)\n",
            "return value with ∅.\n",
            "return root.Value\n",
            "return root.Value\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return union\n",
            "return intersection\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n",
            "return false // value not in Avl\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "while current < list.Count\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return factorial\n",
            "Post: return index of item if found, otherwise −1\n",
            "return index\n",
            "return −1\n",
            "return false\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return index\n",
            "return −1\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "return 0\n",
            "return 1\n",
            "return Fibonacci(n −1) + Fibonacci(n −2)\n",
            "return anything. The third item from the list is our recursive case.\n",
            "A.3 shows the call chain annotated with the return values of each method call\n",
            "as well as the order in which methods return to their callers. In Figure A.3 the\n",
            "return values are represented as annotations to the red arrows.\n",
            "It is important to note that each recursive call only ever returns to its caller\n",
            "Figure A.3: Return chain for Fibonacci algorithm\n",
            "When the ﬁrst recursive call (Fibonacci(n −1)) returns to the caller we then\n",
            "calls have returned to their caller, the caller can then subesequently return to\n",
            "recursive calls out so you can visualise the call/return chain.\n",
            "return false;\n",
            "return false;\n",
            "return true;\n",
            "in the call chain exit and return to their respective caller. When a method exits\n",
            "Like return but builds a sequence.\n"
        ],
        "label": 0
    },
    "set2 pre list": {
        "abstracts": [
            "list.\n",
            "the set are distinct from one another.\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n"
        ],
        "label": 0
    },
    "algorithm remove head value": {
        "abstracts": [
            "algorithms.\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "1) algorithm ReverseWords(value)\n",
            "value\n",
            "1. value\n",
            "value\n"
        ],
        "label": 0
    },
    "selecting correct sorting algorithm": {
        "abstracts": [
            "algorithms.\n",
            "the sorting algorithms.\n",
            "Algorithms\n",
            "Sorting\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n",
            "Iterative algorithms\n"
        ],
        "label": 0
    },
    "greater equal greater inequality": {
        "abstracts": [
            "Equality.\n",
            "Inequality.\n"
        ],
        "label": 0
    },
    "left preorder root": {
        "abstracts": [
            "return root\n",
            "return root\n",
            "return root\n",
            "Preorder\n",
            "subtree and ﬁnally traverse the right subtree. An example of preorder traversal\n",
            "1) algorithm Preorder(root)\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "step match occurred figure": {
        "abstracts": [
            "Match\n",
            "Figure 11.5: a) First Step; b) Second Step c) Match Occurred\n"
        ],
        "label": 0
    },
    "summary summary description": {
        "abstracts": [
            "tions.\n",
            "Summary\n",
            "tions.\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "tions.\n",
            "Summary\n",
            "Description\n"
        ],
        "label": 0
    },
    "ascending order post list": {
        "abstracts": [
            "might be “The list has been sorted in ascending order”\n",
            "list.\n",
            "Inorder\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "list\n"
        ],
        "label": 0
    },
    "pre list": {
        "abstracts": [
            "a node to the tail of a linked list where we always maintain a pointer to\n",
            "Two of the languages that we have listed (C# and Java) target virtual\n",
            "use pointers for certain things. For example, when we describe a linked list\n",
            "of the OO concepts listed above. As a ﬁnal note it is also desirable that the\n",
            "32 bit machine, similarly l is a pseudo-name for a list where a list is a resizeable\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "might be “The list has been sorted in ascending order”\n",
            "quickly look at Appendix E which contains a table listing the various symbols\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "Linked Lists\n",
            "Linked lists can be thought of from a high level perspective as being a series\n",
            "linked list.\n",
            "In DSA our implementations of linked lists always maintain head and tail\n",
            "pointers so that insertion at either the head or tail of the list is a constant\n",
            "operation. As such, linked lists in DSA have the following characteristics:\n",
            "node(s) at the head and tail of the linked list and so performing a traditional\n",
            "insertion to either the front or back of the linked list is an O(1) operation. An\n",
            "the head nor tail in a singly linked list. When the node we are inserting before\n",
            "is somewhere in the middle of the linked list (known as random insertion) the\n",
            "traverse the linked list to ﬁnd that node’s current predecessor. This traversal\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "1. the list is dynamically resized, thus it incurs no copy penalty like an array\n",
            "Singly Linked List\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "a reference to the next node (if any) in the list.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.1: Singly linked list node\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "In general when people talk about insertion with respect to linked lists of any\n",
            "form they implicitly refer to the adding of a node to the tail of the list. When\n",
            "adds a node to the list, you can assume that you are adding the node to the tail\n",
            "of the list not the head.\n",
            "Adding a node to a singly linked list has only two cases:\n",
            "tail of the list; or\n",
            "2. we simply need to append our node onto the end of the list updating the\n",
            "Pre: value is the value to add to the list\n",
            "Post: value has been placed at the tail of the list\n",
            "quence of integers to the list: 1, 45, 60, and 12, the resulting list is that of\n",
            "Searching a linked list is straightforward: we simply traverse the list checking\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Post: the item is either in the linked list, true; otherwise false\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "1. the list is empty; or\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "6. the item to remove doesn’t exist in the linked list\n",
            "that items will only ever be removed from the head or tail of the list then you\n",
            "the front of the linked list deletion becomes an O(1) operation.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "value is the value to remove from the list\n",
            "Post: value is removed from the list, true; otherwise false\n",
            "Traversing the list\n",
            "Traversing a singly linked list is the same as that of traversing a doubly linked\n",
            "list (deﬁned in §2.2). You start at the head of the list and continue until you\n",
            "1. node = ∅, we have exhausted all nodes in the linked list; or\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Post: the items in the list have been traversed\n",
            "Traversing the list in reverse order\n",
            "Traversing a singly linked list in a forward manner (i.e. left to right) is simple\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "characteristics of the nodes that make up a singly linked list make this an\n",
            "so over the course of traversing the whole list backwards the cost becomes O(n2).\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "Pre: head and tail belong to the same list\n",
            "Post: the items in the list have been traversed in reverse order\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "as you will soon see that doubly linked lists (deﬁned in §2.2) make reverse list\n",
            "Doubly Linked List\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "that each node has a reference to both the next and previous nodes in the list.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.3: Reverse traveral of a singly linked list\n",
            "Figure 2.4: Doubly linked list node\n",
            "CHAPTER 2. LINKED LISTS\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "those listed previously for the singly linked list:\n",
            "not the ﬁrst node to be inserted into the list.\n",
            "Pre: value is the value to add to the list\n",
            "Post: value has been placed at the tail of the list\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "value is the value to remove from the list\n",
            "Post: value is removed from the list, true; otherwise false\n",
            "Singly linked lists have a forward only design, which is why the reverse traversal\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "Pre: tail is the tail node of the list to traverse\n",
            "Post: the list has been traversed in reverse order\n",
            "Linked lists are good to use when you have an unknown number of items to\n",
            "a linear run time. You should also use linked lists when you will only remove\n",
            "nodes at either the head or tail of the list to maintain a constant run time.\n",
            "This requires maintaining pointers to the nodes at the head and tail of the list\n",
            "What linked lists are not very good for is random insertion, accessing nodes\n",
            "variable that tracks how many items are contained in the list so that accessing\n",
            "Singly linked lists should be used when you are only performing basic in-\n",
            "sertions. In general doubly linked lists are more accommodating for non-trivial\n",
            "operations on a linked list.\n",
            "We recommend the use of a doubly linked list when you require forwards\n",
            "In this scenario a doubly linked list is best as its design makes\n",
            "CHAPTER 2. LINKED LISTS\n",
            "list.\n",
            "are listed simply for completeness.\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "the set are distinct from one another.\n",
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "Pre: set1, and set2 ̸= ∅\n",
            "Pre: set1, and set2 ̸= ∅\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "item at the head of a singly linked list, removal is simply a case of returning\n",
            "remains the same as that of a singly linked list: O(n).\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "linked list as its baking data structure. While a node that has two pointers\n",
            "every other item in some list, however as the description may imply this form\n",
            "Pre: list ̸= ∅\n",
            "return list\n",
            "merging the sorted lists back together.\n",
            "Note: the function MergeOrdered simply takes two ordered lists and makes\n",
            "Pre: list ̸= ∅\n",
            "return list\n",
            "- in which case the list is implicitly sorted.\n",
            "Pre: list ̸= ∅\n",
            "return list\n",
            "return list\n",
            "coloured square is the current value we are holding.\n",
            "Pre: list ̸= ∅\n",
            "return list\n",
            "specify the maximum key size in the list is that we need a way to isolate a\n",
            "Pre: list ̸= ∅\n",
            "maxKeySize ≥0 and represents the largest key size in the list\n",
            "return list\n",
            "operating on the list whose members are 90, 12, 8, 791, 123, and 61, the key we\n",
            "return Reverse(list)\n",
            "list\n",
            "A simple algorithm that search for a speciﬁc item inside a list.\n",
            "it’s predecessor in the list. The algorithm complexity still remains at O(n) but\n",
            "if index ≥list.Count or list[index] ̸= item\n",
            "to search a BST than it is a linked list. If you are going to search for data fairly\n",
            "return anything. The third item from the list is our recursive case.\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n",
            "Don’t worry if you think that the list is very sparse, there are far more on\n",
            "oﬀer than those that we have listed. The ones listed are the testing frameworks\n",
            "The ﬁrst point of the above list always occurs at least once (more if you count\n",
            "Throughout the pseudocode listings you will ﬁnd several symbols used, describes\n"
        ],
        "label": 0
    },
    "programming language": {
        "abstracts": [
            "imperative programming languages. It is not a deﬁnitive book on the theory of\n",
            "2. An imperative programming language\n",
            "Imperative programming language\n",
            "must know the basics of some imperative mainstream programming language\n",
            "One of the most succinct properties of modern programming languages like\n"
        ],
        "label": 0
    },
    "set figure 11": {
        "abstracts": [
            "subtrees cannot be no more than one, see Figure 7.1. This condition, restored\n",
            "The BST in Figure 7.2 represents the worst case scenario in which the run-\n",
            "character they point to is the same with respect to value. Figure 11.1 shows the\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "are the same word minus the punctuation. Figure 11.4 shows the undesired and\n",
            "location of the ﬁrst character in the match (Figure 11.5); otherwise we return\n",
            "cases. Figure A.2 shows a diagrammtic representation of the recursive call chain.\n"
        ],
        "label": 0
    },
    "tree binary search tree": {
        "abstracts": [
            "Binary Search Tree\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "structures that derive from BinarySearchTree.\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "Trees are\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n",
            "name for binary search, binary chop usually refers to its array counterpart) as\n"
        ],
        "label": 0
    },
    "list return item list": {
        "abstracts": [
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n"
        ],
        "label": 0
    },
    "data structure": {
        "abstracts": [
            "data structures and algorithms.\n",
            "language. In particular, we never provide data structures or algorithms that\n",
            "as possible. However, to appreciate the designs of our data structures you will\n",
            "2. Post-conditions represent the result of applying algorithm a to data struc-\n",
            "ture d\n",
            "a way you can intuitively map relationships between data structures rather\n",
            "mon data structures; and\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "be the most important for each respective data structure.\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "Data Structures\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "store. Using a data structure like an array would require you to specify the size\n",
            "the BST is reasonably balanced; for a tree data structure with self balancing\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "Unlike other tree data structures like the one deﬁned in §3 a heap is generally\n",
            "most two children. Figure 4.1 shows how the tree (not a heap data structure)\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "can be unpredictable when it comes to the size of its internal data structures,\n",
            "so we need to choose a more dynamic data structure that contains the following\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "structure\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "array data structure which our heap implementation is based upon. As a result\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "data structure. As mentioned previously we only add an item to a set if that\n",
            "item is not already in the set, so the backing data structure we use must have\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "the correct backing data structure. As we discussed in §5.1.1 because we check\n",
            "its backing data structure is acceptable.\n",
            "Queues are an essential data structure that are found in vast amounts of soft-\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "queue data structure that you can use with your language of choice. In this\n",
            "data structure.\n",
            "front of the queue. The queue data structure can be eﬃciently implemented\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "frameworks also specify explicit behaviour’s that data structures must adhere to.\n",
            "which requires the data structure to expose a standard Add method. In such\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "Figure 6.2: Deque data structure after several mutations\n",
            "linked list as its baking data structure. While a node that has two pointers\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "One implementation of a priority queue is to use a heap data structure as its\n",
            "Queues are a very natural data structure, and while they are fairly primitive\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "data structure being used to store the data. For instance it is quicker to deter-\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "data structures that best ﬁt your scenario.\n",
            "are. Strings are probably the most common data type (and data structure -\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "Figure A.1: Visualising the data structure we are operating on\n",
            "promote the core data structure being operated on to a larger diagram outside\n",
            "At the cost of a simple table, and quick sketch of the data structure you are\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Something that you may come across is that some data structures and algo-\n",
            "adhering to the inherent design of the data structure you are operating on. Of\n",
            "Many times recursion has a natural home in recursive data structures and\n",
            "test. We have found this approach to provide a more structured intent to the\n",
            "Refactor: Can we restructure our program so it makes more sense, and easier to\n",
            "the restructuring of your program to make it as readable and maintainable as\n",
            "very cleanly structured types and so on.\n",
            "want to know how to actually structure each block of imperatives within a single\n",
            "The structuring of tests\n",
            "Structuring tests can be viewed upon as being the same as structuring pro-\n",
            "you should apply the same amount of thought to its structure as you would do\n"
        ],
        "label": 0
    },
    "current left height": {
        "abstracts": [
            "of eight.\n",
            "Right\n",
            "Left\n",
            "Post: current height has been updated while tree balance is if needed\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "left\n",
            "right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "use tdd": {
        "abstracts": [
            "You should use this book alongside another on the same subject, but one\n",
            "The pseudocode style that we use within this book is rather straightforward.\n",
            "The return keyword causes the method to exit and returns control to the caller,\n",
            "BSTs are of interest because they have operations which are favourably fast:\n",
            "an array and because this property is key to understanding this chapter Figure\n",
            "heap is the array used to store the heap items\n",
            "1. ﬁnd the index of the value to delete\n",
            "3. verify heap ordering for each subtree which used to include the value\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "array. Count is used to partition the conceptual heap from the actual array\n",
            "subscript is used to disambiguate separate objects of T.\n",
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "you should assume that it uses the min-heap strategy.\n",
            "because it is not required.\n",
            "of a hash table and use the key of an item to determine whether or not it is\n",
            "We can use sets to facilitate many algorithms that would otherwise be a little\n",
            "queue data structure that you can use with your language of choice. In this\n",
            "Notice that we use two new algorithms that represent double rotations.\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "below the cast is implicit so we just use the actual argument numberBase.\n",
            "solution is presented because it too is trivial to implement and doesn’t suﬀer\n",
            "are simply here because they were fun to design. Perhaps the message that\n",
            "logarithmic searching algorithm that AVL and BST tree’s use (deﬁned in §3.2).\n",
            "data structure being used to store the data. For instance it is quicker to deter-\n",
            "Strings have their own chapter in this text purely because string operations\n",
            "rithm uses two pointers at opposite ends of string we are checking is a palindrome\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "array of characters) that determines a delimiter to use to split the characters\n",
            "You will notice in the RepeatedWordCount algorithm that we use the Strip\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "diagram will be used to visualise the problem more eﬀectively. Seeing things\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "In Table A.2 we have included both the value, and word variables because it\n",
            "to a larger diagram (like that in Figure A.1) and only use the trace table for\n",
            "your algorithm. You can use these trace tables to verify algorithm correctness.\n",
            "of say 60 then we would have to wait a while to get the value back because it\n",
            "course it is not all good news, after all we are still bound by the limitations we\n",
            "which case recursion is great provided you don’t go and use it to implement\n",
            "make the failing test pass. Because TDD makes you write the tests up front you\n",
            "use TDD as our preferred method.\n",
            "possible. The last point is very important as TDD is a progressive methodology\n",
            "Employing a methodology like TDD, or testing after implementing you will\n",
            "We can also use things like inheritance etc when deﬁning classes of tests.\n",
            "will be very high, although it will vary depending on how easy it is to use TDD\n",
            "testing can be used to create a safety blanket when adding and removing features\n",
            "Throughout the pseudocode listings you will ﬁnd several symbols used, describes\n"
        ],
        "label": 0
    },
    "recursive v iterative solution": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "cursive in nature, however here we present an iterative solution. The iterative\n",
            "Recursive Vs. Iterative\n",
            "Solutions\n",
            "advantage of iterative solutions is speed. Most production software you will\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "algorithm. The iterative solution is not as pretty, nor self documenting but it\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "tions.\n"
        ],
        "label": 0
    },
    "true return false": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false // value not in BST\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "exist in the BST, in which case we return ∅. Callers to this algorithm must take\n",
            "return ∅\n",
            "we are returning a reference to a node not true or false. Given FindNode,\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false // value not in Avl\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "A.3 shows the call chain annotated with the return values of each method call\n",
            "return false;\n",
            "return false;\n",
            "• The return address is pushed onto the stack\n",
            "2. The return address is popped oﬀthe stack\n"
        ],
        "label": 0
    },
    "value delete algorithm": {
        "abstracts": [
            "themselves based on the concepts by which the respective algorithms are based\n",
            "algorithms.\n",
            "count during the insertion and deletion algorithms.\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "Algorithms\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "Iterative algorithms\n",
            "value\n",
            "value\n"
        ],
        "label": 0
    },
    "number digit post maximum": {
        "abstracts": [],
        "label": 0
    },
    "value type": {
        "abstracts": [
            "Pre: n is the value to compute the factorial of\n",
            "whereas yield returns each value to the caller. With yield control only returns\n",
            "to the caller when all values to return to the caller have been exhausted.\n",
            "Pre: value is the value to add to the list\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "value is the value to search for\n",
            "value is the value to remove from the list\n",
            "Pre: value is the value to add to the list\n",
            "value is the value to remove from the list\n",
            "if value = head.Value\n",
            "and the right subtree contains nodes whose values are ≥x. Each node follows\n",
            "the ﬁrst appropriate place in the tree to put value. Note that at each stage we\n",
            "right by comparing the new value with that of the current node. For any totally\n",
            "right subtree containing values that are ≥x where x is the value of the node\n",
            "Post: value is either located or not\n",
            "1. the value to remove is a leaf node; or\n",
            "2. the value to remove has a right subtree, but no left subtree; or\n",
            "3. the value to remove has a left subtree, but no right subtree; or\n",
            "4. the value to remove has both a left and right subtree in which case we\n",
            "promote the largest value in the left subtree.\n",
            "Of course in a BST a value may occur more than once. In such a case the\n",
            "ﬁrst occurrence of that value in the BST will be removed.\n",
            "Pre: value is the value of the node to remove, root is the root node of the BST\n",
            "return false // value not in BST\n",
            "if nodeToRemove.Value < parent.Value\n",
            "if nodeToRemove.Value < parent.Value\n",
            "if nodeToRemove.Value < parent.Value\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "// set the parents’ Right pointer of largestV alue to ∅\n",
            "the parent node of the one with the given value. We have found that such an\n",
            "Pre: value is the value of the node we want to ﬁnd the parent of\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "speciﬁed value exists.\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "Pre: value is the value of the node we want to ﬁnd the parent of\n",
            "return value with ∅.\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "Post: the smallest value in the BST is located\n",
            "Post: the largest value in the BST is located\n",
            "traversal where the value of the current node is yielded in between traversing\n",
            "One of the beauties of inorder traversal is that values are yielded in their\n",
            "have the smallest value in the tree.\n",
            "4.2 shows arrows to the direct left and right child of each value in the array.\n",
            "the heap. This varies from case to case; sometimes null values are prohibited\n",
            "operation. Inserting a value into the next free slot in an array is simple: we just\n",
            "it after each insertion. Inserting our value into the heap is the ﬁrst part of the\n",
            "this requires us to swap the values of a parent and its child if the value of the\n",
            "the value we just inserted.\n",
            "Figure 4.5: Inserting values into a min-heap\n",
            "Pre: value is the value to add to the heap\n",
            "1. ﬁnd the index of the value to delete\n",
            "2. put the last value in the heap at the index location of the item to delete\n",
            "Pre: value is the value to remove from the heap\n",
            "value in the heap array. If you are using a heap for reference types, i.e. objects\n",
            "Pre: value is the value to search the heap for\n",
            "value 4 we would have to exhaust the whole backing heap array before we could\n",
            "Pre: value is the value to search the heap for\n",
            "if value = heap[start]\n",
            "else if value > Parent(heap[start]) and value < heap[start]\n",
            "can conﬁrm that ∀nodes n at level i : value > Parent(n), value < n thus there\n",
            "and then visit each value within the array until you have reached the upper\n",
            "for a value type.\n",
            "less than that of each of its children, the latter enforces that the value of the\n",
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "alias to the current value we are inspecting and to the right hand side of | are\n",
            "the value of the old head node, and then modifying the head pointer to be the\n",
            "nodes is O(log n) regardless of the order in which values are inserted.\n",
            "AVL insertion operates ﬁrst by inserting the given value the same way as BST\n",
            "to be rebalanced and the value we are removing is contained within the tree\n",
            "Pre: value is the value of the node to remove, root is the root node\n",
            "return false // value not in Avl\n",
            "if nodeToRemove.Value < parent.Value\n",
            "if nodeToRemove.Value < parent.Value\n",
            "if nodeToRemove.Value < parent.Value\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "// set the parents’ Right pointer of largestV alue to ∅\n",
            "coloured square is the current value we are holding.\n",
            "location, e.g. 0102 here it is more obvious that the key value at the thousands\n",
            "be as follows: 166 −1. The maximum value of the previous example would be\n",
            "Post: the words in value have been reversed\n",
            "rithm. The values within this table are constantly updated when the algorithm\n",
            "values each variable has held. You may also be able to infer patterns from the\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "the value of the string we will operate on let’s go ahead and draw it as shown\n",
            "value\n",
            "value\n",
            "return values are represented as annotations to the red arrows.\n",
            "algorithm that when invoked given a speciﬁc value it creates many recursive\n",
            "very cleanly structured types and so on.\n"
        ],
        "label": 0
    },
    "parent greater child bound": {
        "abstracts": [
            "Part I\n",
            "parent ←∅\n",
            "bound.\n"
        ],
        "label": 0
    },
    "root case value bst": {
        "abstracts": [
            "value\n",
            "was convenient to do so. You may ﬁnd that you want to promote these values\n",
            "value\n"
        ],
        "label": 0
    },
    "number item deque contain": {
        "abstracts": [
            "Numeric\n"
        ],
        "label": 0
    },
    "increment list increment list": {
        "abstracts": [
            "i−= increment\n",
            "list[i + increment] ←hold\n",
            "list\n"
        ],
        "label": 0
    },
    "chapter introduction chapter introduction": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "factorial post factorial": {
        "abstracts": [
            "factorial ←1\n",
            "factorial ←factorial ∗i\n",
            "return factorial\n"
        ],
        "label": 0
    },
    "radix sort": {
        "abstracts": [
            "to demonstrate sorting, e.g.\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "a list, into two similar sized lists (left, and right) and sorting each list and then\n",
            "if list.Count = 1 // already sorted\n",
            "if list.Count = 1 // already sorted\n",
            "Insertion Sort\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "Figure 8.4: Insertion Sort Iterations\n",
            "Radix Sort\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "Normally a bucket is a queue, each time radix sort is performed these buckets\n",
            "version of radix sort let us clarify what we mean by isolating keys. Given the\n",
            "tation of radix sort that works on only positive integers, and requires you to\n",
            "1) algorithm Radix(list, maxKeySize)\n",
            "Figure 8.6: Radix sort base 10 algorithm\n",
            "from a word. The reason we perform this operation on each word is so that\n"
        ],
        "label": 0
    },
    "faster big oh notation": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "1. Big Oh notation\n",
            "Big Oh notation\n",
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "The following list explains some of the most common big Oh notations:\n",
            "The biggest asset that big Oh notation gives us is that it allows us to es-\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "tions.\n",
            "tions.\n",
            "Rotation\n",
            "Rotation\n",
            "tions.\n"
        ],
        "label": 0
    },
    "10 10 10": {
        "abstracts": [],
        "label": 0
    },
    "doubly linked list": {
        "abstracts": [
            "a node to the tail of a linked list where we always maintain a pointer to\n",
            "use pointers for certain things. For example, when we describe a linked list\n",
            "Linked Lists\n",
            "linked list.\n",
            "In DSA our implementations of linked lists always maintain head and tail\n",
            "operation. As such, linked lists in DSA have the following characteristics:\n",
            "node(s) at the head and tail of the linked list and so performing a traditional\n",
            "insertion to either the front or back of the linked list is an O(1) operation. An\n",
            "the head nor tail in a singly linked list. When the node we are inserting before\n",
            "is somewhere in the middle of the linked list (known as random insertion) the\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "Singly Linked List\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "Figure 2.1: Singly linked list node\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "In general when people talk about insertion with respect to linked lists of any\n",
            "Adding a node to a singly linked list has only two cases:\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "the front of the linked list deletion becomes an O(1) operation.\n",
            "Traversing a singly linked list is the same as that of traversing a doubly linked\n",
            "Traversing a singly linked list in a forward manner (i.e. left to right) is simple\n",
            "characteristics of the nodes that make up a singly linked list make this an\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "as you will soon see that doubly linked lists (deﬁned in §2.2) make reverse list\n",
            "Doubly Linked List\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "Figure 2.3: Reverse traveral of a singly linked list\n",
            "Figure 2.4: Doubly linked list node\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "those listed previously for the singly linked list:\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "As you may of guessed the cases that we use for deletion in a doubly linked\n",
            "Singly linked lists have a forward only design, which is why the reverse traversal\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "a linear run time. You should also use linked lists when you will only remove\n",
            "Singly linked lists should be used when you are only performing basic in-\n",
            "sertions. In general doubly linked lists are more accommodating for non-trivial\n",
            "operations on a linked list.\n",
            "We recommend the use of a doubly linked list when you require forwards\n",
            "In this scenario a doubly linked list is best as its design makes\n",
            "list.\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "item at the head of a singly linked list, removal is simply a case of returning\n",
            "remains the same as that of a singly linked list: O(n).\n",
            "list\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n"
        ],
        "label": 0
    },
    "left preorder root right": {
        "abstracts": [
            "Preorder\n",
            "Preorder(root.Right)\n",
            "Postorder(root.Right)\n",
            "Inorder(root.Right)\n",
            "Right\n",
            "Left\n",
            "left\n",
            "right\n",
            "4. right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "oh notation run time": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "Big Oh notation also acts as a communication tool. Picture the scene: you\n",
            "nodes at either the head or tail of the list to maintain a constant run time.\n",
            "run times.\n",
            "sequentially, so this operation has a run time complexity of O(n). The search\n",
            "a quick look up and insertion run time complexity.\n",
            "constant run time complexity. Ordered sets cost a little more for this check,\n",
            "tion, for a hash table this run time complexity should be near constant. Ordered\n",
            "insertion and deletion run time complexities. The reason we have an O(1) run\n",
            "insertion and deletion run times. Searching a queue is fairly unusual—typically\n",
            "Rotation\n",
            "Rotation\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n"
        ],
        "label": 0
    },
    "unit testing": {
        "abstracts": [
            "Testing\n",
            "then transcribe these tests into unit tests satisfying them one by one. When\n",
            "provided in this book are unit tests. Because unit tests contribute such a core\n",
            "Appendix D which describes testing in more depth.\n",
            "Sorting\n",
            "Strings\n",
            "// if this isn’t the last word in the string add some whitespace after the word in the buﬀer\n",
            "algorithm discards punctuation in the string, including white space. As a result\n",
            "as our delimiter we get all the words within the string back as elements of\n",
            "of some char data types, one after the other. Each character in the string can\n",
            "For our example we will use IsPalindrome to operate on the string “Never\n",
            "Testing\n",
            "Testing is an essential part of software development. Testing has often been\n",
            "a suite of unit tests that verify certain boundary conditions of your software.\n",
            "A great thing about testing is that you build up progressively a safety net. If\n",
            "Unit testing which will be the subject of the vast majority of this chapter\n",
            "for unit testing.\n",
            "The following list identiﬁes testing frameworks which are popular:\n",
            "oﬀer than those that we have listed. The ones listed are the testing frameworks\n",
            "What constitutes a unit test?\n",
            "A unit test should focus on a single atomic property of the subject being tested.\n",
            "given I. A unit test should be simple and self describing.\n",
            "As well as a unit test being relatively atomic you should also make sure that\n",
            "your unit tests execute quickly. If you can imagine in the future when you may\n",
            "One of the founding principles of TDD is to write the unit test ﬁrst, watch\n",
            "As we have already mentioned that TDD is our favoured approach to testing\n",
            "from correct, and clean code formatting, to the testing code being stored within\n",
            "unit test. A popular approach - the three A’s is described in the following list:\n",
            "duction code, e.g. all unit tests for a Person type may be contained within\n",
            "Something that you can get as a product of unit testing are code coverage\n",
            "code that your units tests cover. Using TDD it is likely that your code coverage\n"
        ],
        "label": 0
    },
    "chapter binary search tree": {
        "abstracts": [
            "Chapter 1\n",
            "into smaller chunks per each invocation, e.g. searching a binary search\n",
            "tree.\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Binary Search Tree\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "structures that derive from BinarySearchTree.\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "tree:\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "11 11": {
        "abstracts": [],
        "label": 0
    },
    "list list pre": {
        "abstracts": [
            "The previous list represents what we believe in the vast majority of cases to\n",
            "those listed previously for the singly linked list:\n",
            "Pre:\n",
            "list\n",
            "Pre:\n",
            "Pre:\n",
            "Pre:\n",
            "Pre:\n",
            "Pre:\n",
            "Pre:\n"
        ],
        "label": 0
    },
    "root left enqueue root": {
        "abstracts": [
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "• EnqueueFront\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "parent index index": {
        "abstracts": [
            "Part I\n",
            "1. (index −1)/2 (parent index)\n",
            "and max heap. The former strategy enforces that the value of a parent node is\n",
            "parent ←∅\n",
            "Part II\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "white space we are in a word, the opposite is true if at the present index we are\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index\n",
            "index\n",
            "index\n",
            "index ←index + 1\n"
        ],
        "label": 0
    },
    "height current right": {
        "abstracts": [
            "if current.Right = ∅\n",
            "Right\n",
            "Post: current height has been updated while tree balance is if needed\n",
            "current.Height = Max(Height(current.Left),Height(current.Right)) + 1\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "if Height(current.Left.Left) - Height(current.Left.Right) > 0\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "if Height(current.Right.Left) - Height(current.Right.Right) < 0\n",
            "if current.Right = ∅\n",
            "right\n",
            "4. right\n",
            "right\n"
        ],
        "label": 0
    },
    "passed custom type check": {
        "abstracts": [
            "Pre: value has passed custom type checks for type T\n",
            "Pre: value has passed custom type checks for type T\n"
        ],
        "label": 0
    },
    "nodetoremove right nodetoremove left": {
        "abstracts": [
            "if nodeToRemove = ∅\n",
            "parent.Right ←nodeToRemove.Left\n",
            "Right\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "parent.Right ←nodeToRemove.Left\n",
            "left\n",
            "right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "problem lot easier solve": {
        "abstracts": [
            "domain and keeping track of changing data makes problems a lot easier to solve.\n"
        ],
        "label": 0
    },
    "string just": {
        "abstracts": [
            "Using just an array is often not suﬃcient as we have to be up front about the\n",
            "you traverse the array starting at the initial array index (0 in most languages)\n",
            "the shape of a tree while preserving standard BST properties. There are left and\n",
            "are emptied starting the smallest key bucket to the largest. When looking at\n",
            "Figure 10.1 shows the resulting state of a list after searching for two items,\n",
            "Strings\n",
            "string, rather it reverses the order of words within a string. This algorithm\n",
            "CHAPTER 11. STRINGS\n",
            "value ̸= ∅, sb is a string buﬀer\n",
            "// append chars from start + 1 to length + 1 to string buﬀer sb\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "Figure 11.2: String with three words\n",
            "Figure 11.3: String with varying number of white space delimiting the words\n",
            "within the string into chunks of strings, resulting in an array of sub-strings.\n",
            "Figure 11.3 shows the same string, with the same number of words but with\n",
            "CHAPTER 11. STRINGS\n",
            "// was the string just whitespace?\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "CHAPTER 11. STRINGS\n",
            "between two strings\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "characters in another string is pretty trivial. Put simply, we can parse the strings\n",
            "CHAPTER 11. STRINGS\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "that you learn to be creative with them. We for one ﬁnd strings fascinating. A\n",
            "simple Google search on string nuances between languages and encodings will\n",
            "should be pretty obvious that we are operating on a string, but how is this\n",
            "represented? A string is essentially a block of contiguous memory that consists\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "these strings with array indexes to aid the algorithm walkthrough.\n",
            "Structuring tests can be viewed upon as being the same as structuring pro-\n"
        ],
        "label": 0
    },
    "remove algorithm": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "themselves based on the concepts by which the respective algorithms are based\n",
            "that contains formal proofs of the algorithms in question. In this book we use\n",
            "measurement by which we can judge the performance of algorithms without\n",
            "algorithms.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "about the high level algorithm design rather than its eﬃciency. Replay the scene\n",
            "time should not exceed n ms. The eﬃciency of every algorithm that is invoked\n",
            "management via garbage collection algorithms. It is trivial to port our imple-\n",
            "language. In particular, we never provide data structures or algorithms that\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "All algorithms start with a simple algorithm signature, e.g.\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "Normally what is listed as a pre-conidition is critical to the algorithms opera-\n",
            "describes the eﬀect of the algorithms operation. An example of a post-condition\n",
            "The best way to work through algorithms is to set up a table, and in that\n",
            "Often while working through algorithms in such\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "with just reading the section of a chapter that describes the algorithm you are\n",
            "driven development style on paper to ﬂesh out the pseudocode algorithm. We\n",
            "intuitively identify areas which may cause problems for your algorithms imple-\n",
            "1. Understand how the algorithm works ﬁrst in an abstract sense; and\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "The only major diﬀerence between the algorithm in §2.1.1 is that we need to\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "count during the insertion and deletion algorithms.\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "cases we invoke the recursive InsertNode algorithm which simply guides us to\n",
            "but we will look brieﬂy at the premise of the algorithm nonetheless.\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "Astute readers will have noticed that the FindNode algorithm is exactly the\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "by product of verifying heap order as the ﬁrst part of the algorithm (the actual\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "not satisﬁed for any level of nodes that we are inspecting then the algorithm\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "that upon each insertion and deletion we invoke algorithms that have logarithmic\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "We can use sets to facilitate many algorithms that would otherwise be a little\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "With respect to algorithmic run time complexities a deque is the same as\n",
            "invocation of the garbage collection algorithm. With C++ or any other lan-\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "Algorithms\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "implementing recursive algorithms see Appendix C.\n",
            "A simple algorithm that determines whether or not a given integer is a prime\n",
            "DSA contains a number of algorithms that convert a base 10 number to its\n",
            "A simple algorithm that search for a speciﬁc item inside a list.\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "Although not a frequent algorithm that will be applied in real-life scenarios\n",
            "detecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "In the IsPalindrome algorithm we call a method by the name of Strip. This\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "rithm. The values within this table are constantly updated when the algorithm\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "operating on you can devise correct algorithms quicker. Visualising the problem\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "that you know how the algorithm works. Mastering how an algorithm works\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "translation of our pseudo code algorithms to mainstream imperative languages\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "you might want to use such an approach for your algorithms we will now talk\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "of these algorithms are recursive in their design and so it makes sense to model\n"
        ],
        "label": 0
    },
    "bst post node bst": {
        "abstracts": [
            "Postorder\n"
        ],
        "label": 0
    },
    "value return root value": {
        "abstracts": [
            "to the caller when all values to return to the caller have been exhausted.\n",
            "root ←node(value)\n",
            "3. value < root.Value, we must inspect the left subtree of root for value; or\n",
            "4. value > root.Value, we must inspect the right subtree of root for value.\n",
            "else if value < root.Value\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "else if value < root.Value\n",
            "return root.Value\n",
            "return root.Value\n",
            "root ←node(value)\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "value\n",
            "1. value\n",
            "value\n",
            "return 0\n",
            "return 1\n"
        ],
        "label": 0
    },
    "trouble speak manifest typically": {
        "abstracts": [
            "are going to run into trouble. The trouble we speak of manifests itself typically\n"
        ],
        "label": 0
    },
    "problem lot easier": {
        "abstracts": [
            "sider:\n",
            "they can make many problems a lot simpler.\n",
            "domain and keeping track of changing data makes problems a lot easier to solve.\n"
        ],
        "label": 0
    },
    "left nodetoremove right null": {
        "abstracts": [
            "2. the node to remove is the only node in the linked list; or\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "parent.Left ←nodeToRemove.Right\n",
            "parent.Right ←nodeToRemove.Right\n",
            "Right\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "parent.Left ←nodeToRemove.Right\n",
            "parent.Right ←nodeToRemove.Right\n",
            "left\n",
            "right\n",
            "left\n",
            "right\n",
            "Null.\n"
        ],
        "label": 0
    },
    "list index item": {
        "abstracts": [
            "index ←right\n",
            "list\n",
            "Post: return index of item if found, otherwise −1\n",
            "if index < list.Count and list[index] = item\n",
            "Swap(list[index], list[index −1])\n",
            "Of the previously listed index keeps track of the current index we are at in\n",
            "index\n",
            "index\n",
            "index\n"
        ],
        "label": 0
    },
    "equal greater equal": {
        "abstracts": [],
        "label": 0
    },
    "return true": {
        "abstracts": [
            "If an algorithm has a return type it will often be presented in the post-\n",
            "condition, but where the return type is suﬃciently obvious it may be omitted\n",
            "they return to. This approach is a far cleaner way than drawing out an elaborate\n",
            "The return keyword causes the method to exit and returns control to the caller,\n",
            "whereas yield returns each value to the caller. With yield control only returns\n",
            "to the caller when all values to return to the caller have been exhausted.\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return Contains(root.Left, value)\n",
            "return Contains(root.Right, value)\n",
            "return true\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "return ∅\n",
            "return root\n",
            "return value with ∅.\n",
            "return root.Value\n",
            "return root.Value\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return union\n",
            "return intersection\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return MergeOrdered(left, right)\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return Reverse(list)\n",
            "return m\n",
            "return GreatestCommonDenominator(n, m % n)\n",
            "return Power(numberBase, n) −1\n",
            "return 1\n",
            "return factorial\n",
            "Post: return index of item if found, otherwise −1\n",
            "return index\n",
            "return −1\n",
            "return true\n",
            "return sb\n",
            "return word[left] = word[right]\n",
            "return 0\n",
            "return wordCount\n",
            "number of stings contained in the array returned from the split operation. The\n",
            "Post: the number of repeated words in value is returned\n",
            "return words.Length −uniques.Count\n",
            "return index\n",
            "return −1\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "return 0\n",
            "return 1\n",
            "return anything. The third item from the list is our recursive case.\n",
            "A.3 shows the call chain annotated with the return values of each method call\n",
            "as well as the order in which methods return to their callers. In Figure A.3 the\n",
            "return values are represented as annotations to the red arrows.\n",
            "It is important to note that each recursive call only ever returns to its caller\n",
            "When the ﬁrst recursive call (Fibonacci(n −1)) returns to the caller we then\n",
            "calls have returned to their caller, the caller can then subesequently return to\n",
            "return true;\n",
            "• The return address is pushed onto the stack\n",
            "in the call chain exit and return to their respective caller. When a method exits\n",
            "2. The return address is popped oﬀthe stack\n",
            "veriﬁed that a particular value V is returned from a speciﬁc input I then your\n",
            "Like return but builds a sequence.\n"
        ],
        "label": 0
    },
    "list increment hold increment": {
        "abstracts": [
            "i−= increment\n",
            "list[i + increment] ←hold\n",
            "list\n"
        ],
        "label": 0
    },
    "rotation algorithm": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "data structures and algorithms.\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "O(n log n) just n log n: usually associated with an algorithm that breaks the problem\n",
            "algorithms.\n",
            "sentially discard things like hardware. If you have two sorting algorithms, one\n",
            "logarithmic algorithm will always be faster than the quadratic one when the\n",
            "a key factor in algorithm analysis: growth. An algorithm with a quadratic run\n",
            "some point as n →∞the logarithmic algorithm will become faster than the\n",
            "quadratic algorithm.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "the latter approach you not only get a good general idea about the algorithm\n",
            "when it comes to selecting an algorithm ﬁt for purpose.\n",
            "management via garbage collection algorithms. It is trivial to port our imple-\n",
            "the sorting algorithms.\n",
            "2. Post-conditions represent the result of applying algorithm a to data struc-\n",
            "The example above describes an algorithm by the name of AlgorithmName,\n",
            "throughout the algorithm.\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "For all readers we recommend that before looking at any algorithm you\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "all the test cases have been progressively satisﬁed we consider that algorithm\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "up front; exceeding that size involves invoking a resizing algorithm which has\n",
            "count during the insertion and deletion algorithms.\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "exist in the BST, in which case we return ∅. Callers to this algorithm must take\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "The following algorithm is speciﬁcally designed for a min-heap. To tailor the\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "The run time of our Union algorithm is O(m + n) where m is the number\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "of items in the smaller of the two sets. Just like our Union algorithm a linear\n",
            "The above depends on how good the hashing algorithm of the hash table\n",
            "We can use sets to facilitate many algorithms that would otherwise be a little\n",
            "set to assist in the construction of an algorithm that determines the number of\n",
            "incur the expense of invoking a resizing algorithm which would most likely be\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "invocation of the garbage collection algorithm. With C++ or any other lan-\n",
            "Rotation\n",
            "Rotation\n",
            "The right and left rotation algorithms are symmetric.\n",
            "Our balancing algorithm is like the one presented for our BST (deﬁned in §3.3).\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n",
            "Algorithms\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "Merge sort is an algorithm that has a fairly eﬃcient space time complexity -\n",
            "Quick sort is one of the most popular sorting algorithms based on divide et\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n",
            "In the following algorithm numberBase should be considered restricted to\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "Probability search is a statistical sequential searching algorithm. In addition to\n",
            "In this chapter we have presented a few novel searching algorithms. We have\n",
            "presented more eﬃcient searching algorithms earlier on, like for instance the\n",
            "logarithmic searching algorithm that AVL and BST tree’s use (deﬁned in §3.2).\n",
            "We decided not to cover a searching algorithm known as binary chop (another\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "You will notice in the RepeatedWordCount algorithm that we use the Strip\n",
            "along a little with our introductory algorithms you can devise some of your own.\n",
            "structured approach to tracing its behaviour. In most cases tracing an algorithm\n",
            "Iterative algorithms\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of an algorithm that computes a number from the Fiboncacci sequence.\n",
            "rithm calls for the Fibonacci algorithm we will brieﬂy talk about the cases of\n",
            "Figure A.2: Call chain for Fibonacci algorithm\n",
            "Figure A.3: Return chain for Fibonacci algorithm\n",
            "In the Fibonacci algorithms’ recursive case we make two recursive calls.\n",
            "Understanding algorithms can be hard at times, particularly from an implemen-\n",
            "tation perspective. In order to understand an algorithm try and work through\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "that you know how the algorithm works. Mastering how an algorithm works\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "A consideration to take note of is that many algorithms have fairly strict\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "avoid it for the following algorithm run time deﬁciencies:\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "an iterative vs. recursive solution in the form of the Fibonacci algorithm. This\n",
            "does the job a lot quicker. If we were to give the Fibonacci algorithm an input\n",
            "We can also look at sorting algorithms like merge sort, and quick sort. Both\n",
            "you add or tweak algorithms and then run your suite of tests you will be quickly\n",
            "implementation of algorithms. At any one stage you only have a single goal, to\n"
        ],
        "label": 0
    },
    "32 bit integer": {
        "abstracts": [
            "n translates to an integer that has the same number of bits as a WORD on a\n",
            "32 bit machine, similarly l is a pseudo-name for a list where a list is a resizeable\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "0, x % 2 = 0} the set A contains only positive integers that are even. x is an\n",
            "a 32 bit integer is often used as its associated\n",
            "tation of radix sort that works on only positive integers, and requires you to\n",
            "Unless stated otherwise the alias n denotes a standard 32 bit integer.\n",
            "A simple algorithm that determines whether or not a given integer is a prime\n",
            "denominator of two integers, what we are essentially after is the greatest number\n",
            "Post: the greatest common denominator of the two integers is calculated\n",
            "value of numberBase to an integer, as such we extract the value associated with\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "the string, wordCount is an integer that keeps track of the number of words we\n"
        ],
        "label": 0
    },
    "chapter avl tree": {
        "abstracts": [
            "Chapter 1\n",
            "tree.\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "The run times presented in this chapter are based on a pretty big assumption\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "AVL Tree\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "tree:\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "simply make thing complex": {
        "abstracts": [
            "simply makes things more complex to follow. Track everything in a simple and\n"
        ],
        "label": 0
    },
    "end end end": {
        "abstracts": [
            "4. All primitive language constructs are explicitly begun and ended\n",
            "few markers to deﬁne where words start and end we can easily reverse them.\n"
        ],
        "label": 0
    },
    "25 26 27 28": {
        "abstracts": [],
        "label": 0
    },
    "current right height": {
        "abstracts": [
            "current.Right ←node(value)\n",
            "InsertNode(current.Right, value)\n",
            "Right\n",
            "Post: current height has been updated while tree balance is if needed\n",
            "current.Right ←node(value)\n",
            "InsertNode(current.Right, value)\n",
            "right ←right −1\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "set enforces predeﬁned": {
        "abstracts": [
            "distinct, but an ordered set enforces some predeﬁned comparison on each of its\n"
        ],
        "label": 0
    },
    "overall problem": {
        "abstracts": [
            "should only ever be used for very small problems (if ever!); avoid them if feasibly\n",
            "barded with such a vast amount of concerns look at the overall problem again\n",
            "and sub-divide the problem into smaller problems. Solving the smaller problems\n",
            "straightforward, however the problem is a very interesting one. As an example\n"
        ],
        "label": 0
    },
    "greater equal": {
        "abstracts": [
            "greater elements after it. This is the main quick sort operation, called partition,\n",
            "recursively repeated on lesser and greater sub lists until their size is one or zero\n"
        ],
        "label": 0
    },
    "parameter inferred explicit type": {
        "abstracts": [],
        "label": 0
    },
    "current left height current": {
        "abstracts": [
            "of eight.\n",
            "Left\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "recursive v iterative": {
        "abstracts": [
            "cases we invoke the recursive InsertNode algorithm which simply guides us to\n",
            "cursive in nature, however here we present an iterative solution. The iterative\n",
            "much simple to follow when you draw out the recursive calls rather than using\n",
            "Recursive Vs. Iterative\n",
            "as to their recursive counterparts with respect to their operation. The major\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "recursive counterpart.\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n"
        ],
        "label": 0
    },
    "return root value yield": {
        "abstracts": [
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "itself. Again, ∅is returned if the value isn’t found.\n",
            "return ∅\n",
            "return root\n",
            "return root.Value\n",
            "return root.Value\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "value\n",
            "value\n",
            "return 0\n",
            "return 1\n",
            "yield\n"
        ],
        "label": 0
    },
    "chapter avl tree avl": {
        "abstracts": [
            "Chapter 1\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "In this chapter we have also seen priority queues where those at the front\n",
            "Chapter 7\n",
            "AVL Tree\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "the AVL tree avoids worst case linear complexity runtimes for its operations.\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n",
            "As you can see from the example used in this chapter we have tried to make the\n"
        ],
        "label": 0
    },
    "true false case case": {
        "abstracts": [
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n"
        ],
        "label": 0
    },
    "false return false return": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "post list sorted": {
        "abstracts": [
            "list\n"
        ],
        "label": 0
    },
    "state end": {
        "abstracts": [
            "explicitly state end for rather than leaving the interpretation of when scopes\n",
            "strategy unless otherwise stated.\n",
            "an obvious advantage if the programmer could deterministically state the maxi-\n",
            "few markers to deﬁne where words start and end we can easily reverse them.\n",
            "rithm uses two pointers at opposite ends of string we are checking is a palindrome\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "contiued at the next statement, or expression after the recursive call was made.\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "A source of great debate would be an understatement to personify such a ques-\n"
        ],
        "label": 0
    },
    "algorithm design": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "data structures and algorithms.\n",
            "that contains formal proofs of the algorithms in question. In this book we use\n",
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "ing algorithm designs you may just have the intention of solving the problem\n",
            "review your algorithm design and optimise where possible—particularly loops\n",
            "algorithms.\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "about the high level algorithm design rather than its eﬃciency. Replay the scene\n",
            "back in your head, but this time as well as talking about algorithm design each\n",
            "respective developer states the asymptotic run time of their algorithm. Using\n",
            "the sorting algorithms.\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "All algorithms start with a simple algorithm signature, e.g.\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "the algorithm signature; you should always enforce the pre-conditions of an\n",
            "algorithm when porting them to your language of choice.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "driven development style on paper to ﬂesh out the pseudocode algorithm. We\n",
            "to satisfy. With such algorithms we will point out the test cases which are tricky\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "The algorithm described is a very simple one that makes use of a simple\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "The only major diﬀerence between the algorithm in §2.1.1 is that we need to\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "count during the insertion and deletion algorithms.\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "1) algorithm FindNode(root, value)\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "1) algorithm FindMin(root)\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "1) algorithm Inorder(root)\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "algorithm; the second is validating heap order. In the case of min-heap ordering\n",
            "preserved. The algorithm for deletion has three steps:\n",
            "the heap we can optimise the search algorithm by including logic which makes\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "where such algorithms exist as extension methods deﬁned in the type Sys-\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "1) algorithm Union(set1, set2)\n",
            "1) algorithm Intersection(set1, set2)\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "algorithms and so the run time complexities for the hash table in your library\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "An algorithm described\n",
            "1) algorithm RightRotation(node)\n",
            "The right and left rotation algorithms are symmetric.\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "Our balancing algorithm is like the one presented for our BST (deﬁned in §3.3).\n",
            "Algorithms\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "1) algorithm Mergesort(list)\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "1) algorithm ShellSort(list)\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "1) algorithm Radix(list, maxKeySize)\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "1) algorithm IsPrime(n)\n",
            "1) algorithm ToBinary(n)\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "algorithms in particular drive some of the most advanced systems on the planet\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "presented more eﬃcient searching algorithms earlier on, like for instance the\n",
            "the reader has already seen such an algorithm in §3.\n",
            "and transformations are incredibly frequent within programs. The algorithms\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "1) algorithm ReverseWords(value)\n",
            "design.\n",
            "1) algorithm IsPalindrome(value)\n",
            "algorithm discards punctuation in the string, including white space. As a result\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "generated by the algorithm it can make understanding, and solving problems\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Recursive Algorithms\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "1) algorithm Fibonacci(n)\n",
            "rithm calls for the Fibonacci algorithm we will brieﬂy talk about the cases of\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "you might want to use such an approach for your algorithms we will now talk\n",
            "zero tolerance policy for recursive algorithms.\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "algorithm. The iterative solution is not as pretty, nor self documenting but it\n",
            "does the job a lot quicker. If we were to give the Fibonacci algorithm an input\n"
        ],
        "label": 0
    },
    "heap array used store": {
        "abstracts": [
            "Heap\n",
            "size of the array to use for the heap. Often the run time behaviour of a program\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "value 4 we would have to exhaust the whole backing heap array before we could\n",
            "heap is the array used to store the heap items\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n"
        ],
        "label": 0
    },
    "right height current left": {
        "abstracts": [
            "Right\n",
            "Left\n",
            "current.Height = Max(Height(current.Left),Height(current.Right)) + 1\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "if Height(current.Left.Left) - Height(current.Left.Right) > 0\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "left\n",
            "right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "type check type type": {
        "abstracts": [
            "Pre: value has passed custom type checks for type T\n",
            "Pre: value has passed custom type checks for type T\n"
        ],
        "label": 0
    },
    "equality equal greater": {
        "abstracts": [
            "Equality.\n"
        ],
        "label": 0
    },
    "introduction chapter": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Finally in this brief introduction to sets we will cover set intersection and\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "end end inword": {
        "abstracts": [
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "Inorder\n",
            "end if\n",
            "9) end Inorder\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "does, items are added in order to either the front of back of the deque. The\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "3. inWord\n",
            "end if\n",
            "end if\n",
            "if inWord\n",
            "end if\n",
            "Word\n",
            "end if\n",
            "word\n",
            "word\n",
            "end if\n",
            "word.\n"
        ],
        "label": 0
    },
    "value nodetoremove left nodetoremove": {
        "abstracts": [
            "1. the value to remove is a leaf node; or\n",
            "if nodeToRemove = ∅\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "value\n",
            "left\n",
            "value\n",
            "left\n"
        ],
        "label": 0
    },
    "ten hundred clariﬁcation wanted": {
        "abstracts": [],
        "label": 0
    },
    "recursive algorithm iterative solution": {
        "abstracts": [
            "algorithms.\n",
            "tions.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "tions.\n",
            "Algorithms\n",
            "Iterative algorithms\n",
            "Recursive Algorithms\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "Solutions\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "algorithm. The iterative solution is not as pretty, nor self documenting but it\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "tions.\n"
        ],
        "label": 0
    },
    "requires data structure expose": {
        "abstracts": [
            "ture d\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "Data Structures\n",
            "the BST is reasonably balanced; for a tree data structure with self balancing\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "Unlike other tree data structures like the one deﬁned in §3 a heap is generally\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "structure\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "data structure.\n",
            "front of the queue. The queue data structure can be eﬃciently implemented\n",
            "which requires the data structure to expose a standard Add method. In such\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "Figure 6.2: Deque data structure after several mutations\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "promote the core data structure being operated on to a larger diagram outside\n",
            "Many times recursion has a natural home in recursive data structures and\n"
        ],
        "label": 0
    },
    "11 string": {
        "abstracts": [
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "you traverse the array starting at the initial array index (0 in most languages)\n",
            "backing array. It may be in your best interest to research a good initial starting\n",
            "repeated words within a string.\n",
            "search tree obtained by starting with an empty tree and inserting some values\n",
            "Sorting\n",
            "are emptied starting the smallest key bucket to the largest. When looking at\n",
            "Strings\n",
            "Strings have their own chapter in this text purely because string operations\n",
            "Deﬁning algorithms for primitive string operations is simple, e.g. extracting a\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "string, rather it reverses the order of words within a string. This algorithm\n",
            "CHAPTER 11. STRINGS\n",
            "value ̸= ∅, sb is a string buﬀer\n",
            "// append chars from start + 1 to length + 1 to string buﬀer sb\n",
            "// if this isn’t the last word in the string add some whitespace after the word in the buﬀer\n",
            "rithm uses two pointers at opposite ends of string we are checking is a palindrome\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "If you remove all punctuation, and white space from the aforementioned string\n",
            "CHAPTER 11. STRINGS\n",
            "algorithm discards punctuation in the string, including white space. As a result\n",
            "word contains a heavily compacted representation of the original string, each\n",
            "Counting the number of words in a string\n",
            "Counting the number of words in a string can seem pretty trivial at ﬁrst, however\n",
            "1. tracking when we are in a string\n",
            "As an example consider the string “Ben ate hay” Clearly this string contains\n",
            "CHAPTER 11. STRINGS\n",
            "Figure 11.2: String with three words\n",
            "Figure 11.3: String with varying number of white space delimiting the words\n",
            "the string, wordCount is an integer that keeps track of the number of words we\n",
            "splitting symbols you may use, e.g. in .NET String.Split1 can take a char (or\n",
            "within the string into chunks of strings, resulting in an array of sub-strings.\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "Figure 11.3 shows the same string, with the same number of words but with\n",
            "CHAPTER 11. STRINGS\n",
            "// was the string just whitespace?\n",
            "within a string\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "as our delimiter we get all the words within the string back as elements of\n",
            "contains only unique strings we can attain the number of unique words from the\n",
            "CHAPTER 11. STRINGS\n",
            "we can build a more accurate unique string collection, e.g. “test”, and “test!”\n",
            "between two strings\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "characters in another string is pretty trivial. Put simply, we can parse the strings\n",
            "CHAPTER 11. STRINGS\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "are. Strings are probably the most common data type (and data structure -\n",
            "that you learn to be creative with them. We for one ﬁnd strings fascinating. A\n",
            "simple Google search on string nuances between languages and encodings will\n",
            "should be pretty obvious that we are operating on a string, but how is this\n",
            "represented? A string is essentially a block of contiguous memory that consists\n",
            "of some char data types, one after the other. Each character in the string can\n",
            "an array. The picture should be presenting itself - a string can be thought of as\n",
            "For our example we will use IsPalindrome to operate on the string “Never\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "the value of the string we will operate on let’s go ahead and draw it as shown\n",
            "more compact. Where we have the strings in the table you should annotate\n",
            "these strings with array indexes to aid the algorithm walkthrough.\n"
        ],
        "label": 0
    },
    "tree binary search": {
        "abstracts": [
            "into smaller chunks per each invocation, e.g. searching a binary search\n",
            "Searching\n",
            "Binary Search Tree\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Searching\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "structures that derive from BinarySearchTree.\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "Trees are\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "Searching\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n",
            "Searching\n",
            "name for binary search, binary chop usually refers to its array counterpart) as\n"
        ],
        "label": 0
    },
    "summary summary summary description": {
        "abstracts": [
            "tions.\n",
            "Summary\n",
            "tions.\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "tions.\n",
            "Summary\n",
            "Description\n"
        ],
        "label": 0
    },
    "make thing complex": {
        "abstracts": [
            "simply makes things more complex to follow. Track everything in a simple and\n",
            "make things simple the garbage value of a reference type will be simple ∅and 0\n",
            "the AVL tree avoids worst case linear complexity runtimes for its operations.\n",
            "Merge sort is an algorithm that has a fairly eﬃcient space time complexity -\n"
        ],
        "label": 0
    },
    "item end index list": {
        "abstracts": [
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "list.\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "index ←left\n",
            "index ←right\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "For this example we can further assume that at some point the items in indexes\n",
            "end if\n",
            "end if\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "foreach item in list\n",
            "end if\n",
            "list\n",
            "end if\n",
            "end if\n",
            "A simple algorithm that search for a speciﬁc item inside a list.\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "index\n",
            "index\n",
            "index\n",
            "end if\n",
            "end if\n"
        ],
        "label": 0
    },
    "list pre": {
        "abstracts": [
            "The following list explains some of the most common big Oh notations:\n",
            "a node to the tail of a linked list where we always maintain a pointer to\n",
            "32 bit machine, similarly l is a pseudo-name for a list where a list is a resizeable\n",
            "The previous list represents what we believe in the vast majority of cases to\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "tail of the list; or\n",
            "2. we simply need to append our node onto the end of the list updating the\n",
            "Post: the item is either in the linked list, true; otherwise false\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "where within a list irrespective of whether the node is the head etc. If you know\n",
            "that items will only ever be removed from the head or tail of the list then you\n",
            "the front of the linked list deletion becomes an O(1) operation.\n",
            "Post: value is removed from the list, true; otherwise false\n",
            "list (deﬁned in §2.2). You start at the head of the list and continue until you\n",
            "1. node = ∅, we have exhausted all nodes in the linked list; or\n",
            "expensive operation. For each node, ﬁnding its predecessor is an O(n) operation,\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "those listed previously for the singly linked list:\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "list are exactly the same as those deﬁned in §2.1.3. Like insertion we have the\n",
            "Post: value is removed from the list, true; otherwise false\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "Linked lists are good to use when you have an unknown number of items to\n",
            "What linked lists are not very good for is random insertion, accessing nodes\n",
            "sertions. In general doubly linked lists are more accommodating for non-trivial\n",
            "We recommend the use of a doubly linked list when you require forwards\n",
            "and backwards traversal. For the most cases this requirement is present. For\n",
            "1) algorithm Preorder(root)\n",
            "Traditionally breadth ﬁrst traversal is implemented using a list (vector, re-\n",
            "The run times presented in this chapter are based on a pretty big assumption\n",
            "an array and because this property is key to understanding this chapter Figure\n",
            "upper storage limit required; and\n",
            "heap order is preserved after each insertion. Generally this is a post-insertion\n",
            "determine that it wasn’t present in the heap. Factoring in what we know about\n",
            "use of the properties presented by a certain heap strategy.\n",
            "provide an answer without traversing the rest of the heap. If this property is\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "item at the head of a singly linked list, removal is simply a case of returning\n",
            "of EnqueueFront. The following list identiﬁes operations that are commonly\n",
            "the shape of a tree while preserving standard BST properties. There are left and\n",
            "BST properties are preserved\n",
            "BST properties are preserved\n",
            "Pre:\n",
            "list\n",
            "solution is presented because it too is trivial to implement and doesn’t suﬀer\n",
            "Pre:\n",
            "Pre:\n",
            "in the former case swap founded item with its predecessor\n",
            "available to you. In most cases using a list or any other primarily linear data\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "Pre:\n",
            "Pre:\n",
            "listed points can be managed by using three variables:\n",
            "Pre:\n",
            "number of stings contained in the array returned from the split operation. The\n",
            "split operation that we refer to is the same as that mentioned in §11.3.\n",
            "Pre:\n",
            "characters in another string is pretty trivial. Put simply, we can parse the strings\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "to inject the correct code to handle such situations to preserve the correctness of\n",
            "sometimes be a companies prerequisite to checking in code, e.g. upon checking\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n",
            "The following list identiﬁes testing frameworks which are popular:\n"
        ],
        "label": 0
    },
    "nodetoremove left nodetoremove right": {
        "abstracts": [
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "parent.Left ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "Right\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "parent.Left ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "left\n",
            "right\n",
            "4. right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "list pre list": {
        "abstracts": [
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n"
        ],
        "label": 0
    },
    "list increment list increment": {
        "abstracts": [
            "i−= increment\n",
            "list\n"
        ],
        "label": 0
    },
    "number digit number": {
        "abstracts": [],
        "label": 0
    },
    "scope end end end": {
        "abstracts": [],
        "label": 0
    },
    "false case case": {
        "abstracts": [],
        "label": 0
    },
    "binary search tree": {
        "abstracts": [
            "into smaller chunks per each invocation, e.g. searching a binary search\n",
            "tree.\n",
            "Binary Search Tree\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "structures that derive from BinarySearchTree.\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "tree:\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n",
            "name for binary search, binary chop usually refers to its array counterpart) as\n"
        ],
        "label": 0
    },
    "set2 pre list pre": {
        "abstracts": [
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "list\n"
        ],
        "label": 0
    },
    "linked list traversing": {
        "abstracts": [
            "Linked Lists\n",
            "linked list.\n",
            "Searching a linked list is straightforward: we simply traverse the list checking\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "of the node is yielded after traversing both subtrees. An example of postorder\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "traversing.\n",
            "Traversal\n",
            "property only holds for the subtree of each node and so traversing a heap in\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "list\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n"
        ],
        "label": 0
    },
    "value yield root value": {
        "abstracts": [
            "yield curr.Value\n",
            "yield curr.Value\n",
            "root ←node(value)\n",
            "3. value < root.Value, we must inspect the left subtree of root for value; or\n",
            "4. value > root.Value, we must inspect the right subtree of root for value.\n",
            "else if value < root.Value\n",
            "if value = root.Value\n",
            "if value < root.Value\n",
            "else if value < root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "root ←node(value)\n",
            "value\n",
            "1. value\n",
            "value\n",
            "yield\n"
        ],
        "label": 0
    },
    "root right postorder postorder": {
        "abstracts": [
            "no right subtree\n",
            "Postorder\n",
            "Right\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "problem algorithm algorithm": {
        "abstracts": [
            "algorithms.\n",
            "1) algorithm AlgorithmName(arg1, arg2, ..., argN)\n",
            "1) algorithm AlgorithmName(n)\n",
            "Algorithms\n"
        ],
        "label": 0
    },
    "mentation case yield overwhelming": {
        "abstracts": [
            "mentation. This in some cases will yield an overwhelming list of concerns which\n",
            "yield\n"
        ],
        "label": 0
    },
    "number item heap heap": {
        "abstracts": [
            "Heap\n",
            "The heap\n",
            "mum number of items the deque would contain at any one time. Unfortunately\n",
            "Numeric\n"
        ],
        "label": 0
    },
    "chapter avl": {
        "abstracts": [
            "Chapter 1\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "end: chapters can be read independently from one another. We suggest that\n",
            "in part 1 you read each chapter in its entirety, but in part 2 you can get away\n",
            "with just reading the section of a chapter that describes the algorithm you are\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Chapter 3\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "The run times presented in this chapter are based on a pretty big assumption\n",
            "Chapter 4\n",
            "This chapter is very much centred around the notion of representing a tree as\n",
            "an array and because this property is key to understanding this chapter Figure\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "CHAPTER 4. HEAP\n",
            "Chapter 5\n",
            "CHAPTER 5. SETS\n",
            "CHAPTER 5. SETS\n",
            "CHAPTER 5. SETS\n",
            "Chapter 6\n",
            "CHAPTER 6. QUEUES\n",
            "Unlike the queues we have talked about previously in this chapter a double\n",
            "CHAPTER 6. QUEUES\n",
            "CHAPTER 6. QUEUES\n",
            "CHAPTER 6. QUEUES\n",
            "CHAPTER 6. QUEUES\n",
            "In this chapter we have also seen priority queues where those at the front\n",
            "Chapter 7\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "Chapter 8\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "CHAPTER 8. SORTING\n",
            "Chapter 9\n",
            "CHAPTER 9. NUMERIC\n",
            "CHAPTER 9. NUMERIC\n",
            "CHAPTER 9. NUMERIC\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "Chapter 10\n",
            "CHAPTER 10. SEARCHING\n",
            "In this chapter we have presented a few novel searching algorithms. We have\n",
            "CHAPTER 10. SEARCHING\n",
            "Chapter 11\n",
            "Strings have their own chapter in this text purely because string operations\n",
            "CHAPTER 11. STRINGS\n",
            "or not. These pointers march in towards each other always checking that each\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "In this chapter we will show you how to work through both iterative, and\n",
            "As you can see from the example used in this chapter we have tried to make the\n",
            "have mentioned previously in this chapter.\n",
            "Unit testing which will be the subject of the vast majority of this chapter\n"
        ],
        "label": 0
    },
    "rotation algorithm symmetric": {
        "abstracts": [
            "algorithms.\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "Rotation\n",
            "Rotation\n",
            "The right and left rotation algorithms are symmetric.\n",
            "Algorithms\n",
            "Iterative algorithms\n"
        ],
        "label": 0
    },
    "sort algorithm fairly eﬃcient": {
        "abstracts": [
            "algorithms.\n",
            "Algorithms\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "eﬃcient.\n"
        ],
        "label": 0
    },
    "list list pre value": {
        "abstracts": [
            "list\n",
            "value\n",
            "1. value\n",
            "value\n"
        ],
        "label": 0
    },
    "introduction book": {
        "abstracts": [
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Finally in this brief introduction to sets we will cover set intersection and\n",
            "along a little with our introductory algorithms you can devise some of your own.\n",
            "advantage of iterative solutions is speed. Most production software you will\n",
            "the production code.\n"
        ],
        "label": 0
    },
    "enqueue 10": {
        "abstracts": [
            "and then a queue to store those nodes that have yet to be visited.\n",
            "q.Enqueue(root.Left)\n",
            "q.Enqueue(root.Right)\n",
            "Queues\n",
            "ﬁrst put into the queue will be the ﬁrst served, the second item added to the\n",
            "queue; when you add an item to the queue that item is placed at the back of\n",
            "Enqueue: places an item at the back of the queue;\n",
            "Dequeue: retrieves the item at the front of the queue, and removes it from the\n",
            "queue;\n",
            "Peek: 1 retrieves the item at the front of the queue without removing it from\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "the operations performed upon the queue in Figure 6.1:\n",
            "1. Enqueue(10)\n",
            "2. Enqueue(12)\n",
            "3. Enqueue(9)\n",
            "4. Enqueue(8)\n",
            "5. Enqueue(3)\n",
            "8. Enqueue(33)\n",
            "section we will discuss how you can, if required, implement an eﬃcient queue\n",
            "front of the queue. The queue data structure can be eﬃciently implemented\n",
            "of queues (with the Dequeue operation). Since we always have a pointer to the\n",
            "(deﬁned in §4). Using a heap we can look at the ﬁrst item in the queue by simply\n",
            "Unlike the queues we have talked about previously in this chapter a double\n",
            "Deque’s provide front and back speciﬁc versions of common queue operations,\n",
            "e.g. you may want to enqueue an item to the front of the queue rather than\n",
            "of EnqueueFront. The following list identiﬁes operations that are commonly\n",
            "• EnqueueFront\n",
            "• EnqueueBack\n",
            "1. EnqueueBack(12)\n",
            "2. EnqueueFront(1)\n",
            "3. EnqueueBack(23)\n",
            "4. EnqueueFront(908)\n",
            "normal queues, e.g. EnqueueBack may simply be called Enqueue an so on. Some\n",
            "a scenario you can safely assume that the Add method will simply enqueue an\n",
            "That is enqueueing an item to the back of a the queue is\n",
            "O(1), additionally enqueuing an item to the front of the queue is also an O(1)\n",
            "ever so useful; for example the Windows CPU scheduler uses a diﬀerent queue\n",
            "you are only interested in the item at the front of the queue. Despite that,\n",
            "searching is usually exposed on queues and typically the run time is linear.\n",
            "of the queue have the highest priority and those near the back have the lowest.\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "queues ←Queue[10]\n",
            "queues[GetQueueIndex(item, indexOfKey)].Enqueue(item)\n"
        ],
        "label": 0
    },
    "algorithm add": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "data structures and algorithms.\n",
            "themselves based on the concepts by which the respective algorithms are based\n",
            "that contains formal proofs of the algorithms in question. In this book we use\n",
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "measurement by which we can judge the performance of algorithms without\n",
            "Figure 1.1: Algorithmic run time expansion\n",
            "choose an eﬃcient algorithm. For the sanity of our graph we have omitted cubic\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "O(log n) logarithmic: normally associated with algorithms that break the problem\n",
            "O(n log n) just n log n: usually associated with an algorithm that breaks the problem\n",
            "really a signal for you to review the design of your algorithm. While prototyp-\n",
            "ing algorithm designs you may just have the intention of solving the problem\n",
            "review your algorithm design and optimise where possible—particularly loops\n",
            "algorithms.\n",
            "sentially discard things like hardware. If you have two sorting algorithms, one\n",
            "logarithmic algorithm will always be faster than the quadratic one when the\n",
            "a key factor in algorithm analysis: growth. An algorithm with a quadratic run\n",
            "some point as n →∞the logarithmic algorithm will become faster than the\n",
            "quadratic algorithm.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "algorithms and how they work. Does this give you a good idea of how fast each\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "about the high level algorithm design rather than its eﬃciency. Replay the scene\n",
            "back in your head, but this time as well as talking about algorithm design each\n",
            "respective developer states the asymptotic run time of their algorithm. Using\n",
            "the latter approach you not only get a good general idea about the algorithm\n",
            "when it comes to selecting an algorithm ﬁt for purpose.\n",
            "time should not exceed n ms. The eﬃciency of every algorithm that is invoked\n",
            "management via garbage collection algorithms. It is trivial to port our imple-\n",
            "language. In particular, we never provide data structures or algorithms that\n",
            "the sorting algorithms.\n",
            "2. Post-conditions represent the result of applying algorithm a to data struc-\n",
            "If an algorithm has a return type it will often be presented in the post-\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "All algorithms start with a simple algorithm signature, e.g.\n",
            "1) algorithm AlgorithmName(arg1, arg2, ..., argN)\n",
            "n) end AlgorithmName\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "1) algorithm AlgorithmName(n)\n",
            "n) end AlgorithmName\n",
            "The example above describes an algorithm by the name of AlgorithmName,\n",
            "the algorithm signature; you should always enforce the pre-conditions of an\n",
            "algorithm when porting them to your language of choice.\n",
            "Normally what is listed as a pre-conidition is critical to the algorithms opera-\n",
            "describes the eﬀect of the algorithms operation. An example of a post-condition\n",
            "tell the caller why the algorithm has failed to execute normally.\n",
            "order to get the most out of this book you work through each algorithm with a\n",
            "The best way to work through algorithms is to set up a table, and in that\n",
            "throughout the algorithm.\n",
            "Often while working through algorithms in such\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "with just reading the section of a chapter that describes the algorithm you are\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "For all readers we recommend that before looking at any algorithm you\n",
            "used within our algorithms and their meaning. One keyword that we would like\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "driven development style on paper to ﬂesh out the pseudocode algorithm. We\n",
            "all the test cases have been progressively satisﬁed we consider that algorithm\n",
            "For the most part algorithms have fairly obvious cases which need to be\n",
            "to satisfy. With such algorithms we will point out the test cases which are tricky\n",
            "and the corresponding portions of pseudocode within the algorithm that satisfy\n",
            "intuitively identify areas which may cause problems for your algorithms imple-\n",
            "will hinder your ability to design an algorithm greatly. When you are bom-\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "1. Understand how the algorithm works ﬁrst in an abstract sense; and\n",
            "2. Always work through the algorithms on paper to understand how they\n",
            "1) algorithm Add(value)\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "algorithm listed in this section is very similar to that used for traversal in §2.1.4.\n",
            "1) algorithm Contains(head, value)\n",
            "The algorithm whose cases we have described will remove a node from any-\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "1) algorithm Remove(head, value)\n",
            "The algorithm described is a very simple one that makes use of a simple\n",
            "1) algorithm Traverse(head)\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "The only major diﬀerence between the algorithm in §2.1.1 is that we need to\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(head, value)\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "up front; exceeding that size involves invoking a resizing algorithm which has\n",
            "count during the insertion and deletion algorithms.\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "cases we invoke the recursive InsertNode algorithm which simply guides us to\n",
            "but we will look brieﬂy at the premise of the algorithm nonetheless.\n",
            "1) algorithm Contains(root, value)\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "1) algorithm Remove(value)\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "algorithm is very useful, especially when performing extensive tree transforma-\n",
            "1) algorithm FindParent(value, root)\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "exist in the BST, in which case we return ∅. Callers to this algorithm must take\n",
            "This algorithm is very similar to §3.4, but instead of returning a reference to the\n",
            "1) algorithm FindNode(root, value)\n",
            "Astute readers will have noticed that the FindNode algorithm is exactly the\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "The base case in both FindMin, and FindMax algorithms is when the Left\n",
            "1) algorithm FindMin(root)\n",
            "1) algorithm FindMax(root)\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "1) algorithm Preorder(root)\n",
            "This algorithm is very similar to that described in §3.7.1, however the value\n",
            "1) algorithm Postorder(root)\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "1) algorithm Inorder(root)\n",
            "1) algorithm BreadthFirst(root)\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Designing an algorithm for heap insertion is simple, but we must ensure that\n",
            "algorithm; the second is validating heap order. In the case of min-heap ordering\n",
            "by product of verifying heap order as the ﬁrst part of the algorithm (the actual\n",
            "1) algorithm Add(value)\n",
            "1) algorithm MinHeapify()\n",
            "The design of the MaxHeapify algorithm is very similar to that of the Min-\n",
            "Heapify algorithm, the only diﬀerence is that the < operator in the second\n",
            "preserved. The algorithm for deletion has three steps:\n",
            "1) algorithm Remove(value)\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "1) algorithm Contains(value)\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "the heap we can optimise the search algorithm by including logic which makes\n",
            "not satisﬁed for any level of nodes that we are inspecting then the algorithm\n",
            "The following algorithm is speciﬁcally designed for a min-heap. To tailor the\n",
            "algorithm for a max-heap the two comparison operations in the else if condition\n",
            "1) algorithm Contains(value)\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "bound of the heap. You will note that in the search algorithm that we use Count\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "that upon each insertion and deletion we invoke algorithms that have logarithmic\n",
            "where such algorithms exist as extension methods deﬁned in the type Sys-\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "1) algorithm Union(set1, set2)\n",
            "The run time of our Union algorithm is O(m + n) where m is the number\n",
            "pointing out about our algorithm is that we traverse the set containing the\n",
            "1) algorithm Intersection(set1, set2)\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "of items in the smaller of the two sets. Just like our Union algorithm a linear\n",
            "The above depends on how good the hashing algorithm of the hash table\n",
            "algorithms and so the run time complexities for the hash table in your library\n",
            "We can use sets to facilitate many algorithms that would otherwise be a little\n",
            "set to assist in the construction of an algorithm that determines the number of\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "With respect to algorithmic run time complexities a deque is the same as\n",
            "incur the expense of invoking a resizing algorithm which would most likely be\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "An algorithm described\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "invocation of the garbage collection algorithm. With C++ or any other lan-\n",
            "1) algorithm LeftRotation(node)\n",
            "1) algorithm RightRotation(node)\n",
            "The right and left rotation algorithms are symmetric.\n",
            "The algorithm that we present in this section veriﬁes that the left and right\n",
            "Notice that we use two new algorithms that represent double rotations.\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "1) algorithm CheckBalance(current)\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "Our balancing algorithm is like the one presented for our BST (deﬁned in §3.3).\n",
            "1) algorithm Remove(value)\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n",
            "Algorithms\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "1) algorithm BubbleSort(list)\n",
            "Merge sort is an algorithm that has a fairly eﬃcient space time complexity -\n",
            "O(n log n) and is fairly trivial to implement. The algorithm is based on splitting\n",
            "1) algorithm Mergesort(list)\n",
            "Quick sort is one of the most popular sorting algorithms based on divide et\n",
            "impera strategy, resulting in an O(n log n) complexity. The algorithm starts by\n",
            "1) algorithm QuickSort(list)\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "1) algorithm Insertionsort(list)\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "1) algorithm ShellSort(list)\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "1) algorithm Radix(list, maxKeySize)\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "Figure 8.6: Radix sort base 10 algorithm\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "implementing recursive algorithms see Appendix C.\n",
            "A simple algorithm that determines whether or not a given integer is a prime\n",
            "1) algorithm IsPrime(n)\n",
            "DSA contains a number of algorithms that convert a base 10 number to its\n",
            "Table 9.1 shows the algorithm trace when the number to convert to binary\n",
            "1) algorithm ToBinary(n)\n",
            "Table 9.1: Algorithm trace of ToBinary\n",
            "algorithm that has a run time complexity of O(n2).\n",
            "1) algorithm GreatestCommonDenominator(m, n)\n",
            "This algorithm computes the maximum value of a number for a given number\n",
            "In the following algorithm numberBase should be considered restricted to\n",
            "algorithm can be modelled in a more readable manner rather than using various\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "1) algorithm MaxValue(numberBase, n)\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "1) algorithm Factorial(n)\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "algorithms in particular drive some of the most advanced systems on the planet\n",
            "A simple algorithm that search for a speciﬁc item inside a list.\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "Probability search is a statistical sequential searching algorithm. In addition to\n",
            "it’s predecessor in the list. The algorithm complexity still remains at O(n) but\n",
            "1) algorithm ProbabilitySearch(list, item)\n",
            "In this chapter we have presented a few novel searching algorithms. We have\n",
            "presented more eﬃcient searching algorithms earlier on, like for instance the\n",
            "logarithmic searching algorithm that AVL and BST tree’s use (deﬁned in §3.2).\n",
            "We decided not to cover a searching algorithm known as binary chop (another\n",
            "the reader has already seen such an algorithm in §3.\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "and transformations are incredibly frequent within programs. The algorithms\n",
            "Deﬁning algorithms for primitive string operations is simple, e.g. extracting a\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "string, rather it reverses the order of words within a string. This algorithm\n",
            "1) algorithm ReverseWords(value)\n",
            "Although not a frequent algorithm that will be applied in real-life scenarios\n",
            "detecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\n",
            "The algorithm that we present has a O(n) run time complexity. Our algo-\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "1) algorithm IsPalindrome(value)\n",
            "In the IsPalindrome algorithm we call a method by the name of Strip. This\n",
            "algorithm discards punctuation in the string, including white space. As a result\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "What denotes a word? In our algorithm each word is separated by one or\n",
            "1) algorithm WordCount(value)\n",
            "With the help of an unordered set, and an algorithm that can split the words\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "1) algorithm RepeatedWordCount(value)\n",
            "You will notice in the RepeatedWordCount algorithm that we use the Strip\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "1) algorithm Any(word,match)\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "along a little with our introductory algorithms you can devise some of your own.\n",
            "Algorithm Walkthrough\n",
            "Learning how to design good algorithms can be assisted greatly by using a\n",
            "structured approach to tracing its behaviour. In most cases tracing an algorithm\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "rithm. The values within this table are constantly updated when the algorithm\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "generated by the algorithm it can make understanding, and solving problems\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "these strings with array indexes to aid the algorithm walkthrough.\n",
            "variables whose values change during the algorithm. We recommend that you\n",
            "Table A.2: Algorithm trace for IsPalindrome\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "your algorithm. You can use these trace tables to verify algorithm correctness.\n",
            "operating on you can devise correct algorithms quicker. Visualising the problem\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "of an algorithm that computes a number from the Fiboncacci sequence.\n",
            "1) algorithm Fibonacci(n)\n",
            "rithm calls for the Fibonacci algorithm we will brieﬂy talk about the cases of\n",
            "the algorithm. The algorithm has three cases in total:\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "Figure A.2: Call chain for Fibonacci algorithm\n",
            "Figure A.3: Return chain for Fibonacci algorithm\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "In the Fibonacci algorithms’ recursive case we make two recursive calls.\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "Understanding algorithms can be hard at times, particularly from an implemen-\n",
            "tation perspective. In order to understand an algorithm try and work through\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "that you know how the algorithm works. Mastering how an algorithm works\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "may have to inject various calls to other utility algorithms to ascertain the\n",
            "A consideration to take note of is that many algorithms have fairly strict\n",
            "the algorithm. Most of the preconditions can be suitably handled by throwing\n",
            "translation of our pseudo code algorithms to mainstream imperative languages\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "you might want to use such an approach for your algorithms we will now talk\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "Using recursion should always be reserved for fast algorithms, you should\n",
            "avoid it for the following algorithm run time deﬁciencies:\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "most cases such algorithms will lean very heavily on techniques like divide and\n",
            "cause your algorithm to run a lot slower than expected, or worse, you will run\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "algorithm that when invoked given a speciﬁc value it creates many recursive\n",
            "Recursive algorithms can exhaust the stack size\n",
            "an iterative vs. recursive solution in the form of the Fibonacci algorithm. This\n",
            "algorithm. The iterative solution is not as pretty, nor self documenting but it\n",
            "does the job a lot quicker. If we were to give the Fibonacci algorithm an input\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "We can also look at sorting algorithms like merge sort, and quick sort. Both\n",
            "of these algorithms are recursive in their design and so it makes sense to model\n",
            "an algorithm with a quadratic run time or higher. Of course this is not a rule\n",
            "algorithms which are recursive in nature. Using recursion in such scenarios is\n",
            "you add or tweak algorithms and then run your suite of tests you will be quickly\n",
            "implementation of algorithms. At any one stage you only have a single goal, to\n",
            "to building a solution. If you adhere to progressive revisions of your algorithm\n"
        ],
        "label": 0
    },
    "height current right height": {
        "abstracts": [
            "if current.Right = ∅\n",
            "Right\n",
            "current.Height = Max(Height(current.Left),Height(current.Right)) + 1\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "if Height(current.Right.Left) - Height(current.Right.Right) < 0\n",
            "if current.Right = ∅\n",
            "right ←right −1\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "end inword end end": {
        "abstracts": [
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "Inorder\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "3. inWord\n",
            "end if\n",
            "end if\n",
            "if inWord\n",
            "end if\n",
            "Word\n",
            "end if\n",
            "word\n",
            "word\n",
            "end if\n"
        ],
        "label": 0
    },
    "method return address popped": {
        "abstracts": [
            "ture d\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "• The return address is pushed onto the stack\n",
            "2. The return address is popped oﬀthe stack\n"
        ],
        "label": 0
    },
    "left enqueue": {
        "abstracts": [
            "q ←queue\n",
            "Queues\n",
            "the queue.\n",
            "queue;\n",
            "the queue\n",
            "e.g. you may want to enqueue an item to the front of the queue rather than\n",
            "of EnqueueFront. The following list identiﬁes operations that are commonly\n",
            "normal queues, e.g. EnqueueBack may simply be called Enqueue an so on. Some\n",
            "a scenario you can safely assume that the Add method will simply enqueue an\n",
            "That is enqueueing an item to the back of a the queue is\n",
            "ever so useful; for example the Windows CPU scheduler uses a diﬀerent queue\n",
            "Left\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "index index": {
        "abstracts": [
            "deﬁned as follows for a node at index:\n",
            "need to keep track of the next free index in the array as a counter, and increment\n",
            "index ←FindIndex(heap, value)\n",
            "you traverse the array starting at the initial array index (0 in most languages)\n",
            "For this example we can further assume that at some point the items in indexes\n",
            "queues[GetQueueIndex(item, indexOfKey)].Enqueue(item)\n",
            "index ←index + 1\n",
            "return index\n",
            "index ←index + 1\n",
            "1. index\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index\n",
            "index\n",
            "index\n",
            "index ←index + 1\n",
            "return index\n",
            "• The top-of-stack index is incremented by the total amount of memory\n",
            "1. The top-of-stack index is decremented by the total amount of memory\n",
            "3. The top-of-stack index is decremented by the total amount of memory\n"
        ],
        "label": 0
    },
    "false return true": {
        "abstracts": [
            "If an algorithm has a return type it will often be presented in the post-\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return true;\n"
        ],
        "label": 0
    },
    "10 11": {
        "abstracts": [
            "the integers 5, 10, 1, and 40.\n",
            "representation of 10011102.\n"
        ],
        "label": 0
    },
    "order post list sorted": {
        "abstracts": [
            "list\n"
        ],
        "label": 0
    },
    "return keyword cause": {
        "abstracts": [
            "The return keyword causes the method to exit and returns control to the caller,\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return wordCount\n",
            "Word\n",
            "return −1\n",
            "word\n",
            "word\n",
            "return 0\n",
            "return 1\n"
        ],
        "label": 0
    },
    "oh notation extensively": {
        "abstracts": [
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "Rotation\n",
            "Rotation\n"
        ],
        "label": 0
    },
    "make thing complex follow": {
        "abstracts": [
            "simply makes things more complex to follow. Track everything in a simple and\n"
        ],
        "label": 0
    },
    "false return false": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "chapter introduction": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "tions.\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "tions.\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Finally in this brief introduction to sets we will cover set intersection and\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n",
            "tions.\n",
            "a PersonTest type. Typically all tests are abstracted from production code.\n"
        ],
        "label": 0
    },
    "list index item end": {
        "abstracts": [
            "list\n",
            "if index < list.Count and list[index] = item\n",
            "index\n",
            "index\n",
            "index\n"
        ],
        "label": 0
    },
    "selecting correct sorting": {
        "abstracts": [
            "Sorting\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n"
        ],
        "label": 0
    },
    "false case": {
        "abstracts": [
            "in complex cases it can lead to ambiguity.\n",
            "conditions to be exceptional cases. We provide a message in the exception to\n",
            "mentation. This in some cases will yield an overwhelming list of concerns which\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "The algorithm whose cases we have described will remove a node from any-\n",
            "recursive) checks a very core base case - whether or not the tree is empty. If\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "nating when you ﬁnd a node with no left subtree. The opposite is the case when\n",
            "The base case in both FindMin, and FindMax algorithms is when the Left\n",
            "If this is the case then 5 cannot be in the heap and so we can\n",
            "the loop is justiﬁed to prevent the expensive worse case run time.\n",
            "This is the case in .NET 3.51\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "The factorial of 0 and 1 is 0. The aforementioned acts as a base case that we\n",
            "there are a few cases that we need to be aware of:\n",
            "a table based approach. In this section we will use a recursive implementation\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "Until we hit one of our base cases in our recursive method call tree we won’t\n",
            "return anything. The third item from the list is our recursive case.\n",
            "With each call to the recursive case we etch ever closer to one of our base\n",
            "upon hitting one of the two base cases. When you do eventually hit a base case\n",
            "that branch of recursive calls ceases. Upon hitting a base case you go back to\n",
            "In the Fibonacci algorithms’ recursive case we make two recursive calls.\n",
            "1. One or more base cases; and\n",
            "2. A recursive case\n",
            "each recursive call we should be making progress to our base case otherwise we\n",
            "practice, in these cases you are going to be spawning a lot of method calls. All\n",
            "process will be shutdown by the operating system. This is the case irrespective\n"
        ],
        "label": 0
    },
    "figure 11": {
        "abstracts": [
            "Figure 1.1: Algorithmic run time expansion\n",
            "Figure 1.1 shows some of the run times to demonstrate how important it is to\n",
            "Figure 2.1: Singly linked list node\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "Figure 2.2.\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "Figure 2.3: Reverse traveral of a singly linked list\n",
            "Figure 2.4: Doubly linked list node\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "is shown in Figure 3.3.\n",
            "traversal is shown in Figure 3.4.\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "in Figure 3.5.\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "example of breadth ﬁrst traversal is shown in Figure 3.6.\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "most two children. Figure 4.1 shows how the tree (not a heap data structure)\n",
            "(12 7(3 2) 6(9 )) would be represented as an array. The array in Figure 4.1 is a\n",
            "result of simply adding values in a top-to-bottom, left-to-right fashion. Figure\n",
            "an array and because this property is key to understanding this chapter Figure\n",
            "In Figure 4.3 you can assume that the default capacity of our array is eight.\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "Figure 4.2: Direct children of the nodes in an array representation of a tree data\n",
            "Figure 4.1 does not specify how we would handle adding null references to\n",
            "In Figure 4.4 a) represents the calculation of the right child of 12 (2 ∗0 + 2);\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "Figure 4.4: Calculating node properties\n",
            "Figure 4.5 shows the steps of inserting the values 3, 9, 12, 7, and 1 into a\n",
            "Figure 4.5: Inserting values into a min-heap\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "containing the values 1, 3, 9, 12, and 13. In Figure 4.6 you can assume that we\n",
            "Figure 4.6: Deleting an item from a heap\n",
            "is no possible way that value is in the heap. As an example consider Figure 4.7.\n",
            "Figure 4.7: Determining 10 is not in the heap after inspecting the nodes of Level\n",
            "Figure 4.8: Living and dead space in the heap backing array\n",
            "Figure 4.8 shows a heap that you can assume has been mutated many times.\n",
            "In Figure 4.8\n",
            "A or x ∈B}, and intersection A ∩B = {x | x ∈A and x ∈B}. Figure 5.1\n",
            "Figure 5.1: a) A ∩B; b) A ∪B\n",
            "the operations performed upon the queue in Figure 6.1:\n",
            "Figure 6.1: Queue mutations\n",
            "Figure 6.2 shows a deque after the invocation of the following methods (in-\n",
            "Figure 6.2: Deque data structure after several mutations\n",
            "subtrees cannot be no more than one, see Figure 7.1. This condition, restored\n",
            "The BST in Figure 7.2 represents the worst case scenario in which the run-\n",
            "Figure 7.1: The left and right subtrees of an AVL tree diﬀer in height by at\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "Figure 7.3: Avl trees, insertion order: -a)1,2,3,4,5 -b)1,5,4,3,2\n",
            "Figure 7.4: Tree left and right rotations\n",
            "Figure 8.1: Bubble Sort Iterations\n",
            "Figure 8.2: Merge Sort Divide et Impera Approach\n",
            "Figure 8.3: Quick Sort Example (pivot median strategy)\n",
            "Figure 8.4: Insertion Sort Iterations\n",
            "compare. Figure 8.5 shows shell sort being ran on an array of integers, the red\n",
            "Figure 8.5: Shell sort\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "are interested in for each number is highlighted. Omitted queues in Figure 8.6\n",
            "Figure 8.6: Radix sort base 10 algorithm\n",
            "Figure 10.1 shows the resulting state of a list after searching for two items,\n",
            "Figure 10.1: a) Search(12), b) Search(101)\n",
            "character they point to is the same with respect to value. Figure 11.1 shows the\n",
            "Figure 11.1: left and right pointers marching in towards one another\n",
            "Figure 11.2: String with three words\n",
            "Figure 11.3: String with varying number of white space delimiting the words\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "Figure 11.3 shows the same string, with the same number of words but with\n",
            "Figure 11.4: a) Undesired uniques set; b) desired uniques set\n",
            "are the same word minus the punctuation. Figure 11.4 shows the undesired and\n",
            "location of the ﬁrst character in the match (Figure 11.5); otherwise we return\n",
            "Figure 11.5: a) First Step; b) Second Step c) Match Occurred\n",
            "in Figure A.1.\n",
            "Figure A.1: Visualising the data structure we are operating on\n",
            "to a larger diagram (like that in Figure A.1) and only use the trace table for\n",
            "cases. Figure A.2 shows a diagrammtic representation of the recursive call chain.\n",
            "In Figure A.2 the order in which the methods are called are labelled. Figure\n",
            "as well as the order in which methods return to their callers. In Figure A.3 the\n",
            "Figure A.2: Call chain for Fibonacci algorithm\n",
            "Figure A.3: Return chain for Fibonacci algorithm\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n"
        ],
        "label": 0
    },
    "set eﬃciently implemented using": {
        "abstracts": [
            "An unordered set can be eﬃciently implemented using a hash table as its backing\n",
            "front of the queue. The queue data structure can be eﬃciently implemented\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "eﬃcient.\n"
        ],
        "label": 0
    },
    "like nunit used language": {
        "abstracts": [],
        "label": 0
    },
    "deletion algorithm remove": {
        "abstracts": [
            "algorithms.\n",
            "Deletion\n",
            "Deletion\n",
            "count during the insertion and deletion algorithms.\n",
            "Deletion\n",
            "Deletion\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "The right and left rotation algorithms are symmetric.\n",
            "Deletion\n",
            "Algorithms\n"
        ],
        "label": 0
    },
    "value parent greater": {
        "abstracts": [
            "Part I\n",
            "this requires us to swap the values of a parent and its child if the value of the\n",
            "else if value > Parent(heap[start]) and value < heap[start]\n",
            "parent is greater than that of each of its children.\n",
            "parent ←∅\n",
            "value\n",
            "value\n"
        ],
        "label": 0
    },
    "oh notation big": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "1. Big Oh notation\n",
            "Big Oh notation\n",
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "The following list explains some of the most common big Oh notations:\n",
            "The biggest asset that big Oh notation gives us is that it allows us to es-\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "Big Oh notation also acts as a communication tool. Picture the scene: you\n",
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "right rotations both of them decrease the height of a BST by moving smaller\n",
            "Rotation\n",
            "Rotation\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n"
        ],
        "label": 0
    },
    "optimisation compiler": {
        "abstracts": [
            "will indeed fall back to inspecting all the nodes in the heap. The optimisation\n",
            "commercial compilers will do this. The amount of optimisation compilers can\n"
        ],
        "label": 0
    },
    "performs left rotation": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "Tree Rotations\n",
            "Rotation\n",
            "Left\n",
            "Rotation\n",
            "1) algorithm LeftRotation(node)\n",
            "ﬁrst performs a left rotation and then subsequently a right rotation.\n",
            "rotation(s).\n",
            "from a word. The reason we perform this operation on each word is so that\n",
            "left\n",
            "left\n",
            "tions.\n"
        ],
        "label": 0
    },
    "right sorting": {
        "abstracts": [
            "Right\n",
            "Sorting\n",
            "to demonstrate sorting, e.g.\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "yield root value return": {
        "abstracts": [
            "yield curr.Value\n",
            "yield curr.Value\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "return ∅\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "value\n",
            "value\n",
            "return 0\n",
            "return 1\n",
            "yield\n"
        ],
        "label": 0
    },
    "factorial number": {
        "abstracts": [
            "integers that are a member of the natural numbers set N, where N = {1, 2, 3, ...}.\n",
            "Numeric\n",
            "for a hexadecimal number (base 16) consisting of 6 digits the expression would\n",
            "factorial ←1\n"
        ],
        "label": 0
    },
    "return list return list": {
        "abstracts": [
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "inword end end": {
        "abstracts": [
            "Inorder\n",
            "Word\n",
            "word\n",
            "word\n"
        ],
        "label": 0
    },
    "algorithm remove value": {
        "abstracts": [
            "algorithms.\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(value)\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "1) algorithm MaxValue(numberBase, n)\n",
            "value\n",
            "1. value\n",
            "value\n"
        ],
        "label": 0
    },
    "priority queue use heap": {
        "abstracts": [
            "Heap\n",
            "The heap\n",
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "Priority Queue\n",
            "a priority queue determines the order of its items by using a form of custom\n",
            "priority queue being ordered by priority it remains the same as a normal queue:\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "ability to construct a priority queue where the items with the highest priority\n",
            "A deque applies no prioritization strategy to its items like a priority queue\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "In this chapter we have also seen priority queues where those at the front\n",
            "One implementation of a priority queue is to use a heap data structure as its\n"
        ],
        "label": 0
    },
    "rotation algorithm symmetric changed": {
        "abstracts": [
            "algorithms.\n",
            "Rotation\n",
            "Rotation\n",
            "The right and left rotation algorithms are symmetric.\n",
            "Algorithms\n",
            "Iterative algorithms\n"
        ],
        "label": 0
    },
    "right root dequeue enqueue": {
        "abstracts": [
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "• EnqueueBack\n",
            "Right\n",
            "queues ←Queue[10]\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "linked list": {
        "abstracts": [
            "The following list explains some of the most common big Oh notations:\n",
            "a node to the tail of a linked list where we always maintain a pointer to\n",
            "use pointers for certain things. For example, when we describe a linked list\n",
            "mentation. This in some cases will yield an overwhelming list of concerns which\n",
            "This book doesn’t provide any code speciﬁcally aligned with it, however we do\n",
            "Linked Lists\n",
            "Linked lists can be thought of from a high level perspective as being a series\n",
            "linked list.\n",
            "In DSA our implementations of linked lists always maintain head and tail\n",
            "operation. As such, linked lists in DSA have the following characteristics:\n",
            "node(s) at the head and tail of the linked list and so performing a traditional\n",
            "insertion to either the front or back of the linked list is an O(1) operation. An\n",
            "the head nor tail in a singly linked list. When the node we are inserting before\n",
            "is somewhere in the middle of the linked list (known as random insertion) the\n",
            "traverse the linked list to ﬁnd that node’s current predecessor. This traversal\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "Singly Linked List\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "a reference to the next node (if any) in the list.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.1: Singly linked list node\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "In general when people talk about insertion with respect to linked lists of any\n",
            "Adding a node to a singly linked list has only two cases:\n",
            "Searching a linked list is straightforward: we simply traverse the list checking\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Post: the item is either in the linked list, true; otherwise false\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "6. the item to remove doesn’t exist in the linked list\n",
            "the front of the linked list deletion becomes an O(1) operation.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Traversing a singly linked list is the same as that of traversing a doubly linked\n",
            "1. node = ∅, we have exhausted all nodes in the linked list; or\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Post: the items in the list have been traversed\n",
            "Traversing a singly linked list in a forward manner (i.e. left to right) is simple\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "characteristics of the nodes that make up a singly linked list make this an\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "Post: the items in the list have been traversed in reverse order\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "as you will soon see that doubly linked lists (deﬁned in §2.2) make reverse list\n",
            "Doubly Linked List\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "that each node has a reference to both the next and previous nodes in the list.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.3: Reverse traveral of a singly linked list\n",
            "Figure 2.4: Doubly linked list node\n",
            "CHAPTER 2. LINKED LISTS\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "those listed previously for the singly linked list:\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Singly linked lists have a forward only design, which is why the reverse traversal\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "Linked lists are good to use when you have an unknown number of items to\n",
            "a linear run time. You should also use linked lists when you will only remove\n",
            "What linked lists are not very good for is random insertion, accessing nodes\n",
            "variable that tracks how many items are contained in the list so that accessing\n",
            "Singly linked lists should be used when you are only performing basic in-\n",
            "sertions. In general doubly linked lists are more accommodating for non-trivial\n",
            "operations on a linked list.\n",
            "We recommend the use of a doubly linked list when you require forwards\n",
            "In this scenario a doubly linked list is best as its design makes\n",
            "CHAPTER 2. LINKED LISTS\n",
            "list.\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "item at the head of a singly linked list, removal is simply a case of returning\n",
            "remains the same as that of a singly linked list: O(n).\n",
            "of EnqueueFront. The following list identiﬁes operations that are commonly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "linked list as its baking data structure. While a node that has two pointers\n",
            "a list, into two similar sized lists (left, and right) and sorting each list and then\n",
            "specify the maximum key size in the list is that we need a way to isolate a\n",
            "maxKeySize ≥0 and represents the largest key size in the list\n",
            "foreach item in list\n",
            "list\n",
            "it’s predecessor in the list. The algorithm complexity still remains at O(n) but\n",
            "to search a BST than it is a linked list. If you are going to search for data fairly\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n",
            "The following list identiﬁes testing frameworks which are popular:\n",
            "unit test. A popular approach - the three A’s is described in the following list:\n"
        ],
        "label": 0
    },
    "parent index index left": {
        "abstracts": [
            "Part I\n",
            "index ←left\n",
            "Left\n",
            "parent ←∅\n",
            "Part II\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index ←index + 1\n",
            "index\n",
            "index\n",
            "index\n",
            "index ←index + 1\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "sort algorithm": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "data structures and algorithms.\n",
            "themselves based on the concepts by which the respective algorithms are based\n",
            "that contains formal proofs of the algorithms in question. In this book we use\n",
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "measurement by which we can judge the performance of algorithms without\n",
            "Figure 1.1: Algorithmic run time expansion\n",
            "choose an eﬃcient algorithm. For the sanity of our graph we have omitted cubic\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "O(log n) logarithmic: normally associated with algorithms that break the problem\n",
            "O(n log n) just n log n: usually associated with an algorithm that breaks the problem\n",
            "really a signal for you to review the design of your algorithm. While prototyp-\n",
            "ing algorithm designs you may just have the intention of solving the problem\n",
            "review your algorithm design and optimise where possible—particularly loops\n",
            "algorithms.\n",
            "sentially discard things like hardware. If you have two sorting algorithms, one\n",
            "with a quadratic run time, and the other with a logarithmic run time then the\n",
            "logarithmic algorithm will always be faster than the quadratic one when the\n",
            "a key factor in algorithm analysis: growth. An algorithm with a quadratic run\n",
            "time grows faster than one with a logarithmic run time. It is generally said at\n",
            "some point as n →∞the logarithmic algorithm will become faster than the\n",
            "quadratic algorithm.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "about the high level algorithm design rather than its eﬃciency. Replay the scene\n",
            "back in your head, but this time as well as talking about algorithm design each\n",
            "respective developer states the asymptotic run time of their algorithm. Using\n",
            "the latter approach you not only get a good general idea about the algorithm\n",
            "when it comes to selecting an algorithm ﬁt for purpose.\n",
            "time should not exceed n ms. The eﬃciency of every algorithm that is invoked\n",
            "management via garbage collection algorithms. It is trivial to port our imple-\n",
            "language. In particular, we never provide data structures or algorithms that\n",
            "the sorting algorithms.\n",
            "2. Post-conditions represent the result of applying algorithm a to data struc-\n",
            "If an algorithm has a return type it will often be presented in the post-\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "All algorithms start with a simple algorithm signature, e.g.\n",
            "1) algorithm AlgorithmName(arg1, arg2, ..., argN)\n",
            "n) end AlgorithmName\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "1) algorithm AlgorithmName(n)\n",
            "n) end AlgorithmName\n",
            "The example above describes an algorithm by the name of AlgorithmName,\n",
            "the algorithm signature; you should always enforce the pre-conditions of an\n",
            "Normally what is listed as a pre-conidition is critical to the algorithms opera-\n",
            "describes the eﬀect of the algorithms operation. An example of a post-condition\n",
            "tell the caller why the algorithm has failed to execute normally.\n",
            "order to get the most out of this book you work through each algorithm with a\n",
            "The best way to work through algorithms is to set up a table, and in that\n",
            "throughout the algorithm.\n",
            "Often while working through algorithms in such\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "with just reading the section of a chapter that describes the algorithm you are\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "For all readers we recommend that before looking at any algorithm you\n",
            "used within our algorithms and their meaning. One keyword that we would like\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "driven development style on paper to ﬂesh out the pseudocode algorithm. We\n",
            "all the test cases have been progressively satisﬁed we consider that algorithm\n",
            "For the most part algorithms have fairly obvious cases which need to be\n",
            "to satisfy. With such algorithms we will point out the test cases which are tricky\n",
            "and the corresponding portions of pseudocode within the algorithm that satisfy\n",
            "intuitively identify areas which may cause problems for your algorithms imple-\n",
            "will hinder your ability to design an algorithm greatly. When you are bom-\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "1. Understand how the algorithm works ﬁrst in an abstract sense; and\n",
            "2. Always work through the algorithms on paper to understand how they\n",
            "1) algorithm Add(value)\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "1) algorithm Contains(head, value)\n",
            "The algorithm whose cases we have described will remove a node from any-\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "1) algorithm Remove(head, value)\n",
            "The algorithm described is a very simple one that makes use of a simple\n",
            "1) algorithm Traverse(head)\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "The only major diﬀerence between the algorithm in §2.1.1 is that we need to\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(head, value)\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "up front; exceeding that size involves invoking a resizing algorithm which has\n",
            "count during the insertion and deletion algorithms.\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "cases we invoke the recursive InsertNode algorithm which simply guides us to\n",
            "but we will look brieﬂy at the premise of the algorithm nonetheless.\n",
            "1) algorithm Contains(root, value)\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "1) algorithm Remove(value)\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "1) algorithm FindParent(value, root)\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "exist in the BST, in which case we return ∅. Callers to this algorithm must take\n",
            "This algorithm is very similar to §3.4, but instead of returning a reference to the\n",
            "1) algorithm FindNode(root, value)\n",
            "Astute readers will have noticed that the FindNode algorithm is exactly the\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "The base case in both FindMin, and FindMax algorithms is when the Left\n",
            "1) algorithm FindMin(root)\n",
            "1) algorithm FindMax(root)\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "1) algorithm Preorder(root)\n",
            "This algorithm is very similar to that described in §3.7.1, however the value\n",
            "1) algorithm Postorder(root)\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "1) algorithm Inorder(root)\n",
            "1) algorithm BreadthFirst(root)\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Designing an algorithm for heap insertion is simple, but we must ensure that\n",
            "by product of verifying heap order as the ﬁrst part of the algorithm (the actual\n",
            "1) algorithm Add(value)\n",
            "1) algorithm MinHeapify()\n",
            "The design of the MaxHeapify algorithm is very similar to that of the Min-\n",
            "Heapify algorithm, the only diﬀerence is that the < operator in the second\n",
            "preserved. The algorithm for deletion has three steps:\n",
            "1) algorithm Remove(value)\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "1) algorithm Contains(value)\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "the heap we can optimise the search algorithm by including logic which makes\n",
            "not satisﬁed for any level of nodes that we are inspecting then the algorithm\n",
            "The following algorithm is speciﬁcally designed for a min-heap. To tailor the\n",
            "1) algorithm Contains(value)\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "bound of the heap. You will note that in the search algorithm that we use Count\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "that upon each insertion and deletion we invoke algorithms that have logarithmic\n",
            "where such algorithms exist as extension methods deﬁned in the type Sys-\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "1) algorithm Union(set1, set2)\n",
            "The run time of our Union algorithm is O(m + n) where m is the number\n",
            "pointing out about our algorithm is that we traverse the set containing the\n",
            "1) algorithm Intersection(set1, set2)\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "of items in the smaller of the two sets. Just like our Union algorithm a linear\n",
            "The above depends on how good the hashing algorithm of the hash table\n",
            "We can use sets to facilitate many algorithms that would otherwise be a little\n",
            "set to assist in the construction of an algorithm that determines the number of\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "With respect to algorithmic run time complexities a deque is the same as\n",
            "incur the expense of invoking a resizing algorithm which would most likely be\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "An algorithm described\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "invocation of the garbage collection algorithm. With C++ or any other lan-\n",
            "1) algorithm LeftRotation(node)\n",
            "1) algorithm RightRotation(node)\n",
            "The right and left rotation algorithms are symmetric.\n",
            "The algorithm that we present in this section veriﬁes that the left and right\n",
            "Notice that we use two new algorithms that represent double rotations.\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "1) algorithm CheckBalance(current)\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "Our balancing algorithm is like the one presented for our BST (deﬁned in §3.3).\n",
            "1) algorithm Remove(value)\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n",
            "Algorithms\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "1) algorithm BubbleSort(list)\n",
            "Merge sort is an algorithm that has a fairly eﬃcient space time complexity -\n",
            "O(n log n) and is fairly trivial to implement. The algorithm is based on splitting\n",
            "1) algorithm Mergesort(list)\n",
            "Quick sort is one of the most popular sorting algorithms based on divide et\n",
            "impera strategy, resulting in an O(n log n) complexity. The algorithm starts by\n",
            "1) algorithm QuickSort(list)\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "1) algorithm Insertionsort(list)\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "1) algorithm ShellSort(list)\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "1) algorithm Radix(list, maxKeySize)\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "Figure 8.6: Radix sort base 10 algorithm\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "implementing recursive algorithms see Appendix C.\n",
            "A simple algorithm that determines whether or not a given integer is a prime\n",
            "1) algorithm IsPrime(n)\n",
            "DSA contains a number of algorithms that convert a base 10 number to its\n",
            "Table 9.1 shows the algorithm trace when the number to convert to binary\n",
            "1) algorithm ToBinary(n)\n",
            "Table 9.1: Algorithm trace of ToBinary\n",
            "1) algorithm GreatestCommonDenominator(m, n)\n",
            "This algorithm computes the maximum value of a number for a given number\n",
            "In the following algorithm numberBase should be considered restricted to\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "1) algorithm MaxValue(numberBase, n)\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "1) algorithm Factorial(n)\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "A simple algorithm that search for a speciﬁc item inside a list.\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "Probability search is a statistical sequential searching algorithm. In addition to\n",
            "it’s predecessor in the list. The algorithm complexity still remains at O(n) but\n",
            "1) algorithm ProbabilitySearch(list, item)\n",
            "In this chapter we have presented a few novel searching algorithms. We have\n",
            "presented more eﬃcient searching algorithms earlier on, like for instance the\n",
            "logarithmic searching algorithm that AVL and BST tree’s use (deﬁned in §3.2).\n",
            "We decided not to cover a searching algorithm known as binary chop (another\n",
            "the reader has already seen such an algorithm in §3.\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "and transformations are incredibly frequent within programs. The algorithms\n",
            "Deﬁning algorithms for primitive string operations is simple, e.g. extracting a\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "string, rather it reverses the order of words within a string. This algorithm\n",
            "1) algorithm ReverseWords(value)\n",
            "Although not a frequent algorithm that will be applied in real-life scenarios\n",
            "detecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\n",
            "The algorithm that we present has a O(n) run time complexity. Our algo-\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "1) algorithm IsPalindrome(value)\n",
            "In the IsPalindrome algorithm we call a method by the name of Strip. This\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "What denotes a word? In our algorithm each word is separated by one or\n",
            "1) algorithm WordCount(value)\n",
            "With the help of an unordered set, and an algorithm that can split the words\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "1) algorithm RepeatedWordCount(value)\n",
            "You will notice in the RepeatedWordCount algorithm that we use the Strip\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "1) algorithm Any(word,match)\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "along a little with our introductory algorithms you can devise some of your own.\n",
            "Learning how to design good algorithms can be assisted greatly by using a\n",
            "structured approach to tracing its behaviour. In most cases tracing an algorithm\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "rithm. The values within this table are constantly updated when the algorithm\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "generated by the algorithm it can make understanding, and solving problems\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "these strings with array indexes to aid the algorithm walkthrough.\n",
            "variables whose values change during the algorithm. We recommend that you\n",
            "Table A.2: Algorithm trace for IsPalindrome\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "your algorithm. You can use these trace tables to verify algorithm correctness.\n",
            "operating on you can devise correct algorithms quicker. Visualising the problem\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "of an algorithm that computes a number from the Fiboncacci sequence.\n",
            "1) algorithm Fibonacci(n)\n",
            "rithm calls for the Fibonacci algorithm we will brieﬂy talk about the cases of\n",
            "the algorithm. The algorithm has three cases in total:\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "Figure A.2: Call chain for Fibonacci algorithm\n",
            "Figure A.3: Return chain for Fibonacci algorithm\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "In the Fibonacci algorithms’ recursive case we make two recursive calls.\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "Understanding algorithms can be hard at times, particularly from an implemen-\n",
            "tation perspective. In order to understand an algorithm try and work through\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "that you know how the algorithm works. Mastering how an algorithm works\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "may have to inject various calls to other utility algorithms to ascertain the\n",
            "A consideration to take note of is that many algorithms have fairly strict\n",
            "the algorithm. Most of the preconditions can be suitably handled by throwing\n",
            "translation of our pseudo code algorithms to mainstream imperative languages\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "you might want to use such an approach for your algorithms we will now talk\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "Using recursion should always be reserved for fast algorithms, you should\n",
            "avoid it for the following algorithm run time deﬁciencies:\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "most cases such algorithms will lean very heavily on techniques like divide and\n",
            "cause your algorithm to run a lot slower than expected, or worse, you will run\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "an iterative vs. recursive solution in the form of the Fibonacci algorithm. This\n",
            "does the job a lot quicker. If we were to give the Fibonacci algorithm an input\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "We can also look at sorting algorithms like merge sort, and quick sort. Both\n",
            "of these algorithms are recursive in their design and so it makes sense to model\n",
            "an algorithm with a quadratic run time or higher. Of course this is not a rule\n",
            "you add or tweak algorithms and then run your suite of tests you will be quickly\n",
            "implementation of algorithms. At any one stage you only have a single goal, to\n",
            "to building a solution. If you adhere to progressive revisions of your algorithm\n"
        ],
        "label": 0
    },
    "wanted determine thousand": {
        "abstracts": [
            "For further clariﬁcation what if we wanted to determine how many thousands\n",
            "number of digits. As an example if we wanted to determine the maximum value\n",
            "and\n"
        ],
        "label": 0
    },
    "sort quick sort": {
        "abstracts": [
            "smaller chunks and stitches them back together, e.g. quick sort.\n",
            "Quick Sort\n",
            "greater elements after it. This is the main quick sort operation, called partition,\n",
            "Figure 8.3: Quick Sort Example (pivot median strategy)\n",
            "1) algorithm QuickSort(list)\n",
            "lists, some are very eﬃcient (e.g. quick sort deﬁned in §8.3), some are not (e.g.\n",
            "We can also look at sorting algorithms like merge sort, and quick sort. Both\n"
        ],
        "label": 0
    },
    "thinking style functional complex": {
        "abstracts": [],
        "label": 0
    },
    "search tree binary search": {
        "abstracts": [
            "into smaller chunks per each invocation, e.g. searching a binary search\n",
            "Binary Search Tree\n",
            "the binary search tree\n",
            "Trees are\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "search tree obtained by starting with an empty tree and inserting some values\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n"
        ],
        "label": 0
    },
    "equal greater equal greater": {
        "abstracts": [],
        "label": 0
    },
    "binary search tree example": {
        "abstracts": [
            "Binary Search Tree\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "structures that derive from BinarySearchTree.\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n"
        ],
        "label": 0
    },
    "27 28 29": {
        "abstracts": [],
        "label": 0
    },
    "pre root root node": {
        "abstracts": [
            "that root is a reference to the root node of the tree.\n",
            "the tree is empty then we simply create our root node and ﬁnish. In all other\n"
        ],
        "label": 0
    },
    "parent greater": {
        "abstracts": [
            "Part I\n",
            "parent is greater than that of each of its children.\n",
            "parent ←∅\n",
            "recursively repeated on lesser and greater sub lists until their size is one or zero\n",
            "return GreatestCommonDenominator(n, m % n)\n"
        ],
        "label": 0
    },
    "value return root": {
        "abstracts": [
            "to the caller when all values to return to the caller have been exhausted.\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "return ∅\n",
            "return root\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "Post: the number of repeated words in value is returned\n",
            "return −1\n",
            "value\n",
            "value\n",
            "return 0\n",
            "return 1\n",
            "veriﬁed that a particular value V is returned from a speciﬁc input I then your\n"
        ],
        "label": 0
    },
    "number consists digit base": {
        "abstracts": [
            "Numeric\n"
        ],
        "label": 0
    },
    "item deque contain": {
        "abstracts": [
            "variable that tracks how many items are contained in the list so that accessing\n",
            "additionally ensures that the tree contains unique items you should read §7 to\n"
        ],
        "label": 0
    },
    "nodetoremove left nodetoremove value": {
        "abstracts": [
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "if value < nodeToRemove.Value\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "value\n",
            "left\n",
            "1. value\n",
            "value\n",
            "left\n"
        ],
        "label": 0
    },
    "sorting algorithm": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "data structures and algorithms.\n",
            "themselves based on the concepts by which the respective algorithms are based\n",
            "that contains formal proofs of the algorithms in question. In this book we use\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "O(n log n) just n log n: usually associated with an algorithm that breaks the problem\n",
            "really a signal for you to review the design of your algorithm. While prototyp-\n",
            "ing algorithm designs you may just have the intention of solving the problem\n",
            "review your algorithm design and optimise where possible—particularly loops\n",
            "algorithms.\n",
            "sentially discard things like hardware. If you have two sorting algorithms, one\n",
            "logarithmic algorithm will always be faster than the quadratic one when the\n",
            "a key factor in algorithm analysis: growth. An algorithm with a quadratic run\n",
            "some point as n →∞the logarithmic algorithm will become faster than the\n",
            "quadratic algorithm.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "back in your head, but this time as well as talking about algorithm design each\n",
            "the latter approach you not only get a good general idea about the algorithm\n",
            "when it comes to selecting an algorithm ﬁt for purpose.\n",
            "management via garbage collection algorithms. It is trivial to port our imple-\n",
            "language. In particular, we never provide data structures or algorithms that\n",
            "the sorting algorithms.\n",
            "2. Post-conditions represent the result of applying algorithm a to data struc-\n",
            "If an algorithm has a return type it will often be presented in the post-\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "The example above describes an algorithm by the name of AlgorithmName,\n",
            "Normally what is listed as a pre-conidition is critical to the algorithms opera-\n",
            "describes the eﬀect of the algorithms operation. An example of a post-condition\n",
            "The best way to work through algorithms is to set up a table, and in that\n",
            "throughout the algorithm.\n",
            "Often while working through algorithms in such\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "with just reading the section of a chapter that describes the algorithm you are\n",
            "For all readers we recommend that before looking at any algorithm you\n",
            "used within our algorithms and their meaning. One keyword that we would like\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "all the test cases have been progressively satisﬁed we consider that algorithm\n",
            "For the most part algorithms have fairly obvious cases which need to be\n",
            "and the corresponding portions of pseudocode within the algorithm that satisfy\n",
            "intuitively identify areas which may cause problems for your algorithms imple-\n",
            "will hinder your ability to design an algorithm greatly. When you are bom-\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "1. Understand how the algorithm works ﬁrst in an abstract sense; and\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "up front; exceeding that size involves invoking a resizing algorithm which has\n",
            "count during the insertion and deletion algorithms.\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "cases we invoke the recursive InsertNode algorithm which simply guides us to\n",
            "but we will look brieﬂy at the premise of the algorithm nonetheless.\n",
            "Astute readers will have noticed that the FindNode algorithm is exactly the\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "The base case in both FindMin, and FindMax algorithms is when the Left\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Designing an algorithm for heap insertion is simple, but we must ensure that\n",
            "by product of verifying heap order as the ﬁrst part of the algorithm (the actual\n",
            "Please note that in our deletion algorithm that we don’t default the removed\n",
            "the heap we can optimise the search algorithm by including logic which makes\n",
            "The following algorithm is speciﬁcally designed for a min-heap. To tailor the\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "bound of the heap. You will note that in the search algorithm that we use Count\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "that upon each insertion and deletion we invoke algorithms that have logarithmic\n",
            "The run time of our Union algorithm is O(m + n) where m is the number\n",
            "pointing out about our algorithm is that we traverse the set containing the\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "of items in the smaller of the two sets. Just like our Union algorithm a linear\n",
            "The above depends on how good the hashing algorithm of the hash table\n",
            "the existence of an item yielding a logarithmic run time.\n",
            "We can use sets to facilitate many algorithms that would otherwise be a little\n",
            "set to assist in the construction of an algorithm that determines the number of\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "incur the expense of invoking a resizing algorithm which would most likely be\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "invocation of the garbage collection algorithm. With C++ or any other lan-\n",
            "The right and left rotation algorithms are symmetric.\n",
            "Notice that we use two new algorithms that represent double rotations.\n",
            "Our balancing algorithm is like the one presented for our BST (deﬁned in §3.3).\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n",
            "Algorithms\n",
            "Sorting\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "Merge sort is an algorithm that has a fairly eﬃcient space time complexity -\n",
            "a list, into two similar sized lists (left, and right) and sorting each list and then\n",
            "Quick sort is one of the most popular sorting algorithms based on divide et\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "implementing recursive algorithms see Appendix C.\n",
            "A simple algorithm that determines whether or not a given integer is a prime\n",
            "Table 9.1 shows the algorithm trace when the number to convert to binary\n",
            "In the following algorithm numberBase should be considered restricted to\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "A simple algorithm that search for a speciﬁc item inside a list.\n",
            "Probability search is a statistical sequential searching algorithm. In addition to\n",
            "it’s predecessor in the list. The algorithm complexity still remains at O(n) but\n",
            "In this chapter we have presented a few novel searching algorithms. We have\n",
            "presented more eﬃcient searching algorithms earlier on, like for instance the\n",
            "logarithmic searching algorithm that AVL and BST tree’s use (deﬁned in §3.2).\n",
            "We decided not to cover a searching algorithm known as binary chop (another\n",
            "the reader has already seen such an algorithm in §3.\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "and transformations are incredibly frequent within programs. The algorithms\n",
            "Deﬁning algorithms for primitive string operations is simple, e.g. extracting a\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "Although not a frequent algorithm that will be applied in real-life scenarios\n",
            "detecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "In the IsPalindrome algorithm we call a method by the name of Strip. This\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "What denotes a word? In our algorithm each word is separated by one or\n",
            "You will notice in the RepeatedWordCount algorithm that we use the Strip\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "along a little with our introductory algorithms you can devise some of your own.\n",
            "structured approach to tracing its behaviour. In most cases tracing an algorithm\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "variables whose values change during the algorithm. We recommend that you\n",
            "your algorithm. You can use these trace tables to verify algorithm correctness.\n",
            "operating on you can devise correct algorithms quicker. Visualising the problem\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "of an algorithm that computes a number from the Fiboncacci sequence.\n",
            "rithm calls for the Fibonacci algorithm we will brieﬂy talk about the cases of\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "Figure A.2: Call chain for Fibonacci algorithm\n",
            "Figure A.3: Return chain for Fibonacci algorithm\n",
            "In the Fibonacci algorithms’ recursive case we make two recursive calls.\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "Understanding algorithms can be hard at times, particularly from an implemen-\n",
            "tation perspective. In order to understand an algorithm try and work through\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "that you know how the algorithm works. Mastering how an algorithm works\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "may have to inject various calls to other utility algorithms to ascertain the\n",
            "A consideration to take note of is that many algorithms have fairly strict\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "you might want to use such an approach for your algorithms we will now talk\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "Using recursion should always be reserved for fast algorithms, you should\n",
            "avoid it for the following algorithm run time deﬁciencies:\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "cause your algorithm to run a lot slower than expected, or worse, you will run\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "an iterative vs. recursive solution in the form of the Fibonacci algorithm. This\n",
            "does the job a lot quicker. If we were to give the Fibonacci algorithm an input\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "We can also look at sorting algorithms like merge sort, and quick sort. Both\n",
            "you add or tweak algorithms and then run your suite of tests you will be quickly\n",
            "implementation of algorithms. At any one stage you only have a single goal, to\n",
            "to building a solution. If you adhere to progressive revisions of your algorithm\n"
        ],
        "label": 0
    },
    "list sorted value ascending": {
        "abstracts": [
            "might be “The list has been sorted in ascending order”\n",
            "list\n",
            "value\n",
            "value\n"
        ],
        "label": 0
    },
    "return caller exhausted scenario": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "value yield root": {
        "abstracts": [
            "value\n",
            "value\n",
            "yield\n"
        ],
        "label": 0
    },
    "hundred clariﬁcation wanted determine": {
        "abstracts": [],
        "label": 0
    },
    "word string": {
        "abstracts": [
            "irrespective of how fast it works. We would strongly advise that you always\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "are emptied starting the smallest key bucket to the largest. When looking at\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "Strings\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "few markers to deﬁne where words start and end we can easily reverse them.\n",
            "// append chars from start + 1 to length + 1 to string buﬀer sb\n",
            "rithm uses two pointers at opposite ends of string we are checking is a palindrome\n",
            "If you remove all punctuation, and white space from the aforementioned string\n",
            "implement. If we split all the words using a single occurrence of white space\n",
            "uniques.Add(word.Strip())\n",
            "between two strings\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "characters in another string is pretty trivial. Put simply, we can parse the strings\n",
            "Word\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "are. Strings are probably the most common data type (and data structure -\n",
            "that you learn to be creative with them. We for one ﬁnd strings fascinating. A\n",
            "simple Google search on string nuances between languages and encodings will\n",
            "should be pretty obvious that we are operating on a string, but how is this\n",
            "represented? A string is essentially a block of contiguous memory that consists\n",
            "word\n",
            "word\n",
            "Whenever you encounter a keyword within our pseudo code examples that\n"
        ],
        "label": 0
    },
    "scope end end": {
        "abstracts": [],
        "label": 0
    },
    "set figure 11 step": {
        "abstracts": [
            "subtrees cannot be no more than one, see Figure 7.1. This condition, restored\n",
            "character they point to is the same with respect to value. Figure 11.1 shows the\n"
        ],
        "label": 0
    },
    "value ascending order post": {
        "abstracts": [
            "Inorder\n",
            "ordered set.\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "Post: list has been sorted into values of ascending order\n",
            "value\n",
            "value\n"
        ],
        "label": 0
    },
    "list increment": {
        "abstracts": [
            "The reason that we are explicit in this requirement is simple—all our imple-\n",
            "The previous list represents what we believe in the vast majority of cases to\n",
            "where within a list irrespective of whether the node is the head etc. If you know\n",
            "Traversing the list in reverse order\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "and backwards traversal. For the most cases this requirement is present. For\n",
            "need to keep track of the next free index in the array as a counter, and increment\n",
            "while increment ̸= 0\n",
            "current ←increment\n",
            "i ←current −increment\n",
            "list[i + increment] ←list[i]\n",
            "i−= increment\n",
            "list[i + increment] ←hold\n",
            "list\n",
            "notice how the searched items have had their search probability increased after\n",
            "• The top-of-stack index is incremented by the total amount of memory\n",
            "1. The top-of-stack index is decremented by the total amount of memory\n",
            "3. The top-of-stack index is decremented by the total amount of memory\n"
        ],
        "label": 0
    },
    "heap value": {
        "abstracts": [
            "Pre: n is the value to compute the factorial of\n",
            "than trying to work out a few values on paper and the rest in your head. We\n",
            "whereas yield returns each value to the caller. With yield control only returns\n",
            "to the caller when all values to return to the caller have been exhausted.\n",
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "Pre: value is the value to add to the list\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "1) algorithm Contains(head, value)\n",
            "value is the value to search for\n",
            "while n ̸= ∅and n.Value ̸= value\n",
            "1) algorithm Remove(head, value)\n",
            "value is the value to remove from the list\n",
            "if n.Value = value\n",
            "while n.Next ̸= ∅and n.Next.Value ̸= value\n",
            "Pre: value is the value to add to the list\n",
            "added task of binding an additional reference (Previous) to the correct value.\n",
            "1) algorithm Remove(head, value)\n",
            "value is the value to remove from the list\n",
            "if value = head.Value\n",
            "while n ̸= ∅and value ̸= n.Value\n",
            "node with value x, where the left subtree of x contains nodes with values < x\n",
            "and the right subtree contains nodes whose values are ≥x. Each node follows\n",
            "Pre: value has passed custom type checks for type T\n",
            "1) algorithm InsertNode(current, value)\n",
            "InsertNode(current.Left, value)\n",
            "InsertNode(current.Right, value)\n",
            "the ﬁrst appropriate place in the tree to put value. Note that at each stage we\n",
            "right by comparing the new value with that of the current node. For any totally\n",
            "1. the root = ∅in which case value is not in the BST; or\n",
            "2. root.Value = value in which case value is in the BST; or\n",
            "Pre: root is the root node of the tree, value is what we would like to locate\n",
            "if root.Value = value\n",
            "else if value < root.Value\n",
            "return Contains(root.Left, value)\n",
            "return Contains(root.Right, value)\n",
            "1. the value to remove is a leaf node; or\n",
            "2. the value to remove has a right subtree, but no left subtree; or\n",
            "3. the value to remove has a left subtree, but no right subtree; or\n",
            "4. the value to remove has both a left and right subtree in which case we\n",
            "promote the largest value in the left subtree.\n",
            "Of course in a BST a value may occur more than once. In such a case the\n",
            "ﬁrst occurrence of that value in the BST will be removed.\n",
            "Pre: value is the value of the node to remove, root is the root node of the BST\n",
            "Post: node with value is removed if found in which case yields true, otherwise false\n",
            "return false // value not in BST\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "the parent node of the one with the given value. We have found that such an\n",
            "Pre: value is the value of the node we want to ﬁnd the parent of\n",
            "Post: a reference to the parent node of value if found; otherwise ∅\n",
            "else if root.Left.Value = value\n",
            "else if root.Right.Value = value\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "speciﬁed value exists.\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "itself. Again, ∅is returned if the value isn’t found.\n",
            "Pre: value is the value of the node we want to ﬁnd the parent of\n",
            "Post: a reference to the node of value if found; otherwise ∅\n",
            "if root.Value = value\n",
            "else if value < root.Value\n",
            "return FindNode(root.Left, value)\n",
            "return FindNode(root.Right, value)\n",
            "Finding the smallest and largest values in\n",
            "To ﬁnd the smallest value in a BST you simply traverse the nodes in the left\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "Post: the smallest value in the BST is located\n",
            "Post: the largest value in the BST is located\n",
            "This algorithm is very similar to that described in §3.7.1, however the value\n",
            "traversal where the value of the current node is yielded in between traversing\n",
            "One of the beauties of inorder traversal is that values are yielded in their\n",
            "Traversing a tree in breadth ﬁrst order yields the values of all nodes of a par-\n",
            "d we would visit the values of all nodes at d in a left to right fashion, then we\n",
            "sizeable array, etc) to store the values of the nodes visited in breadth ﬁrst order\n",
            "Heap\n",
            "were to choose the min heap strategy then each parent node would have a value\n",
            "have the smallest value in the tree.\n",
            "4.2 shows arrows to the direct left and right child of each value in the array.\n",
            "operation. Inserting a value into the next free slot in an array is simple: we just\n",
            "this requires us to swap the values of a parent and its child if the value of the\n",
            "child is < the value of its parent. We must do this for each subtree containing\n",
            "the value we just inserted.\n",
            "Figure 4.5 shows the steps of inserting the values 3, 9, 12, 7, and 1 into a\n",
            "Pre: value is the value to add to the heap\n",
            "Post: the value has been added to the heap\n",
            "The design of the MaxHeapify algorithm is very similar to that of the Min-\n",
            "Heapify algorithm, the only diﬀerence is that the < operator in the second\n",
            "1. ﬁnd the index of the value to delete\n",
            "2. put the last value in the heap at the index location of the item to delete\n",
            "3. verify heap ordering for each subtree which used to include the value\n",
            "Pre: value is the value to remove from the heap\n",
            "index ←FindIndex(heap, value)\n",
            "Swap(heap, left, index)\n",
            "containing the values 1, 3, 9, 12, and 13. In Figure 4.6 you can assume that we\n",
            "Pre: value is the value to search the heap for\n",
            "of the properties in which all values of a heap hold, that is the property of the\n",
            "Optimising to deterministically state that a value is in the heap is not that\n",
            "consider a min-heap that doesn’t contain the value 5. We can only rule that the\n",
            "Pre: value is the value to search the heap for\n",
            "else if value > Parent(heap[start]) and value < heap[start]\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "is no possible way that value is in the heap. As an example consider Figure 4.7.\n",
            "If we are searching for the value 10 within the min-heap displayed it is obvious\n",
            "array data structure which our heap implementation is based upon. As a result\n",
            "and then visit each value within the array until you have reached the upper\n",
            "Figure 4.7: Determining 10 is not in the heap after inspecting the nodes of Level\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n",
            "structure. The garbage values of course vary from platform to platform. To\n",
            "make things simple the garbage value of a reference type will be simple ∅and 0\n",
            "for a value type.\n",
            "any other fashion requires some creative intervention. Heaps are not usually\n",
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "and max heap. The former strategy enforces that the value of a parent node is\n",
            "less than that of each of its children, the latter enforces that the value of the\n",
            "state this explicitly. The heap abides progressively to a strategy during the\n",
            "Generally set implementations tend to check that a value is not in the set\n",
            "before adding it, avoiding the issue of repeated values from ever occurring.\n",
            "the ways in which the values of sets can be deﬁned, and common operations that\n",
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "alias to the current value we are inspecting and to the right hand side of | are\n",
            "the value of the old head node, and then modifying the head pointer to be the\n",
            "are either those with the smallest value, or those with the largest.\n",
            "search tree obtained by starting with an empty tree and inserting some values\n",
            "nodes is O(log n) regardless of the order in which values are inserted.\n",
            "AVL insertion operates ﬁrst by inserting the given value the same way as BST\n",
            "Pre: value has passed custom type checks for type T\n",
            "1) algorithm InsertNode(current, value)\n",
            "InsertNode(current.Left, value)\n",
            "InsertNode(current.Right, value)\n",
            "to be rebalanced and the value we are removing is contained within the tree\n",
            "then no further step are required. However, when the value is in the tree and\n",
            "Pre: value is the value of the node to remove, root is the root node\n",
            "Post: node with value is removed and tree rebalanced if found in which\n",
            "return false // value not in Avl\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "pivot ←MedianValue(list)\n",
            "coloured square is the current value we are holding.\n",
            "this example base 10 numbers we have at any one point 10 possible key values\n",
            "location, e.g. 0102 here it is more obvious that the key value at the thousands\n",
            "left to right in a sequential manner. The value of key is used in the following\n",
            "the values of 2, 8, 9, and 16.\n",
            "value of numberBase to an integer, as such we extract the value associated with\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "last ←value.Length −1\n",
            "while start ≥0 and value[start] = whitespace\n",
            "Post: the number of words contained within value is determined\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "if index = value.Length and value[index] = whitespace\n",
            "while index < value.Length\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "rithm. The values within this table are constantly updated when the algorithm\n",
            "visual representation of the problem as well as having a history of past values\n",
            "the value of the string we will operate on let’s go ahead and draw it as shown\n",
            "value\n",
            "1. value\n",
            "Having identiﬁed the values of the variables we need to keep track of we\n",
            "the variable values in the table appropriately. Table A.2 shows the ﬁnal table\n",
            "In Table A.2 we have included both the value, and word variables because it\n",
            "was convenient to do so. You may ﬁnd that you want to promote these values\n",
            "variables whose values change during the algorithm. We recommend that you\n",
            "value\n",
            "of say 60 then we would have to wait a while to get the value back because it\n",
            "structure. A common tree node usually contains a value, along with two point-\n",
            "veriﬁed that a particular value V is returned from a speciﬁc input I then your\n"
        ],
        "label": 0
    },
    "inword end": {
        "abstracts": [
            "Inorder\n",
            "3. inWord\n",
            "have encountered, and ﬁnally inWord is a Boolean ﬂag that denotes whether\n",
            "inWord ←true\n",
            "inWord ←false\n",
            "inWord ←true\n",
            "if inWord\n",
            "Word\n",
            "word\n",
            "word\n"
        ],
        "label": 0
    },
    "algorithm remove": {
        "abstracts": [
            "themselves based on the concepts by which the respective algorithms are based\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "algorithms.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "For all readers we recommend that before looking at any algorithm you\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "driven development style on paper to ﬂesh out the pseudocode algorithm. We\n",
            "For the most part algorithms have fairly obvious cases which need to be\n",
            "will hinder your ability to design an algorithm greatly. When you are bom-\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm Traverse(head)\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "1) algorithm Remove(head, value)\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "1) algorithm Remove(value)\n",
            "algorithm is very useful, especially when performing extensive tree transforma-\n",
            "This algorithm is very similar to §3.4, but instead of returning a reference to the\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "1) algorithm Preorder(root)\n",
            "This algorithm is very similar to that described in §3.7.1, however the value\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "1) algorithm Inorder(root)\n",
            "1) algorithm BreadthFirst(root)\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "Designing an algorithm for heap insertion is simple, but we must ensure that\n",
            "The design of the MaxHeapify algorithm is very similar to that of the Min-\n",
            "Heapify algorithm, the only diﬀerence is that the < operator in the second\n",
            "preserved. The algorithm for deletion has three steps:\n",
            "1) algorithm Remove(value)\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "1) algorithm LeftRotation(node)\n",
            "The right and left rotation algorithms are symmetric.\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "1) algorithm Mergesort(list)\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "implementing recursive algorithms see Appendix C.\n",
            "1) algorithm IsPrime(n)\n",
            "Table 9.1 shows the algorithm trace when the number to convert to binary\n",
            "Table 9.1: Algorithm trace of ToBinary\n",
            "1) algorithm GreatestCommonDenominator(m, n)\n",
            "1) algorithm MaxValue(numberBase, n)\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "1) algorithm ProbabilitySearch(list, item)\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "1) algorithm ReverseWords(value)\n",
            "detecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\n",
            "1) algorithm WordCount(value)\n",
            "1) algorithm RepeatedWordCount(value)\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "variables whose values change during the algorithm. We recommend that you\n",
            "Table A.2: Algorithm trace for IsPalindrome\n",
            "your algorithm. You can use these trace tables to verify algorithm correctness.\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "In the Fibonacci algorithms’ recursive case we make two recursive calls.\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "A consideration to take note of is that many algorithms have fairly strict\n",
            "the algorithm. Most of the preconditions can be suitably handled by throwing\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n"
        ],
        "label": 0
    },
    "101 figure 11 undesired": {
        "abstracts": [
            "Unordered\n",
            "unordered.\n",
            "Figure 11.4: a) Undesired uniques set; b) desired uniques set\n"
        ],
        "label": 0
    },
    "26 27": {
        "abstracts": [],
        "label": 0
    },
    "avl tree avl": {
        "abstracts": [
            "properties see AVL tree deﬁned in §7).\n",
            "an AVL tree that enforces self-balancing properties to help attain logarithmic\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "AVL Tree\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "after each tree modiﬁcation, forces the general shape of an AVL tree. Before\n",
            "time of each common operation is O(log n). The height of an AVL tree with n\n",
            "AVL tree the inventors make use of a well-known technique called tree rotation.\n",
            "Figure 7.1: The left and right subtrees of an AVL tree diﬀer in height by at\n",
            "CHAPTER 7. AVL TREE\n",
            "Figure 7.3: Avl trees, insertion order: -a)1,2,3,4,5 -b)1,5,4,3,2\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "Post: current height has been updated while tree balance is if needed\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "The AVL tree is a sophisticated self balancing tree. It can be thought of as\n",
            "the AVL tree avoids worst case linear complexity runtimes for its operations.\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n"
        ],
        "label": 0
    },
    "pre number compute factorial": {
        "abstracts": [
            "Pre: n is the value to compute the factorial of\n",
            "Numeric\n",
            "Pre: n ≥0, n is the number to compute the factorial of\n",
            "factorial ←1\n",
            "return factorial\n"
        ],
        "label": 0
    },
    "left height current right": {
        "abstracts": [
            "if current.Right = ∅\n",
            "of eight.\n",
            "Right\n",
            "Left\n",
            "if current.Left = ∅and current.Right = ∅\n",
            "current.Height = Max(Height(current.Left),Height(current.Right)) + 1\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "if Height(current.Left.Left) - Height(current.Left.Right) > 0\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "if Height(current.Right.Left) - Height(current.Right.Right) < 0\n",
            "if current.Right = ∅\n",
            "left\n",
            "right\n",
            "4. right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "unordered set": {
        "abstracts": [
            "Inorder\n",
            "Sets\n",
            "Unordered\n",
            "Most libraries provide implementations of unordered sets and so DSA does\n",
            "not; we simply mention it here to disambiguate between an unordered set and\n",
            "ordered set.\n",
            "We will only look at insertion for an unordered set and cover brieﬂy why a\n",
            "An unordered set can be eﬃciently implemented using a hash table as its backing\n",
            "Ordered\n",
            "An ordered set is similar to an unordered set in the sense that its members are\n",
            "distinct, but an ordered set enforces some predeﬁned comparison on each of its\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "The ordered set has its order realised by performing an inorder traversal\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "unordered.\n",
            "When implementing a set (either ordered or unordered) it is key to select\n",
            "this check to be as quick as possible. For unordered sets we can rely on the use\n",
            "constant run time complexity. Ordered sets cost a little more for this check,\n",
            "less clear in their implementation. For example in §11.4 we use an unordered\n",
            "the intent of building up an ordered set of cards in your hand.\n",
            "With the help of an unordered set, and an algorithm that can split the words\n"
        ],
        "label": 0
    },
    "root value yield root": {
        "abstracts": [
            "yield root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "value\n",
            "value\n",
            "yield\n"
        ],
        "label": 0
    },
    "type check type": {
        "abstracts": [
            "Pre: value has passed custom type checks for type T\n",
            "Pre: value has passed custom type checks for type T\n"
        ],
        "label": 0
    },
    "search tree binary": {
        "abstracts": [
            "into smaller chunks per each invocation, e.g. searching a binary search\n",
            "Binary Search Tree\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "Trees are\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "search tree obtained by starting with an empty tree and inserting some values\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n"
        ],
        "label": 0
    },
    "root left postorder": {
        "abstracts": [
            "Postorder\n",
            "9) end Postorder\n",
            "Ordered\n",
            "order):\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "26 27 28 29": {
        "abstracts": [],
        "label": 0
    },
    "left enqueue root right": {
        "abstracts": [
            "q.Enqueue(root.Right)\n",
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "• EnqueueFront\n",
            "Right\n",
            "Left\n",
            "left\n",
            "right\n",
            "4. right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "vast majority case satisﬁed": {
        "abstracts": [
            "The previous list represents what we believe in the vast majority of cases to\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "* This symbol has a direct translation with the vast majority of imperative\n"
        ],
        "label": 0
    },
    "sure unit test": {
        "abstracts": [
            "permost time bound. If you save some time in one feature it doesn’t necessarily\n",
            "then transcribe these tests into unit tests satisfying them one by one. When\n",
            "provided in this book are unit tests. Because unit tests contribute such a core\n",
            "a suite of unit tests that verify certain boundary conditions of your software.\n",
            "for unit testing.\n",
            "What constitutes a unit test?\n",
            "A unit test should focus on a single atomic property of the subject being tested.\n",
            "given I. A unit test should be simple and self describing.\n",
            "As well as a unit test being relatively atomic you should also make sure that\n",
            "your unit tests execute quickly. If you can imagine in the future when you may\n",
            "One of the founding principles of TDD is to write the unit test ﬁrst, watch\n",
            "duction code, e.g. all unit tests for a Person type may be contained within\n",
            "Something that you can get as a product of unit testing are code coverage\n",
            "code that your units tests cover. Using TDD it is likely that your code coverage\n"
        ],
        "label": 0
    },
    "equal greater": {
        "abstracts": [],
        "label": 0
    },
    "item deque": {
        "abstracts": [
            "1All readers are encouraged to provide suggestions, feature requests, and bugs so we can\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "root ←q.Dequeue()\n",
            "upper storage limit required; and\n",
            "2. put the last value in the heap at the index location of the item to delete\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "deal mainly with sequences rather than sets exclusively.\n",
            "of a hash table and use the key of an item to determine whether or not it is\n",
            "ﬁrst put into the queue will be the ﬁrst served, the second item added to the\n",
            "of queues (with the Dequeue operation). Since we always have a pointer to the\n",
            "(deﬁned in §4). Using a heap we can look at the ﬁrst item in the queue by simply\n",
            "does, items are added in order to either the front of back of the deque. The\n",
            "former properties of the deque are denoted by the programmer utilising the data\n",
            "that add an item to the back of the deque may be named as they are with\n",
            "item to the back of the deque.\n",
            "With respect to algorithmic run time complexities a deque is the same as\n",
            "mum number of items the deque would contain at any one time. Unfortunately\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "To bypass all the aforementioned issues a deque typically uses a doubly\n",
            "right rotations both of them decrease the height of a BST by moving smaller\n",
            "queues[GetQueueIndex(item, indexOfKey)].Enqueue(item)\n",
            "are interested in for each number is highlighted. Omitted queues in Figure 8.6\n",
            "searching for an item, it takes into account its frequency by swapping it with\n"
        ],
        "label": 0
    },
    "tree chapter binary search": {
        "abstracts": [
            "Chapter 1\n",
            "Chapter 2\n",
            "Searching\n",
            "Chapter 3\n",
            "Binary Search Tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Searching\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "Chapter 4\n",
            "Searching\n",
            "Chapter 5\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Searching\n",
            "CHAPTER 10. SEARCHING\n",
            "CHAPTER 10. SEARCHING\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "postorder root left postorder": {
        "abstracts": [
            "Preorder(root.Left)\n",
            "Postorder\n",
            "Postorder(root.Left)\n",
            "9) end Postorder\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "node linked list": {
        "abstracts": [
            "a node to the tail of a linked list where we always maintain a pointer to\n",
            "use pointers for certain things. For example, when we describe a linked list\n",
            "Linked Lists\n",
            "linked list.\n",
            "In DSA our implementations of linked lists always maintain head and tail\n",
            "operation. As such, linked lists in DSA have the following characteristics:\n",
            "node(s) at the head and tail of the linked list and so performing a traditional\n",
            "insertion to either the front or back of the linked list is an O(1) operation. An\n",
            "the head nor tail in a singly linked list. When the node we are inserting before\n",
            "is somewhere in the middle of the linked list (known as random insertion) the\n",
            "traverse the linked list to ﬁnd that node’s current predecessor. This traversal\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "Singly Linked List\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "this book. Each node that makes up a singly linked list consists of a value, and\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.1: Singly linked list node\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "In general when people talk about insertion with respect to linked lists of any\n",
            "Adding a node to a singly linked list has only two cases:\n",
            "Searching a linked list is straightforward: we simply traverse the list checking\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Post: the item is either in the linked list, true; otherwise false\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "6. the item to remove doesn’t exist in the linked list\n",
            "the front of the linked list deletion becomes an O(1) operation.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Traversing a singly linked list is the same as that of traversing a doubly linked\n",
            "1. node = ∅, we have exhausted all nodes in the linked list; or\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Traversing a singly linked list in a forward manner (i.e. left to right) is simple\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "characteristics of the nodes that make up a singly linked list make this an\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "as you will soon see that doubly linked lists (deﬁned in §2.2) make reverse list\n",
            "Doubly Linked List\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "that each node has a reference to both the next and previous nodes in the list.\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.3: Reverse traveral of a singly linked list\n",
            "Figure 2.4: Doubly linked list node\n",
            "CHAPTER 2. LINKED LISTS\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "those listed previously for the singly linked list:\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Pre: head is the head node in the list\n",
            "Singly linked lists have a forward only design, which is why the reverse traversal\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "CHAPTER 2. LINKED LISTS\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "a linear run time. You should also use linked lists when you will only remove\n",
            "What linked lists are not very good for is random insertion, accessing nodes\n",
            "Singly linked lists should be used when you are only performing basic in-\n",
            "sertions. In general doubly linked lists are more accommodating for non-trivial\n",
            "operations on a linked list.\n",
            "We recommend the use of a doubly linked list when you require forwards\n",
            "In this scenario a doubly linked list is best as its design makes\n",
            "CHAPTER 2. LINKED LISTS\n",
            "list.\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "item at the head of a singly linked list, removal is simply a case of returning\n",
            "remains the same as that of a singly linked list: O(n).\n",
            "list\n",
            "to search a BST than it is a linked list. If you are going to search for data fairly\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n"
        ],
        "label": 0
    },
    "data structure operating": {
        "abstracts": [
            "language. In particular, we never provide data structures or algorithms that\n",
            "as possible. However, to appreciate the designs of our data structures you will\n",
            "ture d\n",
            "a way you can intuitively map relationships between data structures rather\n",
            "mon data structures; and\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "be the most important for each respective data structure.\n",
            "Data Structures\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "store. Using a data structure like an array would require you to specify the size\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "Unlike other tree data structures like the one deﬁned in §3 a heap is generally\n",
            "most two children. Figure 4.1 shows how the tree (not a heap data structure)\n",
            "so we need to choose a more dynamic data structure that contains the following\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "structure\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "array data structure which our heap implementation is based upon. As a result\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "data structure. As mentioned previously we only add an item to a set if that\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "the correct backing data structure. As we discussed in §5.1.1 because we check\n",
            "its backing data structure is acceptable.\n",
            "Queues are an essential data structure that are found in vast amounts of soft-\n",
            "queue data structure that you can use with your language of choice. In this\n",
            "data structure.\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "which requires the data structure to expose a standard Add method. In such\n",
            "operation.\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "Figure 6.2: Deque data structure after several mutations\n",
            "linked list as its baking data structure. While a node that has two pointers\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "One implementation of a priority queue is to use a heap data structure as its\n",
            "Queues are a very natural data structure, and while they are fairly primitive\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "data structure being used to store the data. For instance it is quicker to deter-\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "data structures that best ﬁt your scenario.\n",
            "are. Strings are probably the most common data type (and data structure -\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "Figure A.1: Visualising the data structure we are operating on\n",
            "promote the core data structure being operated on to a larger diagram outside\n",
            "At the cost of a simple table, and quick sketch of the data structure you are\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "adhering to the inherent design of the data structure you are operating on. Of\n",
            "Many times recursion has a natural home in recursive data structures and\n"
        ],
        "label": 0
    },
    "algorithm remove head": {
        "abstracts": [
            "algorithms.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm Traverse(head)\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "prev ←head\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "1) algorithm Remove(value)\n",
            "Designing an algorithm for heap insertion is simple, but we must ensure that\n",
            "1) algorithm Remove(value)\n",
            "The above depends on how good the hashing algorithm of the hash table\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "implementing recursive algorithms see Appendix C.\n",
            "Table 9.1 shows the algorithm trace when the number to convert to binary\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "1) algorithm ReverseWords(value)\n",
            "1) algorithm RepeatedWordCount(value)\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "avoid it for the following algorithm run time deﬁciencies:\n"
        ],
        "label": 0
    },
    "complexity deque deque wrapper": {
        "abstracts": [],
        "label": 0
    },
    "bst located pre root": {
        "abstracts": [
            "Post: value is either located or not\n",
            "return root\n",
            "return root\n",
            "return root\n"
        ],
        "label": 0
    },
    "list count list index": {
        "abstracts": [
            "list\n",
            "index ←0\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index < list.Count and list[index] = item\n",
            "index ←0\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index ≥list.Count or list[index] ̸= item\n",
            "1. index\n",
            "index ←0\n",
            "index\n",
            "index\n",
            "index\n"
        ],
        "label": 0
    },
    "algorithm insert": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "data structures and algorithms.\n",
            "that contains formal proofs of the algorithms in question. In this book we use\n",
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "measurement by which we can judge the performance of algorithms without\n",
            "choose an eﬃcient algorithm. For the sanity of our graph we have omitted cubic\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "really a signal for you to review the design of your algorithm. While prototyp-\n",
            "ing algorithm designs you may just have the intention of solving the problem\n",
            "review your algorithm design and optimise where possible—particularly loops\n",
            "algorithms.\n",
            "sentially discard things like hardware. If you have two sorting algorithms, one\n",
            "a key factor in algorithm analysis: growth. An algorithm with a quadratic run\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "about the high level algorithm design rather than its eﬃciency. Replay the scene\n",
            "back in your head, but this time as well as talking about algorithm design each\n",
            "respective developer states the asymptotic run time of their algorithm. Using\n",
            "management via garbage collection algorithms. It is trivial to port our imple-\n",
            "the sorting algorithms.\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "All algorithms start with a simple algorithm signature, e.g.\n",
            "n) end AlgorithmName\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "n) end AlgorithmName\n",
            "the algorithm signature; you should always enforce the pre-conditions of an\n",
            "Normally what is listed as a pre-conidition is critical to the algorithms opera-\n",
            "describes the eﬀect of the algorithms operation. An example of a post-condition\n",
            "order to get the most out of this book you work through each algorithm with a\n",
            "The best way to work through algorithms is to set up a table, and in that\n",
            "Often while working through algorithms in such\n",
            "used within our algorithms and their meaning. One keyword that we would like\n",
            "driven development style on paper to ﬂesh out the pseudocode algorithm. We\n",
            "intuitively identify areas which may cause problems for your algorithms imple-\n",
            "will hinder your ability to design an algorithm greatly. When you are bom-\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "Insertion\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "algorithm listed in this section is very similar to that used for traversal in §2.1.4.\n",
            "The algorithm whose cases we have described will remove a node from any-\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "1) algorithm Traverse(head)\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "Insertion\n",
            "The only major diﬀerence between the algorithm in §2.1.1 is that we need to\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "count during the insertion and deletion algorithms.\n",
            "Insertion\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "but we will look brieﬂy at the premise of the algorithm nonetheless.\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "algorithm is very useful, especially when performing extensive tree transforma-\n",
            "1) algorithm FindParent(value, root)\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "exist in the BST, in which case we return ∅. Callers to this algorithm must take\n",
            "This algorithm is very similar to §3.4, but instead of returning a reference to the\n",
            "1) algorithm FindNode(root, value)\n",
            "Astute readers will have noticed that the FindNode algorithm is exactly the\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "The base case in both FindMin, and FindMax algorithms is when the Left\n",
            "1) algorithm FindMin(root)\n",
            "1) algorithm FindMax(root)\n",
            "1) algorithm Preorder(root)\n",
            "This algorithm is very similar to that described in §3.7.1, however the value\n",
            "1) algorithm Postorder(root)\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "1) algorithm Inorder(root)\n",
            "1) algorithm BreadthFirst(root)\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "Insertion\n",
            "1) algorithm MinHeapify()\n",
            "The design of the MaxHeapify algorithm is very similar to that of the Min-\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "the heap we can optimise the search algorithm by including logic which makes\n",
            "The following algorithm is speciﬁcally designed for a min-heap. To tailor the\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "where such algorithms exist as extension methods deﬁned in the type Sys-\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "1) algorithm Union(set1, set2)\n",
            "The run time of our Union algorithm is O(m + n) where m is the number\n",
            "pointing out about our algorithm is that we traverse the set containing the\n",
            "1) algorithm Intersection(set1, set2)\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "of items in the smaller of the two sets. Just like our Union algorithm a linear\n",
            "Insertion\n",
            "algorithms and so the run time complexities for the hash table in your library\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "invocation of the garbage collection algorithm. With C++ or any other lan-\n",
            "1) algorithm LeftRotation(node)\n",
            "1) algorithm RightRotation(node)\n",
            "Insertion\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "Our balancing algorithm is like the one presented for our BST (deﬁned in §3.3).\n",
            "Algorithms\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "O(n log n) and is fairly trivial to implement. The algorithm is based on splitting\n",
            "1) algorithm Mergesort(list)\n",
            "Quick sort is one of the most popular sorting algorithms based on divide et\n",
            "impera strategy, resulting in an O(n log n) complexity. The algorithm starts by\n",
            "1) algorithm QuickSort(list)\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "1) algorithm Insertionsort(list)\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "1) algorithm ShellSort(list)\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "Selecting the correct sorting algorithm is usually denoted purely by eﬃciency,\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "implementing recursive algorithms see Appendix C.\n",
            "1) algorithm IsPrime(n)\n",
            "1) algorithm ToBinary(n)\n",
            "1) algorithm GreatestCommonDenominator(m, n)\n",
            "In the following algorithm numberBase should be considered restricted to\n",
            "algorithm can be modelled in a more readable manner rather than using various\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "algorithms in particular drive some of the most advanced systems on the planet\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "Probability search is a statistical sequential searching algorithm. In addition to\n",
            "the reader has already seen such an algorithm in §3.\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "and transformations are incredibly frequent within programs. The algorithms\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "1) algorithm ReverseWords(value)\n",
            "detecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "1) algorithm IsPalindrome(value)\n",
            "algorithm discards punctuation in the string, including white space. As a result\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "1) algorithm RepeatedWordCount(value)\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "generated by the algorithm it can make understanding, and solving problems\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "variables whose values change during the algorithm. We recommend that you\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "1) algorithm Fibonacci(n)\n",
            "the algorithm. The algorithm has three cases in total:\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "the algorithm. Most of the preconditions can be suitably handled by throwing\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "an iterative vs. recursive solution in the form of the Fibonacci algorithm. This\n",
            "does the job a lot quicker. If we were to give the Fibonacci algorithm an input\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "We can also look at sorting algorithms like merge sort, and quick sort. Both\n",
            "of these algorithms are recursive in their design and so it makes sense to model\n",
            "an algorithm with a quadratic run time or higher. Of course this is not a rule\n",
            "you add or tweak algorithms and then run your suite of tests you will be quickly\n"
        ],
        "label": 0
    },
    "number compute factorial": {
        "abstracts": [
            "Pre: n is the value to compute the factorial of\n",
            "Numeric\n",
            "Pre: n ≥0, n is the number to compute the factorial of\n",
            "factorial ←1\n",
            "return factorial\n"
        ],
        "label": 0
    },
    "problem lot simpler": {
        "abstracts": [
            "and sub-divide the problem into smaller problems. Solving the smaller problems\n",
            "they can make many problems a lot simpler.\n",
            "Impera\n",
            "domain and keeping track of changing data makes problems a lot easier to solve.\n"
        ],
        "label": 0
    },
    "problem spurred": {
        "abstracts": [
            "implementations of the factorial algorithm are recursive as the problem is re-\n"
        ],
        "label": 0
    },
    "algorithm insert value": {
        "abstracts": [
            "algorithms.\n",
            "order to get the most out of this book you work through each algorithm with a\n",
            "The best way to work through algorithms is to set up a table, and in that\n",
            "1) algorithm Add(value)\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "1) algorithm Remove(value)\n",
            "exist in the BST, in which case we return ∅. Callers to this algorithm must take\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Contains(value)\n",
            "1) algorithm Contains(value)\n",
            "where such algorithms exist as extension methods deﬁned in the type Sys-\n",
            "1) algorithm Union(set1, set2)\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "1) algorithm Insertionsort(list)\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "value\n",
            "1. value\n",
            "value\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n"
        ],
        "label": 0
    },
    "order deque property": {
        "abstracts": [
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "properties:\n",
            "Ordered\n",
            "Another key property of sets implemented using the approach we describe is\n"
        ],
        "label": 0
    },
    "line 25 false case": {
        "abstracts": [
            "// this is only case 5 if the conditional on line 25 was false\n"
        ],
        "label": 0
    },
    "return caller exhausted": {
        "abstracts": [
            "to the caller when all values to return to the caller have been exhausted.\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "12 search 101 figure": {
        "abstracts": [],
        "label": 0
    },
    "value 12 13 figure": {
        "abstracts": [
            "value\n",
            "value\n"
        ],
        "label": 0
    },
    "queue normal queue priority": {
        "abstracts": [
            "Queues\n",
            "queue;\n",
            "Priority Queue\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "a normal queue.\n"
        ],
        "label": 0
    },
    "number digit post": {
        "abstracts": [
            "number of digits. As an example if we wanted to determine the maximum value\n",
            "Pre: numberBase is the number system to use, n is the number of digits\n"
        ],
        "label": 0
    },
    "ﬁrst performs left rotation": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "Tree Rotations\n",
            "Rotation\n",
            "Left\n",
            "Rotation\n",
            "ﬁrst performs a left rotation and then subsequently a right rotation.\n",
            "rotation(s).\n",
            "left\n",
            "left\n",
            "tions.\n"
        ],
        "label": 0
    },
    "parent index": {
        "abstracts": [
            "Part I\n",
            "named FindParent, and FindNode which are described in §3.4 and §3.5 re-\n",
            "parent ←FindParent(value)\n",
            "the parent node of the one with the given value. We have found that such an\n",
            "Post: a reference to the parent node of value if found; otherwise ∅\n",
            "were to choose the min heap strategy then each parent node would have a value\n",
            "parent node, and the children of a node. The required expressions for this are\n",
            "1. (index −1)/2 (parent index)\n",
            "this requires us to swap the values of a parent and its child if the value of the\n",
            "and max heap. The former strategy enforces that the value of a parent node is\n",
            "parent ←∅\n",
            "parent = nodeToRemove\n",
            "parent ←FindParent(value)\n",
            "Part II\n",
            "Post: return index of item if found, otherwise −1\n",
            "index ←0\n",
            "return index\n",
            "index ←0\n",
            "1. index\n",
            "Of the previously listed index keeps track of the current index we are at in\n",
            "white space we are in a word, the opposite is true if at the present index we are\n",
            "index ←0\n",
            "index\n",
            "index\n",
            "index\n",
            "return index\n"
        ],
        "label": 0
    },
    "root right postorder": {
        "abstracts": [
            "no right subtree\n",
            "// set the parents’ Right pointer of largestV alue to ∅\n",
            "Postorder\n",
            "1) algorithm Postorder(root)\n",
            "Ordered\n",
            "order):\n",
            "Right\n",
            "// set the parents’ Right pointer of largestV alue to ∅\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "root left enqueue": {
        "abstracts": [
            "q ←queue\n",
            "Queues\n",
            "the queue.\n",
            "queue;\n",
            "the queue\n",
            "• EnqueueBack\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "platform modern language like": {
        "abstracts": [
            "are widely available on most platforms. Most modern languages like C++, C#,\n"
        ],
        "label": 0
    },
    "return false return false": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "avl tree": {
        "abstracts": [
            "tree.\n",
            "tail reference appropriately.\n",
            "added task of binding an additional reference (Previous) to the correct value.\n",
            "bi-directional traversal much simpler and quicker than that of a singly linked\n",
            "the BST is reasonably balanced; for a tree data structure with self balancing\n",
            "properties see AVL tree deﬁned in §7).\n",
            "algorithm is very useful, especially when performing extensive tree transforma-\n",
            "Traversing a tree in breadth ﬁrst order yields the values of all nodes of a par-\n",
            "there are many ways in which you can visit the nodes of a tree.\n",
            "operate on a tree are recursive.\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "an AVL tree that enforces self-balancing properties to help attain logarithmic\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "implemented as an array rather than a series of nodes which each have refer-\n",
            "This chapter is very much centred around the notion of representing a tree as\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "Figure 4.2: Direct children of the nodes in an array representation of a tree data\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "preserved. The algorithm for deletion has three steps:\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "AVL Tree\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "after each tree modiﬁcation, forces the general shape of an AVL tree. Before\n",
            "time of each common operation is O(log n). The height of an AVL tree with n\n",
            "AVL tree the inventors make use of a well-known technique called tree rotation.\n",
            "Figure 7.1: The left and right subtrees of an AVL tree diﬀer in height by at\n",
            "CHAPTER 7. AVL TREE\n",
            "Figure 7.3: Avl trees, insertion order: -a)1,2,3,4,5 -b)1,5,4,3,2\n",
            "CHAPTER 7. AVL TREE\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "the shape of a tree while preserving standard BST properties. There are left and\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "Post: current height has been updated while tree balance is if needed\n",
            "tree:\n",
            "CHAPTER 7. AVL TREE\n",
            "CHAPTER 7. AVL TREE\n",
            "Post: node with value is removed and tree rebalanced if found in which\n",
            "CHAPTER 7. AVL TREE\n",
            "The AVL tree is a sophisticated self balancing tree. It can be thought of as\n",
            "the AVL tree avoids worst case linear complexity runtimes for its operations.\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n",
            "used as an example has in total three keys:\n",
            "the algorithm. The algorithm has three cases in total:\n",
            "Until we hit one of our base cases in our recursive method call tree we won’t\n",
            "As you can see from the example used in this chapter we have tried to make the\n",
            "rithms are actually recursive in nature. A perfect example of this is a tree data\n"
        ],
        "label": 0
    },
    "array used store heap": {
        "abstracts": [
            "Heap\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "The heap\n"
        ],
        "label": 0
    },
    "node tree": {
        "abstracts": [
            "tree.\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "5. the node to remove is somewhere in between the head and tail; or\n",
            "2. we must update the node reference to be node.Next.\n",
            "acquire a reference to the predecessor of a node, even though the fundamental\n",
            "Pre: value is the value of the node to remove, root is the root node of the BST\n",
            "nodeToRemove ←FindNode(value)\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "if nodeToRemove.Value < parent.Value\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Right\n",
            "parent.Right ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Left\n",
            "parent.Right ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "nodeToRemove.Value ←largestV alue.Value\n",
            "subtree of the BST always going left upon each encounter with a node, termi-\n",
            "(FindMin), or Right (FindMax) node references are ∅in which case we have\n",
            "One of the beauties of inorder traversal is that values are yielded in their\n",
            "the run times for these operations on a pathologically unbalanced tree become\n",
            "The ordered set has its order realised by performing an inorder traversal\n",
            "present in the nodes are not changed.\n",
            "tree:\n",
            "Pre: value is the value of the node to remove, root is the root node\n",
            "Post: node with value is removed and tree rebalanced if found in which\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "parent = nodeToRemove\n",
            "if value < nodeToRemove.Value\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "path.Push(nodeToRemove)\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "if nodeToRemove.Value < parent.Value\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Right\n",
            "parent.Right ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Left\n",
            "parent.Right ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "nodeToRemove.Value ←largestV alue.Value\n",
            "ers to two other nodes of the same node type. As you can see tree is recursive\n"
        ],
        "label": 0
    },
    "avl balance": {
        "abstracts": [
            "the BST is reasonably balanced; for a tree data structure with self balancing\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "tree is moderately balanced.\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "the run times for these operations on a pathologically unbalanced tree become\n",
            "balanced.\n",
            "continuing, let us focus on why balance is so important.\n",
            "O(n). By applying a balance condition we ensure that the worst case running\n",
            "The AVL balance condition, known also as the node balance factor represents\n",
            "a technique that eﬃciently restores the balance condition for the tree. In an\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "Post: current height has been updated while tree balance is if needed\n",
            "violated then we need not rebalance the tree, the opposite is true if the\n",
            "preserving tree balance\n",
            "AVL balance property after the removal of the node. If the tree doesn’t need\n",
            "to be rebalanced and the value we are removing is contained within the tree\n",
            "its removal upsets the AVL balance property then we must perform the correct\n",
            "Post: node with value is removed and tree rebalanced if found in which\n",
            "CheckBalance(path.Pop()) // we trackback to the root node check balance\n",
            "The AVL tree is a sophisticated self balancing tree. It can be thought of as\n"
        ],
        "label": 0
    },
    "pivot moving smaller item": {
        "abstracts": [
            "right rotations both of them decrease the height of a BST by moving smaller\n",
            "picking an item, called pivot, and moving all smaller items before it, while all\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n"
        ],
        "label": 0
    },
    "queue enqueue root": {
        "abstracts": [
            "Queues\n",
            "queue;\n",
            "• EnqueueFront\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n"
        ],
        "label": 0
    },
    "yield root value": {
        "abstracts": [
            "yield curr.Value\n",
            "yield curr.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "yield root.Value\n",
            "Traversing a tree in breadth ﬁrst order yields the values of all nodes of a par-\n",
            "yield root.Value\n",
            "value\n",
            "1. value\n",
            "value\n",
            "yield\n"
        ],
        "label": 0
    },
    "post list sorted value": {
        "abstracts": [
            "list\n",
            "value\n",
            "1. value\n",
            "value\n"
        ],
        "label": 0
    },
    "return keyword cause method": {
        "abstracts": [
            "The return keyword causes the method to exit and returns control to the caller,\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return wordCount\n",
            "Word\n",
            "return −1\n",
            "word\n",
            "word\n",
            "return 0\n",
            "return 1\n"
        ],
        "label": 0
    },
    "populated bst pre root": {
        "abstracts": [
            "return root\n",
            "return root\n",
            "return root\n"
        ],
        "label": 0
    },
    "28 29": {
        "abstracts": [],
        "label": 0
    },
    "queue highest priority": {
        "abstracts": [
            "Queues\n",
            "queue;\n",
            "Priority Queue\n",
            "comparer to see which item has the highest priority. Other than the items in a\n",
            "ability to construct a priority queue where the items with the highest priority\n",
            "of the queue have the highest priority and those near the back have the lowest.\n"
        ],
        "label": 0
    },
    "26 27 28": {
        "abstracts": [],
        "label": 0
    },
    "method call": {
        "abstracts": [
            "you use an API like that of DSA and you see a general purpose method that\n",
            "a scenario you can safely assume that the Add method will simply enqueue an\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "Until we hit one of our base cases in our recursive method call tree we won’t\n",
            "In Figure A.2 the order in which the methods are called are labelled. Figure\n",
            "A.3 shows the call chain annotated with the return values of each method call\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "you to deﬁne methods that reference themselves, such methods are said to be\n",
            "practice, in these cases you are going to be spawning a lot of method calls. All\n",
            "this overhead (method calls don’t come that cheap) will soon pile up and either\n",
            "Normally an activation record for a method call is as follows (this is very\n",
            "• The actual parameters of the method are pushed onto the stack\n",
            "While activation records are an eﬃcient way to support method calls they\n",
            "The following example shows a simple test method that employs the three\n"
        ],
        "label": 0
    },
    "postorder postorder root left": {
        "abstracts": [
            "Preorder(root.Left)\n",
            "Postorder\n",
            "Postorder(root.Left)\n",
            "Inorder(root.Left)\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "list increment list": {
        "abstracts": [
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "increment ←list.Count / 2\n",
            "list[i + increment] ←list[i]\n",
            "i−= increment\n",
            "list[i + increment] ←hold\n",
            "return list\n",
            "return list\n",
            "list\n",
            "• The top-of-stack index is incremented by the total amount of memory\n"
        ],
        "label": 0
    },
    "queue priority": {
        "abstracts": [
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "Queues\n",
            "queue;\n",
            "of queues (with the Dequeue operation). Since we always have a pointer to the\n",
            "comparer to see which item has the highest priority. Other than the items in a\n",
            "priority queue being ordered by priority it remains the same as a normal queue:\n",
            "ability to construct a priority queue where the items with the highest priority\n",
            "A deque applies no prioritization strategy to its items like a priority queue\n",
            "Deque’s provide front and back speciﬁc versions of common queue operations,\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "for each priority of process to determine which should be the next process to\n",
            "In this chapter we have also seen priority queues where those at the front\n",
            "of the queue have the highest priority and those near the back have the lowest.\n"
        ],
        "label": 0
    },
    "algorithm sorting": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "that contains formal proofs of the algorithms in question. In this book we use\n",
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "Figure 1.1: Algorithmic run time expansion\n",
            "choose an eﬃcient algorithm. For the sanity of our graph we have omitted cubic\n",
            "O(n3), and exponential O(2n) run times. Cubic and exponential algorithms\n",
            "ing algorithm designs you may just have the intention of solving the problem\n",
            "review your algorithm design and optimise where possible—particularly loops\n",
            "algorithms.\n",
            "sentially discard things like hardware. If you have two sorting algorithms, one\n",
            "a key factor in algorithm analysis: growth. An algorithm with a quadratic run\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "about the high level algorithm design rather than its eﬃciency. Replay the scene\n",
            "back in your head, but this time as well as talking about algorithm design each\n",
            "respective developer states the asymptotic run time of their algorithm. Using\n",
            "when it comes to selecting an algorithm ﬁt for purpose.\n",
            "If an algorithm has a return type it will often be presented in the post-\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "All algorithms start with a simple algorithm signature, e.g.\n",
            "1) algorithm AlgorithmName(arg1, arg2, ..., argN)\n",
            "Immediately after the algorithm signature we list any Pre or Post condi-\n",
            "1) algorithm AlgorithmName(n)\n",
            "the algorithm signature; you should always enforce the pre-conditions of an\n",
            "Normally what is listed as a pre-conidition is critical to the algorithms opera-\n",
            "describes the eﬀect of the algorithms operation. An example of a post-condition\n",
            "tell the caller why the algorithm has failed to execute normally.\n",
            "The best way to work through algorithms is to set up a table, and in that\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "with just reading the section of a chapter that describes the algorithm you are\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "For all readers we recommend that before looking at any algorithm you\n",
            "will hinder your ability to design an algorithm greatly. When you are bom-\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "1. Understand how the algorithm works ﬁrst in an abstract sense; and\n",
            "2. Always work through the algorithms on paper to understand how they\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "algorithm listed in this section is very similar to that used for traversal in §2.1.4.\n",
            "1) algorithm Contains(head, value)\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "The algorithm described is a very simple one that makes use of a simple\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "Figure 2.3 depicts the following algorithm being applied to a linked list with\n",
            "This algorithm is only of real interest when we are using singly linked lists,\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "The only major diﬀerence between the algorithm in §2.1.1 is that we need to\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "The insertion algorithm is split for a good reason. The ﬁrst algorithm (non-\n",
            "but we will look brieﬂy at the premise of the algorithm nonetheless.\n",
            "1) algorithm Contains(root, value)\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "The purpose of this algorithm is simple - to return a reference (or pointer) to\n",
            "algorithm is very useful, especially when performing extensive tree transforma-\n",
            "1) algorithm FindParent(value, root)\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "exist in the BST, in which case we return ∅. Callers to this algorithm must take\n",
            "This algorithm is very similar to §3.4, but instead of returning a reference to the\n",
            "1) algorithm FindNode(root, value)\n",
            "ﬁnding the largest value in the BST. Both algorithms are incredibly simple, and\n",
            "1) algorithm FindMin(root)\n",
            "1) algorithm FindMax(root)\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "1) algorithm Preorder(root)\n",
            "This algorithm is very similar to that described in §3.7.1, however the value\n",
            "1) algorithm Postorder(root)\n",
            "1) algorithm Inorder(root)\n",
            "1) algorithm BreadthFirst(root)\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Designing an algorithm for heap insertion is simple, but we must ensure that\n",
            "1) algorithm MinHeapify()\n",
            "The design of the MaxHeapify algorithm is very similar to that of the Min-\n",
            "Heapify algorithm, the only diﬀerence is that the < operator in the second\n",
            "preserved. The algorithm for deletion has three steps:\n",
            "1) algorithm Contains(value)\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "the heap we can optimise the search algorithm by including logic which makes\n",
            "algorithm for a max-heap the two comparison operations in the else if condition\n",
            "1) algorithm Contains(value)\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "If you have followed the advice we gave in the deletion algorithm then a\n",
            "where such algorithms exist as extension methods deﬁned in the type Sys-\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "The run time of our Union algorithm is O(m + n) where m is the number\n",
            "pointing out about our algorithm is that we traverse the set containing the\n",
            "1) algorithm Intersection(set1, set2)\n",
            "The run time of our Intersection algorithm is O(n) where n is the number\n",
            "of items in the smaller of the two sets. Just like our Union algorithm a linear\n",
            "The above depends on how good the hashing algorithm of the hash table\n",
            "algorithms and so the run time complexities for the hash table in your library\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "With respect to algorithmic run time complexities a deque is the same as\n",
            "An algorithm described\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "1) algorithm LeftRotation(node)\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "1) algorithm Insert(value)\n",
            "1) algorithm InsertNode(current, value)\n",
            "Our balancing algorithm is like the one presented for our BST (deﬁned in §3.3).\n",
            "Algorithms\n",
            "Sorting\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "1) algorithm Mergesort(list)\n",
            "impera strategy, resulting in an O(n log n) complexity. The algorithm starts by\n",
            "1) algorithm QuickSort(list)\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "1) algorithm Insertionsort(list)\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "1) algorithm ShellSort(list)\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "1) algorithm Radix(list, maxKeySize)\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "Throughout this chapter we have seen many diﬀerent algorithms for sorting\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "1) algorithm IsPrime(n)\n",
            "1) algorithm ToBinary(n)\n",
            "This algorithm computes the maximum value of a number for a given number\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "1) algorithm Factorial(n)\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "algorithms in particular drive some of the most advanced systems on the planet\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "Probability search is a statistical sequential searching algorithm. In addition to\n",
            "1) algorithm ProbabilitySearch(list, item)\n",
            "presented more eﬃcient searching algorithms earlier on, like for instance the\n",
            "We decided not to cover a searching algorithm known as binary chop (another\n",
            "the reader has already seen such an algorithm in §3.\n",
            "and transformations are incredibly frequent within programs. The algorithms\n",
            "Deﬁning algorithms for primitive string operations is simple, e.g. extracting a\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "Although not a frequent algorithm that will be applied in real-life scenarios\n",
            "detecting a palindrome is a fun, and as it turns out pretty trivial algorithm to\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "1) algorithm IsPalindrome(value)\n",
            "algorithm discards punctuation in the string, including white space. As a result\n",
            "1) algorithm WordCount(value)\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "1) algorithm RepeatedWordCount(value)\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "1) algorithm Any(word,match)\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "values each variable has contained so that you can make your algorithm more\n",
            "generated by the algorithm it can make understanding, and solving problems\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "your algorithm. You can use these trace tables to verify algorithm correctness.\n",
            "Recursive Algorithms\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "1) algorithm Fibonacci(n)\n",
            "the algorithm. The algorithm has three cases in total:\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "tation perspective. In order to understand an algorithm try and work through\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "In the vast majority of cases implementing an algorithm is simple provided\n",
            "that you know how the algorithm works. Mastering how an algorithm works\n",
            "convert the algorithm in §9.1 to the C# language.\n",
            "the algorithm. Most of the preconditions can be suitably handled by throwing\n",
            "translation of our pseudo code algorithms to mainstream imperative languages\n",
            "a recursive algorithms has two main properties:\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "avoid it for the following algorithm run time deﬁciencies:\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "cause your algorithm to run a lot slower than expected, or worse, you will run\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "algorithm. The iterative solution is not as pretty, nor self documenting but it\n",
            "does the job a lot quicker. If we were to give the Fibonacci algorithm an input\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "implementation of algorithms. At any one stage you only have a single goal, to\n"
        ],
        "label": 0
    },
    "factorial pre number": {
        "abstracts": [
            "Numeric\n",
            "number, e.g. 2, 5, 7, and 13 are all prime numbers, however 6 is not as it can\n",
            "Factorial of a number\n",
            "Attaining the factorial of a number is a primitive mathematical operation. Many\n",
            "factorial of a number using the form N! where N is the number we wish to\n",
            "factorial ←1\n"
        ],
        "label": 0
    },
    "type parameter": {
        "abstracts": [
            "3. The type of parameters is inferred\n",
            "Most algorithms in this book require parameters, and because we assign no\n",
            "explicit type to those parameters the type is inferred from the contexts in which\n",
            "the parameter usually acts as the biggest clue to its type. For instance n is a\n",
            "which takes a single numeric parameter n. The pre and post conditions follow\n",
            "tion. This may cover things like the actual parameter not being null, or that the\n",
            "In the following examples you can assume, unless used as a parameter alias\n",
            "• The actual parameters of the method are pushed onto the stack\n",
            "consumed by the actual parameters\n"
        ],
        "label": 0
    },
    "wanted determine thousand ﬁnal": {
        "abstracts": [
            "For further clariﬁcation what if we wanted to determine how many thousands\n",
            "and\n"
        ],
        "label": 0
    },
    "search 101 figure 11": {
        "abstracts": [
            "location of the ﬁrst character in the match (Figure 11.5); otherwise we return\n"
        ],
        "label": 0
    },
    "end leaving": {
        "abstracts": [
            "The last major point of reference is that we always explicitly end a language\n",
            "explicitly state end for rather than leaving the interpretation of when scopes\n",
            "Figure 4.1 does not specify how we would handle adding null references to\n",
            "generated by the algorithm it can make understanding, and solving problems\n",
            "testing can be used to create a safety blanket when adding and removing features\n"
        ],
        "label": 0
    },
    "mainstream programming language": {
        "abstracts": [
            "imperative programming languages. It is not a deﬁnitive book on the theory of\n",
            "2. An imperative programming language\n",
            "Imperative programming language\n",
            "must know the basics of some imperative mainstream programming language\n",
            "work associated with mainstream languages.\n",
            "translation of our pseudo code algorithms to mainstream imperative languages\n",
            "One of the most succinct properties of modern programming languages like\n"
        ],
        "label": 0
    },
    "linked list populated": {
        "abstracts": [
            "Linked Lists\n",
            "linked list.\n",
            "Figure 2.1: Singly linked list node\n",
            "Figure 2.2: A singly linked list populated with integers\n",
            "the value we are looking for with the value of each node in the linked list. The\n",
            "2. the node to remove is the only node in the linked list; or\n",
            "1. node = ∅, we have exhausted all nodes in the linked list; or\n",
            "Figure 2.4: Doubly linked list node\n",
            "Figure 2.5 shows the doubly linked list after adding the sequence of integers\n",
            "Figure 2.5: Doubly linked list populated with integers\n",
            "Singly linked lists should be used when you are only performing basic in-\n",
            "linear: such a tree is eﬀectively just a linked list. Later in §7 we will examine\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "list\n",
            "to search a BST than it is a linked list. If you are going to search for data fairly\n"
        ],
        "label": 0
    },
    "number digit example wanted": {
        "abstracts": [],
        "label": 0
    },
    "oh notation": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "1. Big Oh notation\n",
            "Big Oh notation\n",
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "The following list explains some of the most common big Oh notations:\n",
            "into smaller chunks per each invocation, e.g. searching a binary search\n",
            "into smaller chunks per each invocation, and then takes the results of these\n",
            "The biggest asset that big Oh notation gives us is that it allows us to es-\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "Big Oh notation also acts as a communication tool. Picture the scene: you\n",
            "tions.\n",
            "This will help you keep track of and visualise the mutations that are occurring\n",
            "tions.\n",
            "This chapter is very much centred around the notion of representing a tree as\n",
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "AVL tree the inventors make use of a well-known technique called tree rotation.\n",
            "Tree Rotations\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "right rotations both of them decrease the height of a BST by moving smaller\n",
            "Rotation\n",
            "Rotation\n",
            "Figure 7.4: Tree left and right rotations\n",
            "1) algorithm RightRotation(node)\n",
            "9) end RightRotation\n",
            "The right and left rotation algorithms are symmetric.\n",
            "changed by a rotation resulting in an O(1) runtime complexity; the other ﬁelds\n",
            "perform the correct rotation.\n",
            "Notice that we use two new algorithms that represent double rotations.\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "ﬁrst performs a left rotation and then subsequently a right rotation.\n",
            "restored through rotations\n",
            "RightRotation(current)\n",
            "LeftAndRightRotation(current)\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "each search operation respectively.\n",
            "Post: index representing match location if occured, −1 otherwise\n",
            "return values are represented as annotations to the red arrows.\n",
            "to inject the correct code to handle such situations to preserve the correctness of\n",
            "tions.\n"
        ],
        "label": 0
    },
    "root value yield": {
        "abstracts": [
            "value\n",
            "value\n",
            "yield\n"
        ],
        "label": 0
    },
    "end end inword end": {
        "abstracts": [
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "Inorder\n",
            "end if\n",
            "9) end Inorder\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "3. inWord\n",
            "inWord ←true\n",
            "end if\n",
            "inWord ←true\n",
            "end if\n",
            "if inWord\n",
            "end if\n",
            "Word\n",
            "end if\n",
            "word\n",
            "word\n",
            "end if\n"
        ],
        "label": 0
    },
    "item choosing appropriate pivot": {
        "abstracts": [
            "Choosing an appropriate pivot, as for example the median element is funda-\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n"
        ],
        "label": 0
    },
    "binary search tree binary": {
        "abstracts": [
            "Binary Search Tree\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "Trees are\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n",
            "name for binary search, binary chop usually refers to its array counterpart) as\n"
        ],
        "label": 0
    },
    "list return list": {
        "abstracts": [
            "return false\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "itself. Again, ∅is returned if the value isn’t found.\n",
            "return ∅\n",
            "return root\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "string figure": {
        "abstracts": [
            "(12 7(3 2) 6(9 )) would be represented as an array. The array in Figure 4.1 is a\n",
            "result of simply adding values in a top-to-bottom, left-to-right fashion. Figure\n",
            "The BST in Figure 7.2 represents the worst case scenario in which the run-\n",
            "are interested in for each number is highlighted. Omitted queues in Figure 8.6\n",
            "Strings\n",
            "are the same word minus the punctuation. Figure 11.4 shows the undesired and\n",
            "characters in another string is pretty trivial. Put simply, we can parse the strings\n",
            "to a larger diagram (like that in Figure A.1) and only use the trace table for\n",
            "as well as the order in which methods return to their callers. In Figure A.3 the\n"
        ],
        "label": 0
    },
    "explicitly state end": {
        "abstracts": [
            "4. All primitive language constructs are explicitly begun and ended\n",
            "The last major point of reference is that we always explicitly end a language\n",
            "explicitly state end for rather than leaving the interpretation of when scopes\n",
            "state this explicitly. The heap abides progressively to a strategy during the\n"
        ],
        "label": 0
    },
    "summary description": {
        "abstracts": [
            "tions.\n",
            "Summary\n",
            "tions.\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "tions.\n",
            "Summary\n",
            "Description\n"
        ],
        "label": 0
    },
    "case yield true": {
        "abstracts": [
            "whereas yield returns each value to the caller. With yield control only returns\n",
            "Post: node with value is removed if found in which case yields true, otherwise false\n",
            "case yields true, otherwise false\n",
            "yield\n"
        ],
        "label": 0
    },
    "number digit": {
        "abstracts": [
            "Linked lists are good to use when you have an unknown number of items to\n",
            "Count is the number of items in the BST\n",
            "Count is the number of items in the heap\n",
            "Pre: Count is the number of items in the heap\n",
            "Count is the number of items in the heap\n",
            "Count is the number of items in the heap\n",
            "Count is the number of items in the heap\n",
            "number of items within the heap outgrows the space allocated in the heap’s\n",
            "of items in the ﬁrst set and n is the number of items in the second set. This\n",
            "mum number of items the deque would contain at any one time. Unfortunately\n",
            "thousands does 102 have you should simply pad the number with a zero in that\n",
            "are interested in for each number is highlighted. Omitted queues in Figure 8.6\n",
            "number of digits. As an example if we wanted to determine the maximum value\n",
            "Pre: numberBase is the number system to use, n is the number of digits\n",
            "factorial of a number using the form N! where N is the number we wish to\n",
            "Pre: n is the number in the ﬁbonacci sequence to compute\n"
        ],
        "label": 0
    },
    "use big oh notation": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "1. Big Oh notation\n",
            "Big Oh notation\n",
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "The following list explains some of the most common big Oh notations:\n",
            "The biggest asset that big Oh notation gives us is that it allows us to es-\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "Big Oh notation also acts as a communication tool. Picture the scene: you\n",
            "tions.\n",
            "tions.\n",
            "Rotation\n",
            "Rotation\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "tions.\n"
        ],
        "label": 0
    },
    "end inword": {
        "abstracts": [
            "with at least one imperative language in order to successfully port the pseudo-\n",
            "might be “The list has been sorted in ascending order”\n",
            "complexity is O(n). In order to add before the designated node we need to\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "9) end Insert\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "17) end InsertNode\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "25) end FindParent\n",
            "end if\n",
            "end if\n",
            "15) end FindNode\n",
            "we are returning a reference to a node not true or false. Given FindNode,\n",
            "end if\n",
            "9) end FindMin\n",
            "end if\n",
            "9) end FindMax\n",
            "end if\n",
            "9) end Preorder\n",
            "end if\n",
            "Inorder\n",
            "the left subtree and the right subtree. An example of inorder traversal is shown\n",
            "Post: the nodes in the BST have been visited in inorder\n",
            "end if\n",
            "9) end Inorder\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end ←nodes + start\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "15) end Intersection\n",
            "The ordered set has its order realised by performing an inorder traversal\n",
            "less clear in their implementation. For example in §11.4 we use an unordered\n",
            "repeated words within a string.\n",
            "does, items are added in order to either the front of back of the deque. The\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "9) end Insert\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "19) end InsertNode\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "Post: list has been sorted into values of ascending order\n",
            "end if\n",
            "Post: list has been sorted into values of ascending order\n",
            "end if\n",
            "Post: list has been sorted into values of ascending order\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "Post: list has been sorted into values of ascending order\n",
            "16) end Insertionsort\n",
            "Post: list has been sorted into values of ascending order\n",
            "are interested in for each number is highlighted. Omitted queues in Figure 8.6\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "return word[left] = word[right]\n",
            "3. inWord\n",
            "have encountered, and ﬁnally inWord is a Boolean ﬂag that denotes whether\n",
            "white space we are in a word, the opposite is true if at the present index we are\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "end if\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "end if\n",
            "if inWord\n",
            "end if\n",
            "return wordCount\n",
            "33) end WordCount\n",
            "Determining the number of repeated words\n",
            "Post: the number of repeated words in value is returned\n",
            "foreach word in words\n",
            "return words.Length −uniques.Count\n",
            "Word\n",
            "end if\n",
            "The trace table will store information about the variables used in your algo-\n",
            "word\n",
            "In Table A.2 we have included both the value, and word variables because it\n",
            "word\n",
            "end if\n",
            "word.\n",
            "algorithm that when invoked given a speciﬁc value it creates many recursive\n",
            "bar when it comes to quality. Of course in order to attain such a standard you\n",
            "Assemble: Create the objects you require in order to perform the state based asser-\n"
        ],
        "label": 0
    },
    "right nodetoremove left nodetoremove": {
        "abstracts": [
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "Right\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "left\n",
            "right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "heap array used": {
        "abstracts": [
            "Heap\n",
            "size of the array to use for the heap. Often the run time behaviour of a program\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "value in the heap array. If you are using a heap for reference types, i.e. objects\n",
            "Searching a heap is merely a matter of traversing the items in the heap array\n",
            "heap is the array used to store the heap items\n",
            "value 4 we would have to exhaust the whole backing heap array before we could\n",
            "heap is the array used to store the heap items\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n",
            "size for your heap array. This will assist in minimising the impact of dynamic\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n"
        ],
        "label": 0
    },
    "count list index": {
        "abstracts": [
            "list\n",
            "index ←0\n",
            "index ←0\n",
            "if index ≥list.Count or list[index] ̸= item\n",
            "1. index\n",
            "the string, wordCount is an integer that keeps track of the number of words we\n",
            "index ←0\n",
            "index\n",
            "index\n",
            "index\n"
        ],
        "label": 0
    },
    "implementation priority queue": {
        "abstracts": [
            "q ←queue\n",
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "Queues\n",
            "the queue.\n",
            "queue;\n",
            "the queue\n",
            "section we will discuss how you can, if required, implement an eﬃcient queue\n",
            "Priority Queue\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "One implementation of a priority queue is to use a heap data structure as its\n"
        ],
        "label": 0
    },
    "operation implementation factorial": {
        "abstracts": [
            "operation.\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "factorial ←1\n",
            "return factorial\n"
        ],
        "label": 0
    },
    "heap heap array used": {
        "abstracts": [
            "Heap\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "value in the heap array. If you are using a heap for reference types, i.e. objects\n",
            "Searching a heap is merely a matter of traversing the items in the heap array\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n",
            "The heap\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n"
        ],
        "label": 0
    },
    "searching data structure used": {
        "abstracts": [
            "ture d\n",
            "mon data structures; and\n",
            "Data Structures\n",
            "Searching\n",
            "store. Using a data structure like an array would require you to specify the size\n",
            "Searching\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "structure\n",
            "Searching\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "item is not already in the set, so the backing data structure we use must have\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "the correct backing data structure. As we discussed in §5.1.1 because we check\n",
            "its backing data structure is acceptable.\n",
            "data structure.\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "linked list as its baking data structure. While a node that has two pointers\n",
            "One implementation of a priority queue is to use a heap data structure as its\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "Searching\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "Figure A.1: Visualising the data structure we are operating on\n"
        ],
        "label": 0
    },
    "introduction chapter introduction book": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "introduction chapter introduction": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "method pushed stack return": {
        "abstracts": [
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n"
        ],
        "label": 0
    },
    "message summary summary": {
        "abstracts": [
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n"
        ],
        "label": 0
    },
    "recursion recursive algorithm": {
        "abstracts": [
            "algorithms.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Algorithms\n",
            "implementing recursive algorithms see Appendix C.\n",
            "Iterative algorithms\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n"
        ],
        "label": 0
    },
    "root node bst post": {
        "abstracts": [
            "that root is a reference to the root node of the tree.\n",
            "Pre: root is the root node of the tree, value is what we would like to locate\n"
        ],
        "label": 0
    },
    "recursive v": {
        "abstracts": [
            "and recursive calls—so that you can get the most eﬃcient run times for your\n",
            "pen and paper to track things like variable names, recursive calls etc.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "example, consider a token stream that you want to parse in a recursive descent\n",
            "recursive) checks a very core base case - whether or not the tree is empty. If\n",
            "cases we invoke the recursive InsertNode algorithm which simply guides us to\n",
            "perform a binary chop: we either choose to recurse into the left subtree or the\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "operate on a tree are recursive.\n",
            "recursively repeated on lesser and greater sub lists until their size is one or zero\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "implementing recursive algorithms see Appendix C.\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "cursive in nature, however here we present an iterative solution. The iterative\n",
            "from the use of recursion (for more on recursion see §C).\n",
            "recursive algorithms using the technique outlined.\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "much simple to follow when you draw out the recursive calls rather than using\n",
            "a table based approach. In this section we will use a recursive implementation\n",
            "Until we hit one of our base cases in our recursive method call tree we won’t\n",
            "return anything. The third item from the list is our recursive case.\n",
            "With each call to the recursive case we etch ever closer to one of our base\n",
            "cases. Figure A.2 shows a diagrammtic representation of the recursive call chain.\n",
            "It is important to note that each recursive call only ever returns to its caller\n",
            "that branch of recursive calls ceases. Upon hitting a base case you go back to\n",
            "contiued at the next statement, or expression after the recursive call was made.\n",
            "In the Fibonacci algorithms’ recursive case we make two recursive calls.\n",
            "When the ﬁrst recursive call (Fibonacci(n −1)) returns to the caller we then\n",
            "execute the the second recursive call (Fibonacci(n −2)). After both recursive\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "recursive calls out so you can visualise the call/return chain.\n",
            "Recursive Vs. Iterative\n",
            "recursive. One of the biggest advantages recursive methods bring to the table is\n",
            "A recursive method then is one that is deﬁned in terms of itself. Generally\n",
            "a recursive algorithms has two main properties:\n",
            "2. A recursive case\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "each recursive call we should be making progress to our base case otherwise we\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "about iterative solutions. An iterative solution uses no recursion whatsoever.\n",
            "as to their recursive counterparts with respect to their operation. The major\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "Using recursion should always be reserved for fast algorithms, you should\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "If you use recursion for algorithms with any of the above run time eﬃciency’s\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "algorithm that when invoked given a speciﬁc value it creates many recursive\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "Recursive algorithms can exhaust the stack size\n",
            "an iterative vs. recursive solution in the form of the Fibonacci algorithm. This\n",
            "is a famous example as it highlights both the beauty and pitfalls of a recursive\n",
            "run time. Don’t let this put you oﬀrecursion. This example is mainly used\n",
            "to shock programmers into thinking about the ramiﬁcations of recursion rather\n",
            "Some problems are recursive in nature\n",
            "rithms are actually recursive in nature. A perfect example of this is a tree data\n",
            "ers to two other nodes of the same node type. As you can see tree is recursive\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "of these algorithms are recursive in their design and so it makes sense to model\n",
            "them recursively.\n",
            "Recursion is a powerful tool, and one that all programmers should know of.\n",
            "which case recursion is great provided you don’t go and use it to implement\n",
            "Many times recursion has a natural home in recursive data structures and\n",
            "algorithms which are recursive in nature. Using recursion in such scenarios is\n",
            "perfectly acceptable. Using recursion for something like linked list traversal is\n",
            "recursive counterpart.\n",
            "Because we can only talk about the implications of using recursion from an\n",
            "like tail recursion and can optimise them. This isn’t unheard of, in fact most\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "to building a solution. If you adhere to progressive revisions of your algorithm\n"
        ],
        "label": 0
    },
    "implementation priority queue use": {
        "abstracts": [
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "Priority Queue\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "One implementation of a priority queue is to use a heap data structure as its\n"
        ],
        "label": 0
    },
    "recursive algorithm appendix": {
        "abstracts": [
            "algorithms.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Algorithms\n",
            "implementing recursive algorithms see Appendix C.\n",
            "Appendix A\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "Appendix B\n",
            "Appendix C\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "Appendix D\n",
            "Appendix E\n"
        ],
        "label": 0
    },
    "return list return": {
        "abstracts": [
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "given set": {
        "abstracts": [
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "Sets\n",
            "Given the set A deﬁned previously we can say that 4 is a member of A\n",
            "Given the set deﬁnitions A = {1, 2, 3}, and B = {6, 2, 9} the union of the two\n",
            "version of radix sort let us clarify what we mean by isolating keys. Given the\n",
            "A simple algorithm that determines whether or not a given integer is a prime\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "algorithm that when invoked given a speciﬁc value it creates many recursive\n",
            "allocated to the thread fairly fast given the chance.\n"
        ],
        "label": 0
    },
    "pivot list pivot list": {
        "abstracts": [
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "list\n"
        ],
        "label": 0
    },
    "problem author come": {
        "abstracts": [
            "presented are based on problems the authors have come across previously, or\n"
        ],
        "label": 0
    },
    "list index item index": {
        "abstracts": [
            "list\n",
            "Swap(list[index], list[index −1])\n",
            "index\n",
            "index\n",
            "index\n"
        ],
        "label": 0
    },
    "test unit test": {
        "abstracts": [
            "then transcribe these tests into unit tests satisfying them one by one. When\n",
            "provided in this book are unit tests. Because unit tests contribute such a core\n",
            "a suite of unit tests that verify certain boundary conditions of your software.\n",
            "for unit testing.\n",
            "What constitutes a unit test?\n",
            "A unit test should focus on a single atomic property of the subject being tested.\n",
            "given I. A unit test should be simple and self describing.\n",
            "As well as a unit test being relatively atomic you should also make sure that\n",
            "your unit tests execute quickly. If you can imagine in the future when you may\n",
            "incredibly tedious waiting several minutes to run tests on a developers local\n",
            "One of the founding principles of TDD is to write the unit test ﬁrst, watch\n",
            "duction code, e.g. all unit tests for a Person type may be contained within\n",
            "Something that you can get as a product of unit testing are code coverage\n",
            "code that your units tests cover. Using TDD it is likely that your code coverage\n"
        ],
        "label": 0
    },
    "right one ten hundred": {
        "abstracts": [
            "Unordered\n",
            "unordered.\n",
            "Right\n",
            "3. Hundreds\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "overwhelming list concern": {
        "abstracts": [
            "mentation. This in some cases will yield an overwhelming list of concerns which\n",
            "list\n"
        ],
        "label": 0
    },
    "thousand ﬁnal": {
        "abstracts": [
            "For further clariﬁcation what if we wanted to determine how many thousands\n",
            "location, e.g. 0102 here it is more obvious that the key value at the thousands\n",
            "and\n"
        ],
        "label": 0
    },
    "return true return false": {
        "abstracts": [
            "return false\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n",
            "return true;\n"
        ],
        "label": 0
    },
    "heap heap array": {
        "abstracts": [
            "Heap\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "value in the heap array. If you are using a heap for reference types, i.e. objects\n",
            "Searching a heap is merely a matter of traversing the items in the heap array\n",
            "heap is the array used to store the heap items\n",
            "value 4 we would have to exhaust the whole backing heap array before we could\n",
            "heap is the array used to store the heap items\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n",
            "The heap\n",
            "size for your heap array. This will assist in minimising the impact of dynamic\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n",
            "that we have an array taking up a considerable amount of memory yet we are\n"
        ],
        "label": 0
    },
    "respective data structure": {
        "abstracts": [
            "language. In particular, we never provide data structures or algorithms that\n",
            "ture d\n",
            "a way you can intuitively map relationships between data structures rather\n",
            "be the most important for each respective data structure.\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "Data Structures\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "store. Using a data structure like an array would require you to specify the size\n",
            "the BST is reasonably balanced; for a tree data structure with self balancing\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "Unlike other tree data structures like the one deﬁned in §3 a heap is generally\n",
            "most two children. Figure 4.1 shows how the tree (not a heap data structure)\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "so we need to choose a more dynamic data structure that contains the following\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "structure\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "item is not already in the set, so the backing data structure we use must have\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "the correct backing data structure. As we discussed in §5.1.1 because we check\n",
            "its backing data structure is acceptable.\n",
            "Queues are an essential data structure that are found in vast amounts of soft-\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "data structure.\n",
            "front of the queue. The queue data structure can be eﬃciently implemented\n",
            "frameworks also specify explicit behaviour’s that data structures must adhere to.\n",
            "which requires the data structure to expose a standard Add method. In such\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "Figure A.1: Visualising the data structure we are operating on\n",
            "At the cost of a simple table, and quick sketch of the data structure you are\n",
            "Many times recursion has a natural home in recursive data structures and\n"
        ],
        "label": 0
    },
    "heap array": {
        "abstracts": [
            "1. the list is dynamically resized, thus it incurs no copy penalty like an array\n",
            "store. Using a data structure like an array would require you to specify the size\n",
            "sizeable array, etc) to store the values of the nodes visited in breadth ﬁrst order\n",
            "Heap\n",
            "were to choose the min heap strategy then each parent node would have a value\n",
            "implemented as an array rather than a series of nodes which each have refer-\n",
            "most two children. Figure 4.1 shows how the tree (not a heap data structure)\n",
            "(12 7(3 2) 6(9 )) would be represented as an array. The array in Figure 4.1 is a\n",
            "4.2 shows arrows to the direct left and right child of each value in the array.\n",
            "an array and because this property is key to understanding this chapter Figure\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "Using just an array is often not suﬃcient as we have to be up front about the\n",
            "size of the array to use for the heap. Often the run time behaviour of a program\n",
            "1. we can specify an initial size of the array for scenarios where we know the\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Figure 4.2: Direct children of the nodes in an array representation of a tree data\n",
            "Because we are using an array we need some way to calculate the index of a\n",
            "heap order is preserved after each insertion. Generally this is a post-insertion\n",
            "operation. Inserting a value into the next free slot in an array is simple: we just\n",
            "need to keep track of the next free index in the array as a counter, and increment\n",
            "algorithm; the second is validating heap order. In the case of min-heap ordering\n",
            "by product of verifying heap order as the ﬁrst part of the algorithm (the actual\n",
            "insertion into the array) is O(1).\n",
            "heap is the array used to store the heap items\n",
            "Just as for insertion, deleting an item involves ensuring that heap ordering is\n",
            "3. verify heap ordering for each subtree which used to include the value\n",
            "heap is the array used to store the heap items\n",
            "Post: value is located in the heap and removed, true; otherwise false\n",
            "value in the heap array. If you are using a heap for reference types, i.e. objects\n",
            "Searching a heap is merely a matter of traversing the items in the heap array\n",
            "heap is the array used to store the heap items\n",
            "heap strategy being used. For instance if we had a heap that didn’t contain the\n",
            "value 4 we would have to exhaust the whole backing heap array before we could\n",
            "use of the properties presented by a certain heap strategy.\n",
            "heap is the array used to store the heap items\n",
            "is no possible way that value is in the heap. As an example consider Figure 4.7.\n",
            "you traverse the array starting at the initial array index (0 in most languages)\n",
            "and then visit each value within the array until you have reached the upper\n",
            "array. Count is used to partition the conceptual heap from the actual array\n",
            "whole array—the latter may contain various other bits of data as a result of\n",
            "Figure 4.7: Determining 10 is not in the heap after inspecting the nodes of Level\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n",
            "any other fashion requires some creative intervention. Heaps are not usually\n",
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "insertion §4.1 and deletion §4.2 sections a heap maintains heap order according\n",
            "When you come across a heap and you are not told what strategy it enforces\n",
            "you should assume that it uses the min-heap strategy.\n",
            "in the cost of dynamic array expansion at some stage. This will occur if the\n",
            "size for your heap array. This will assist in minimising the impact of dynamic\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "grammer to be explicit about the size of the array up front, this would provide\n",
            "to look at array minimization techniques as well, it could be that after several\n",
            "that we have an array taking up a considerable amount of memory yet we are\n",
            "One implementation of a priority queue is to use a heap data structure as its\n",
            "compare. Figure 8.5 shows shell sort being ran on an array of integers, the red\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "mine whether an item is in a hash table than it is an array, similarly it is quicker\n",
            "within the string into chunks of strings, resulting in an array of sub-strings.\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "an array. Then if we iterate through these words adding them to a set which\n",
            "number of stings contained in the array returned from the split operation. The\n",
            "remember we are dealing with an array) that you will work with so its important\n",
            "an array. The picture should be presenting itself - a string can be thought of as\n",
            "an array of characters.\n",
            "these strings with array indexes to aid the algorithm walkthrough.\n"
        ],
        "label": 0
    },
    "return item list": {
        "abstracts": [
            "condition, but where the return type is suﬃciently obvious it may be omitted\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "list.\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return intersection\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return true\n",
            "mine whether an item is in a hash table than it is an array, similarly it is quicker\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n"
        ],
        "label": 0
    },
    "appendix recursive v iterative": {
        "abstracts": [
            "Appendix A\n",
            "Appendix B\n",
            "Appendix C\n",
            "Recursive Vs. Iterative\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "APPENDIX C. RECURSIVE VS. ITERATIVE SOLUTIONS\n",
            "Appendix D\n",
            "Appendix E\n"
        ],
        "label": 0
    },
    "big oh notation": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "1. Big Oh notation\n",
            "Big Oh notation\n",
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "The following list explains some of the most common big Oh notations:\n",
            "The biggest asset that big Oh notation gives us is that it allows us to es-\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "Big Oh notation also acts as a communication tool. Picture the scene: you\n",
            "tions.\n",
            "tions.\n",
            "Rotation\n",
            "Rotation\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n",
            "tions.\n"
        ],
        "label": 0
    },
    "radix sort unlike sorting": {
        "abstracts": [
            "Sorting\n",
            "Radix Sort\n"
        ],
        "label": 0
    },
    "custom type check type": {
        "abstracts": [
            "Pre: value has passed custom type checks for type T\n",
            "Pre: value has passed custom type checks for type T\n"
        ],
        "label": 0
    },
    "list algorithm remove": {
        "abstracts": [
            "algorithms.\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm ReverseTraversal(head, tail)\n",
            "1) algorithm Remove(head, value)\n",
            "1) algorithm ReverseTraversal(tail)\n",
            "1) algorithm Remove(value)\n",
            "This algorithm is very similar to §3.4, but instead of returning a reference to the\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "1) algorithm Preorder(root)\n",
            "This algorithm is very similar to that described in §3.7.1, however the value\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "1) algorithm Remove(value)\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "The right and left rotation algorithms are symmetric.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "list\n",
            "implementations of the factorial algorithm are recursive as the problem is re-\n",
            "it’s predecessor in the list. The algorithm complexity still remains at O(n) but\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "1) algorithm ReverseWords(value)\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "may have to inject various calls to other utility algorithms to ascertain the\n"
        ],
        "label": 0
    },
    "requires data structure": {
        "abstracts": [
            "language. In particular, we never provide data structures or algorithms that\n",
            "as possible. However, to appreciate the designs of our data structures you will\n",
            "ture d\n",
            "a way you can intuitively map relationships between data structures rather\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "be the most important for each respective data structure.\n",
            "All the data structures and algorithms have been tested using a minimised test\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "Data Structures\n",
            "This data structure is trivial, but linked lists have a few key points which at\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "store. Using a data structure like an array would require you to specify the size\n",
            "the BST is reasonably balanced; for a tree data structure with self balancing\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "Unlike other tree data structures like the one deﬁned in §3 a heap is generally\n",
            "most two children. Figure 4.1 shows how the tree (not a heap data structure)\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "can be unpredictable when it comes to the size of its internal data structures,\n",
            "so we need to choose a more dynamic data structure that contains the following\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "structure\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "array data structure which our heap implementation is based upon. As a result\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "item is not already in the set, so the backing data structure we use must have\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "the correct backing data structure. As we discussed in §5.1.1 because we check\n",
            "its backing data structure is acceptable.\n",
            "Queues are an essential data structure that are found in vast amounts of soft-\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "queue data structure that you can use with your language of choice. In this\n",
            "data structure.\n",
            "front of the queue. The queue data structure can be eﬃciently implemented\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "frameworks also specify explicit behaviour’s that data structures must adhere to.\n",
            "which requires the data structure to expose a standard Add method. In such\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "Figure 6.2: Deque data structure after several mutations\n",
            "linked list as its baking data structure. While a node that has two pointers\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "One implementation of a priority queue is to use a heap data structure as its\n",
            "Queues are a very natural data structure, and while they are fairly primitive\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "are. Strings are probably the most common data type (and data structure -\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "Figure A.1: Visualising the data structure we are operating on\n",
            "promote the core data structure being operated on to a larger diagram outside\n",
            "At the cost of a simple table, and quick sketch of the data structure you are\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Something that you may come across is that some data structures and algo-\n",
            "adhering to the inherent design of the data structure you are operating on. Of\n",
            "Many times recursion has a natural home in recursive data structures and\n"
        ],
        "label": 0
    },
    "yield value return root": {
        "abstracts": [
            "to the caller when all values to return to the caller have been exhausted.\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "yield n.Value\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "yield n.Value\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "return ∅\n",
            "return root\n",
            "return root.Value\n",
            "return root.Value\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return wordCount\n",
            "return −1\n",
            "value\n",
            "value\n",
            "return 0\n",
            "return 1\n",
            "yield\n"
        ],
        "label": 0
    },
    "25 26 27": {
        "abstracts": [],
        "label": 0
    },
    "vast concern": {
        "abstracts": [
            "mentation. This in some cases will yield an overwhelming list of concerns which\n",
            "barded with such a vast amount of concerns look at the overall problem again\n"
        ],
        "label": 0
    },
    "thinking style functional": {
        "abstracts": [
            "mentations are based on an imperative thinking style. If you are a functional\n"
        ],
        "label": 0
    },
    "string operate": {
        "abstracts": [
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "such a primitive property is a constant operation - you just need to update\n",
            "an AVL tree that enforces self-balancing properties to help attain logarithmic\n",
            "algorithm for a max-heap the two comparison operations in the else if condition\n",
            "AVL insertion operates ﬁrst by inserting the given value the same way as BST\n",
            "It operates\n",
            "Strings\n",
            "Strings have their own chapter in this text purely because string operations\n",
            "Deﬁning algorithms for primitive string operations is simple, e.g. extracting a\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "string, rather it reverses the order of words within a string. This algorithm\n",
            "rithm uses two pointers at opposite ends of string we are checking is a palindrome\n",
            "As an example consider the string “Ben ate hay” Clearly this string contains\n",
            "we can build a more accurate unique string collection, e.g. “test”, and “test!”\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "characters in another string is pretty trivial. Put simply, we can parse the strings\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "promote the core data structure being operated on to a larger diagram outside\n"
        ],
        "label": 0
    },
    "list pivot list": {
        "abstracts": [
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "list\n"
        ],
        "label": 0
    },
    "count list index item": {
        "abstracts": [
            "index ←right\n",
            "list\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index < list.Count and list[index] = item\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index ≥list.Count or list[index] ̸= item\n",
            "Of the previously listed index keeps track of the current index we are at in\n",
            "index\n",
            "index\n",
            "index\n"
        ],
        "label": 0
    },
    "link library": {
        "abstracts": [
            "dynamic link libraries (dll); the ﬁrst containing the production code, the second\n"
        ],
        "label": 0
    },
    "nodetoremove left nodetoremove": {
        "abstracts": [
            "if nodeToRemove = ∅\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "parent = nodeToRemove\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "introduction chapter introduction chapter": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "case case correct exception": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "the correct exception.\n",
            "tions.\n"
        ],
        "label": 0
    },
    "array heap": {
        "abstracts": [
            "array (e.g. a vector).\n",
            "sizeable array, etc) to store the values of the nodes visited in breadth ﬁrst order\n",
            "Heap\n",
            "strategy. In this book you should assume that a heap employs the min heap\n",
            "implemented as an array rather than a series of nodes which each have refer-\n",
            "an array and because this property is key to understanding this chapter Figure\n",
            "In Figure 4.3 you can assume that the default capacity of our array is eight.\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "Figure 4.2: Direct children of the nodes in an array representation of a tree data\n",
            "Because we are using an array we need some way to calculate the index of a\n",
            "need to keep track of the next free index in the array as a counter, and increment\n",
            "heap is the array used to store the heap items\n",
            "3. verify heap ordering for each subtree which used to include the value\n",
            "heap is the array used to store the heap items\n",
            "heap is the array used to store the heap items\n",
            "heap strategy being used. For instance if we had a heap that didn’t contain the\n",
            "value 4 we would have to exhaust the whole backing heap array before we could\n",
            "heap is the array used to store the heap items\n",
            "array data structure which our heap implementation is based upon. As a result\n",
            "you traverse the array starting at the initial array index (0 in most languages)\n",
            "whole array—the latter may contain various other bits of data as a result of\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n",
            "in the cost of dynamic array expansion at some stage. This will occur if the\n",
            "size for your heap array. This will assist in minimising the impact of dynamic\n",
            "array resizing.\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "grammer to be explicit about the size of the array up front, this would provide\n",
            "that we have an array taking up a considerable amount of memory yet we are\n",
            "consumes more memory than its array item counterpart it makes redundant the\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "an array. Then if we iterate through these words adding them to a set which\n",
            "number of stings contained in the array returned from the split operation. The\n",
            "remember we are dealing with an array) that you will work with so its important\n",
            "an array. The picture should be presenting itself - a string can be thought of as\n",
            "these strings with array indexes to aid the algorithm walkthrough.\n"
        ],
        "label": 0
    },
    "left nodetoremove value": {
        "abstracts": [
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "if nodeToRemove.Value < parent.Value\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Left\n",
            "parent.Right ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "nodeToRemove.Value ←largestV alue.Value\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "if value < nodeToRemove.Value\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "if nodeToRemove.Value < parent.Value\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "if nodeToRemove.Value < parent.Value\n",
            "parent.Left ←nodeToRemove.Left\n",
            "parent.Right ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "nodeToRemove.Value ←largestV alue.Value\n",
            "value\n",
            "left\n",
            "1. value\n",
            "value\n",
            "left\n"
        ],
        "label": 0
    },
    "indicate factorial number": {
        "abstracts": [
            "Numeric\n",
            "Factorial of a number\n",
            "Attaining the factorial of a number is a primitive mathematical operation. Many\n",
            "factorial ←1\n"
        ],
        "label": 0
    },
    "method said stack overﬂow": {
        "abstracts": [],
        "label": 0
    },
    "11 11 11 11": {
        "abstracts": [],
        "label": 0
    },
    "end inword end": {
        "abstracts": [
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "Inorder\n",
            "end if\n",
            "9) end Inorder\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "end if\n",
            "3. inWord\n",
            "inWord ←true\n",
            "end if\n",
            "inWord ←true\n",
            "end if\n",
            "if inWord\n",
            "end if\n",
            "Word\n",
            "end if\n",
            "word\n",
            "word\n",
            "end if\n"
        ],
        "label": 0
    },
    "value value": {
        "abstracts": [
            "than trying to work out a few values on paper and the rest in your head. We\n",
            "to the caller when all values to return to the caller have been exhausted.\n",
            "while n ̸= ∅and n.Value ̸= value\n",
            "if n.Value = value\n",
            "while n.Next ̸= ∅and n.Next.Value ̸= value\n",
            "InsertNode(current.Left, value)\n",
            "1. the root = ∅in which case value is not in the BST; or\n",
            "2. root.Value = value in which case value is in the BST; or\n",
            "if root.Value = value\n",
            "return Contains(root.Left, value)\n",
            "the parent node of the one with the given value. We have found that such an\n",
            "else if root.Left.Value = value\n",
            "else if root.Right.Value = value\n",
            "if root.Value = value\n",
            "return FindNode(root.Left, value)\n",
            "were to choose the min heap strategy then each parent node would have a value\n",
            "of the properties in which all values of a heap hold, that is the property of the\n",
            "LengthOf(heapArray) −Count garbage values in the backing heap array data\n",
            "structure. The garbage values of course vary from platform to platform. To\n",
            "make things simple the garbage value of a reference type will be simple ∅and 0\n",
            "before adding it, avoiding the issue of repeated values from ever occurring.\n",
            "are either those with the smallest value, or those with the largest.\n",
            "InsertNode(current.Left, value)\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "Post: the words in value have been reversed\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "while value[index] = whitespace and index < value.Length −1\n",
            "value\n",
            "1. value\n",
            "the variable values in the table appropriately. Table A.2 shows the ﬁnal table\n",
            "value\n"
        ],
        "label": 0
    },
    "return false": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false // value not in BST\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "parent of the node with the speciﬁed value, it returns a reference to the node\n",
            "return ∅\n",
            "we are returning a reference to a node not true or false. Given FindNode,\n",
            "return value with ∅.\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false // value not in Avl\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return factorial\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "A.3 shows the call chain annotated with the return values of each method call\n",
            "return values are represented as annotations to the red arrows.\n",
            "return false;\n",
            "return false;\n",
            "• The return address is pushed onto the stack\n",
            "2. The return address is popped oﬀthe stack\n"
        ],
        "label": 0
    },
    "open source": {
        "abstracts": [
            "are closed to the reader. While implicit scope closure works well in simple code,\n",
            "actively maintain an open source project1 that houses a C# implementation of\n"
        ],
        "label": 0
    },
    "string figure 11": {
        "abstracts": [
            "in Figure 3.5.\n",
            "In Figure 4.8\n",
            "The BST in Figure 7.2 represents the worst case scenario in which the run-\n",
            "Strings\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "are the same word minus the punctuation. Figure 11.4 shows the undesired and\n",
            "in Figure A.1.\n",
            "to a larger diagram (like that in Figure A.1) and only use the trace table for\n"
        ],
        "label": 0
    },
    "string nuance": {
        "abstracts": [
            "Strings\n",
            "Counting the number of words in a string can seem pretty trivial at ﬁrst, however\n",
            "The algorithm to determine whether any character of a string matches any of the\n",
            "simple Google search on string nuances between languages and encodings will\n",
            "of some char data types, one after the other. Each character in the string can\n",
            "an array. The picture should be presenting itself - a string can be thought of as\n"
        ],
        "label": 0
    },
    "order deque": {
        "abstracts": [
            "Ordered\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "that is they are dealt with in a ﬁrst-in-ﬁrst-out (FIFO) order. Queues can be\n",
            "in a non-uniform items search the more frequent items are in the ﬁrst positions,\n"
        ],
        "label": 0
    },
    "queue sensible implementation priority": {
        "abstracts": [
            "Queues\n",
            "queue;\n",
            "Priority Queue\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n"
        ],
        "label": 0
    },
    "size internal data structure": {
        "abstracts": [
            "ture d\n",
            "mon data structures; and\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "Data Structures\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "Unlike other tree data structures like the one deﬁned in §3 a heap is generally\n",
            "most two children. Figure 4.1 shows how the tree (not a heap data structure)\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "can be unpredictable when it comes to the size of its internal data structures,\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "structure\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "Queues are an essential data structure that are found in vast amounts of soft-\n",
            "data structure.\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "One implementation of a priority queue is to use a heap data structure as its\n",
            "Queues are a very natural data structure, and while they are fairly primitive\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "All the sorting algorithms in this chapter use data structures of a speciﬁc type\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "promote the core data structure being operated on to a larger diagram outside\n",
            "At the cost of a simple table, and quick sketch of the data structure you are\n",
            "Many times recursion has a natural home in recursive data structures and\n"
        ],
        "label": 0
    },
    "priority queue": {
        "abstracts": [
            "q ←queue\n",
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "Queues\n",
            "the queue.\n",
            "Historically queues always have the following three core methods:\n",
            "queue;\n",
            "the queue\n",
            "Priority Queue\n",
            "a priority queue determines the order of its items by using a form of custom\n",
            "comparer to see which item has the highest priority. Other than the items in a\n",
            "priority queue being ordered by priority it remains the same as a normal queue:\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "ability to construct a priority queue where the items with the highest priority\n",
            "A deque applies no prioritization strategy to its items like a priority queue\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "In this chapter we have also seen priority queues where those at the front\n",
            "One implementation of a priority queue is to use a heap data structure as its\n"
        ],
        "label": 0
    },
    "number use number digit": {
        "abstracts": [
            "Pre: numberBase is the number system to use, n is the number of digits\n"
        ],
        "label": 0
    },
    "case correct exception": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "the correct exception.\n",
            "tions.\n"
        ],
        "label": 0
    },
    "clariﬁcation wanted determine thousand": {
        "abstracts": [
            "and\n"
        ],
        "label": 0
    },
    "item heap heap array": {
        "abstracts": [
            "Heap\n",
            "value in the heap array. If you are using a heap for reference types, i.e. objects\n",
            "Searching a heap is merely a matter of traversing the items in the heap array\n",
            "Figure 4.8: Living and dead space in the heap backing array\n",
            "The heap\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n"
        ],
        "label": 0
    },
    "required data structure encapsulates": {
        "abstracts": [
            "ture d\n",
            "Data Structures\n",
            "2. the data structure encapsulates resizing algorithms to grow the array as\n",
            "required at run time\n",
            "structure\n",
            "data structure.\n",
            "which requires the data structure to expose a standard Add method. In such\n"
        ],
        "label": 0
    },
    "list list pivot list": {
        "abstracts": [
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "list\n"
        ],
        "label": 0
    },
    "right nodetoremove left": {
        "abstracts": [
            "2. the node to remove is the only node in the linked list; or\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "parent.Right ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "parent.Left ←nodeToRemove.Left\n",
            "parent.Right ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "Right\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "nodeToRemove ←nodeToRemove.Left\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "parent.Right ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "parent.Left ←nodeToRemove.Left\n",
            "parent.Right ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "left\n",
            "right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "10 10 11": {
        "abstracts": [],
        "label": 0
    },
    "respective caller method exit": {
        "abstracts": [
            "spectively.\n",
            "in the call chain exit and return to their respective caller. When a method exits\n"
        ],
        "label": 0
    },
    "make problem lot easier": {
        "abstracts": [
            "sider:\n",
            "they can make many problems a lot simpler.\n",
            "domain and keeping track of changing data makes problems a lot easier to solve.\n"
        ],
        "label": 0
    },
    "inword end end end": {
        "abstracts": [
            "Inorder\n",
            "Word\n",
            "word\n",
            "word\n"
        ],
        "label": 0
    },
    "chapter introduction book": {
        "abstracts": [
            "Chapter 1\n",
            "Introduction\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "CHAPTER 1. INTRODUCTION\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "tree avl": {
        "abstracts": [
            "a node to the tail of a linked list where we always maintain a pointer to\n",
            "the BST is reasonably balanced; for a tree data structure with self balancing\n",
            "properties see AVL tree deﬁned in §7).\n",
            "Pre: root is the root node of the tree, value is what we would like to locate\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "algorithm is very useful, especially when performing extensive tree transforma-\n",
            "Tree Traversals\n",
            "subtree and ﬁnally traverse the right subtree. An example of preorder traversal\n",
            "of the node is yielded after traversing both subtrees. An example of postorder\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "the left subtree and the right subtree. An example of inorder traversal is shown\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "Trees are\n",
            "operate on a tree are recursive.\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "an AVL tree that enforces self-balancing properties to help attain logarithmic\n",
            "A heap can be thought of as a simple tree data structure, however a heap usually\n",
            "Each strategy determines the properties of the tree and its values. If you\n",
            "that is ≤than its children. For example, the node at the root of the tree will\n",
            "Unlike other tree data structures like the one deﬁned in §3 a heap is generally\n",
            "This chapter is very much centred around the notion of representing a tree as\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "Figure 4.2: Direct children of the nodes in an array representation of a tree data\n",
            "Figure 4.3: Converting a tree data structure to its array counterpart\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "subtrees cannot be no more than one, see Figure 7.1. This condition, restored\n",
            "search tree obtained by starting with an empty tree and inserting some values\n",
            "The AVL balance condition, known also as the node balance factor represents\n",
            "Figure 7.4: Tree left and right rotations\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "Post: current height has been updated while tree balance is if needed\n",
            "is only performed if the AVL property no longer holds, that is the left and right\n",
            "preserving tree balance\n",
            "then no further step are required. However, when the value is in the tree and\n",
            "its removal upsets the AVL balance property then we must perform the correct\n",
            "of the Avl\n",
            "if count = 1 // count keeps track of the # of nodes in the Avl\n",
            "root ←∅// we are removing the only node in the Avl\n",
            "the AVL tree avoids worst case linear complexity runtimes for its operations.\n",
            "The AVL tree guarantees via the enforcement of balancing algorithms that the\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "rithms are actually recursive in nature. A perfect example of this is a tree data\n",
            "of these algorithms are recursive in their design and so it makes sense to model\n"
        ],
        "label": 0
    },
    "optimisation compiler widely": {
        "abstracts": [
            "commercial compilers will do this. The amount of optimisation compilers can\n"
        ],
        "label": 0
    },
    "list list pivot": {
        "abstracts": [
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "if list[i] = pivot\n",
            "if list[i] < pivot\n",
            "if list[i] > pivot\n",
            "list\n"
        ],
        "label": 0
    },
    "binary search tree chapter": {
        "abstracts": [
            "Chapter 1\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Binary Search Tree\n",
            "Binary search trees (BSTs) are very simple to understand. We start with a root\n",
            "Figure 3.1: Simple unbalanced binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.2: binary search tree deletion cases\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "the binary search tree\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "structures that derive from BinarySearchTree.\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "Figure 3.6: Breadth First visit binary search tree example\n",
            "CHAPTER 3. BINARY SEARCH TREE\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "- that the binary search tree’s left and right subtrees are reasonably balanced.\n",
            "when this is true. A binary search tree does not enforce such a property, and\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "In DSA 0.5 and earlier we used a binary search tree (deﬁned in §3) as the\n",
            "we replaced the binary search tree with an AVL tree primarily because AVL is\n",
            "however the logarithmic growth that we incur by using a binary search tree as\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "An AVL tree is a binary search tree (BST, deﬁned in §3) with a self-balancing\n",
            "Figure 7.2: Unbalanced binary search tree\n",
            "A tree rotation is a constant time operation on a binary search tree that changes\n",
            "the smarter, younger brother of the binary search tree. Unlike its older brother\n",
            "Chapter 8\n",
            "Chapter 9\n",
            "Chapter 10\n",
            "name for binary search, binary chop usually refers to its array counterpart) as\n",
            "Chapter 11\n"
        ],
        "label": 0
    },
    "list return item": {
        "abstracts": [
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return root\n",
            "return ∅\n",
            "return root\n",
            "itself. Again, ∅is returned if the value isn’t found.\n",
            "return ∅\n",
            "return root\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "Post: return index of item if found, otherwise −1\n",
            "return index\n",
            "return −1\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return index\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return true;\n"
        ],
        "label": 0
    },
    "10 10 11 11": {
        "abstracts": [],
        "label": 0
    },
    "scope end": {
        "abstracts": [],
        "label": 0
    },
    "10 10 10 11": {
        "abstracts": [],
        "label": 0
    },
    "zero pre list mean": {
        "abstracts": [
            "list\n"
        ],
        "label": 0
    },
    "method said stack": {
        "abstracts": [],
        "label": 0
    },
    "mainstream programming language target": {
        "abstracts": [
            "imperative programming languages. It is not a deﬁnitive book on the theory of\n",
            "2. An imperative programming language\n",
            "Imperative programming language\n",
            "must know the basics of some imperative mainstream programming language\n"
        ],
        "label": 0
    },
    "explicitly state end leaving": {
        "abstracts": [
            "The last major point of reference is that we always explicitly end a language\n",
            "explicitly state end for rather than leaving the interpretation of when scopes\n"
        ],
        "label": 0
    },
    "return false return true": {
        "abstracts": [
            "return false\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return true\n",
            "return true\n",
            "return false\n",
            "return true\n",
            "return false\n",
            "return false\n",
            "return true\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return true\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n",
            "return true;\n"
        ],
        "label": 0
    },
    "priority queue use": {
        "abstracts": [
            "Heaps are most commonly used to implement priority queues (see §6.2 for a\n",
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "Priority Queue\n",
            "a priority queue determines the order of its items by using a form of custom\n",
            "priority queue being ordered by priority it remains the same as a normal queue:\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "ability to construct a priority queue where the items with the highest priority\n",
            "A deque applies no prioritization strategy to its items like a priority queue\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "In this chapter we have also seen priority queues where those at the front\n",
            "One implementation of a priority queue is to use a heap data structure as its\n"
        ],
        "label": 0
    },
    "previous algorithm consider adding": {
        "abstracts": [
            "algorithms.\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "sider:\n",
            "Consider a binary\n",
            "Algorithms\n"
        ],
        "label": 0
    },
    "end remove algorithm": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "themselves based on the concepts by which the respective algorithms are based\n",
            "algorithms.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "respective algorithm is? No. The result of such a discussion will tell you more\n",
            "describes the eﬀect of the algorithms operation. An example of a post-condition\n",
            "Often while working through algorithms in such\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "driven development style on paper to ﬂesh out the pseudocode algorithm. We\n",
            "1. Understand how the algorithm works ﬁrst in an abstract sense; and\n",
            "As an example of the previous algorithm consider adding the following se-\n",
            "can create much more concise algorithms. In the case of always removing from\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "The only major diﬀerence between the algorithm in §2.1.1 is that we need to\n",
            "Figure 2.6 shows the reverse traversal algorithm in action.\n",
            "count during the insertion and deletion algorithms.\n",
            "cases we invoke the recursive InsertNode algorithm which simply guides us to\n",
            "but we will look brieﬂy at the premise of the algorithm nonetheless.\n",
            "The Remove algorithm given below relies on two further helper algorithms\n",
            "A special case in the above algorithm is when the speciﬁed value does not\n",
            "Astute readers will have noticed that the FindNode algorithm is exactly the\n",
            "The base case in both FindMin, and FindMax algorithms is when the Left\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "We can only attain logarithmic run times for the algorithms presented earlier\n",
            "preserved. The algorithm for deletion has three steps:\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "not satisﬁed for any level of nodes that we are inspecting then the algorithm\n",
            "invocation of the insertion, and deletion algorithms. The cost of such a policy is\n",
            "that upon each insertion and deletion we invoke algorithms that have logarithmic\n",
            "those of a normal queue, or priority queue. In some cases the set of algorithms\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "need for expensive resizing algorithms as the data structure increases in size\n",
            "Algorithms\n",
            "O(n log n) and is fairly trivial to implement. The algorithm is based on splitting\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "however these algorithms ought to be pretty eﬃcient, e.g. implementing a linear,\n",
            "implementing recursive algorithms see Appendix C.\n",
            "sub-string of a string, however some algorithms that require more inventiveness\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "In the IsPalindrome algorithm we call a method by the name of Strip. This\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "With the help of an unordered set, and an algorithm that can split the words\n",
            "We hope that the reader has seen how fun algorithms on string data types\n",
            "rithm. The values within this table are constantly updated when the algorithm\n",
            "generated by the algorithm it can make understanding, and solving problems\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "operating on you can devise correct algorithms quicker. Visualising the problem\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "through an iterative algorithm. One of the things that we need to keep track\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "The ﬁrst two items in the preceeding list are the base cases of the algorithm.\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "APPENDIX A. ALGORITHM WALKTHROUGH\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "method call diagrams to understand how the algorithm works at a high level.\n",
            "tation perspective. In order to understand an algorithm try and work through\n",
            "it using trace tables. In cases where the algorithm is also recursive sketch the\n",
            "translation of our pseudo code algorithms to mainstream imperative languages\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "etc). The down side to iterative algorithms is that they tend not to be as clear\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "you are inviting trouble. The growth rate of these algorithms is high and in\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n",
            "you add or tweak algorithms and then run your suite of tests you will be quickly\n"
        ],
        "label": 0
    },
    "respective data structure data": {
        "abstracts": [
            "language. In particular, we never provide data structures or algorithms that\n",
            "ture d\n",
            "a way you can intuitively map relationships between data structures rather\n",
            "mon data structures; and\n",
            "be the most important for each respective data structure.\n",
            "all the pseudocode listed. The project is named Data Structures and Algorithms\n",
            "Data Structures\n",
            "Singly linked lists are one of the most primitive data structures you will ﬁnd in\n",
            "recursive data structures, so typically you will ﬁnd that many algorithms that\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "so we need to choose a more dynamic data structure that contains the following\n",
            "structure\n",
            "the correct backing data structure. As we discussed in §5.1.1 because we check\n",
            "Queues are an essential data structure that are found in vast amounts of soft-\n",
            "queue data structure that you can use with your language of choice. In this\n",
            "data structure.\n",
            "which requires the data structure to expose a standard Add method. In such\n",
            "A deque is a wrapper data structure that uses either an array, or a doubly\n",
            "Figure 6.2: Deque data structure after several mutations\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "often then we strongly advise that you sit down and research the data structures\n",
            "Many times recursion has a natural home in recursive data structures and\n"
        ],
        "label": 0
    },
    "pivot list pivot": {
        "abstracts": [
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "list\n"
        ],
        "label": 0
    },
    "list list return": {
        "abstracts": [
            "to point out here is yield. You can think of yield in the same light as return.\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "list\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n"
        ],
        "label": 0
    },
    "rotation subsequently": {
        "abstracts": [
            "tions.\n",
            "tions.\n",
            "Rotation\n",
            "Rotation\n",
            "ﬁrst performs a left rotation and then subsequently a right rotation.\n",
            "calls have returned to their caller, the caller can then subesequently return to\n",
            "tions.\n"
        ],
        "label": 0
    },
    "self right rotation": {
        "abstracts": [
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "tions.\n",
            "tions.\n",
            "Tree Rotations\n",
            "right rotations both of them decrease the height of a BST by moving smaller\n",
            "Right\n",
            "Rotation\n",
            "Rotation\n",
            "Figure 7.4: Tree left and right rotations\n",
            "1) algorithm RightRotation(node)\n",
            "9) end RightRotation\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "The algorithms are self documenting in their names, e.g. LeftAndRightRotation\n",
            "ﬁrst performs a left rotation and then subsequently a right rotation.\n",
            "restored through rotations\n",
            "LeftAndRightRotation(current)\n",
            "rotation(s).\n",
            "right\n",
            "right\n",
            "tions.\n"
        ],
        "label": 0
    },
    "case conditional line 25": {
        "abstracts": [
            "// this is only case 5 if the conditional on line 25 was false\n"
        ],
        "label": 0
    },
    "mathematical operation implementation factorial": {
        "abstracts": [
            "operation.\n",
            "factorial ←1\n",
            "return factorial\n"
        ],
        "label": 0
    },
    "avl tree avl tree": {
        "abstracts": [
            "properties see AVL tree deﬁned in §7).\n",
            "an AVL tree that enforces self-balancing properties to help attain logarithmic\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "AVL Tree\n",
            "balancing binary search tree data structure, calling it AVL Tree.\n",
            "the AVL tree avoids worst case linear complexity runtimes for its operations.\n"
        ],
        "label": 0
    },
    "overwhelming list concern barded": {
        "abstracts": [
            "mentation. This in some cases will yield an overwhelming list of concerns which\n",
            "list\n"
        ],
        "label": 0
    },
    "case yield true false": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "Post: node with value is removed if found in which case yields true, otherwise false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "case yields true, otherwise false\n",
            "return false\n",
            "return false\n",
            "return false;\n",
            "return false;\n",
            "yield\n"
        ],
        "label": 0
    },
    "linked list straightforward": {
        "abstracts": [
            "The pseudocode style that we use within this book is rather straightforward.\n",
            "Linked Lists\n",
            "linked list.\n",
            "Searching a linked list is straightforward: we simply traverse the list checking\n",
            "Deleting a node from a linked list is straightforward but there are a few cases\n",
            "Traversing a singly linked list in a forward manner (i.e. left to right) is simple\n",
            "Singly linked lists have a forward only design, which is why the reverse traversal\n",
            "Removing a node from a BST is fairly straightforward, with four cases to con-\n",
            "Right\n",
            "Shell sort is fairly straight forward but may seem somewhat confusing at\n",
            "list\n",
            "within a string using a speciﬁed delimiter this algorithm is straightforward to\n",
            "right\n",
            "right\n",
            "For the most part the conversion is a straight forward process, however you\n"
        ],
        "label": 0
    },
    "return false return": {
        "abstracts": [
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return ∅\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return false\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return list\n",
            "return false\n",
            "return m\n",
            "return 1\n",
            "return −1\n",
            "return false\n",
            "return sb\n",
            "return 0\n",
            "return −1\n",
            "return 0\n",
            "return 1\n",
            "return false;\n",
            "return false;\n"
        ],
        "label": 0
    },
    "list pre list list": {
        "abstracts": [
            "list\n"
        ],
        "label": 0
    },
    "order post list": {
        "abstracts": [
            "adds a node to the list, you can assume that you are adding the node to the tail\n",
            "Pre: tail is the tail node of the list to traverse\n",
            "list.\n",
            "An ordered set is similar to an unordered set in the sense that its members are\n",
            "list\n"
        ],
        "label": 0
    },
    "node bst root": {
        "abstracts": [],
        "label": 0
    },
    "root dequeue enqueue": {
        "abstracts": [
            "Queues\n",
            "queue;\n",
            "the queue\n",
            "• EnqueueBack\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "queues ←Queue[10]\n"
        ],
        "label": 0
    },
    "greater equal greater": {
        "abstracts": [],
        "label": 0
    },
    "algorithm described": {
        "abstracts": [
            "ing algorithm designs you may just have the intention of solving the problem\n",
            "review your algorithm design and optimise where possible—particularly loops\n",
            "algorithms.\n",
            "about the high level algorithm design rather than its eﬃciency. Replay the scene\n",
            "back in your head, but this time as well as talking about algorithm design each\n",
            "The algorithm described is a very simple one that makes use of a simple\n",
            "algorithm deﬁned in §2.1.5 required some creative invention. Doubly linked lists\n",
            "same as the Contains algorithm (deﬁned in §3.2) with the modiﬁcation that\n",
            "Another variation of the algorithms deﬁned in §3.7.1 and §3.7.2 is that of inorder\n",
            "The new Contains algorithm determines if the value is not in the heap by\n",
            "these algorithms. Most of the algorithms deﬁned in System.Linq.Enumerable\n",
            "A queue is implicitly like that described prior to this section. In DSA we don’t\n",
            "An algorithm described\n",
            "Algorithms\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "O(n log n) and is fairly trivial to implement. The algorithm is based on splitting\n",
            "Unlike the sorting algorithms described previously radix sort uses buckets to\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "1) algorithm IsPrime(n)\n",
            "the option Octal to an integer we would get the value 8. In the algorithm listed\n",
            "presented more eﬃcient searching algorithms earlier on, like for instance the\n",
            "The algorithm presented here does not simply reverse the characters in a\n",
            "algorithm discards punctuation in the string, including white space. As a result\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n"
        ],
        "label": 0
    },
    "left preorder root left": {
        "abstracts": [
            "Preorder\n",
            "Preorder(root.Left)\n",
            "Postorder(root.Left)\n",
            "Inorder(root.Left)\n",
            "Left\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "preorder root right postorder": {
        "abstracts": [
            "no right subtree\n",
            "Preorder\n",
            "Preorder(root.Right)\n",
            "Postorder\n",
            "Inorder(root.Right)\n",
            "Right\n",
            "right\n",
            "right\n"
        ],
        "label": 0
    },
    "28 29 31": {
        "abstracts": [],
        "label": 0
    },
    "thousand ﬁnal like obvious": {
        "abstracts": [
            "and\n"
        ],
        "label": 0
    },
    "10 11 11": {
        "abstracts": [],
        "label": 0
    },
    "represent type": {
        "abstracts": [
            "budgets per feature. Each feature holds with it a budget that represents its up-\n",
            "2. Post-conditions represent the result of applying algorithm a to data struc-\n",
            "Each of the chapters on data structures present initially the algorithms con-\n",
            "The previous list represents what we believe in the vast majority of cases to\n",
            "last node’s case a null pointer representing that there are no more nodes in the\n",
            "A binary search tree is a good solution when you need to represent types that are\n",
            "(12 7(3 2) 6(9 )) would be represented as an array. The array in Figure 4.1 is a\n",
            "This chapter is very much centred around the notion of representing a tree as\n",
            "4.3 shows a step by step process to represent a tree data structure as an array.\n",
            "Figure 4.1: Array representation of a simple tree data structure\n",
            "Figure 4.2: Direct children of the nodes in an array representation of a tree data\n",
            "In Figure 4.4 a) represents the calculation of the right child of 12 (2 ∗0 + 2);\n",
            "value in the heap array. If you are using a heap for reference types, i.e. objects\n",
            "make things simple the garbage value of a reference type will be simple ∅and 0\n",
            "The BST in Figure 7.2 represents the worst case scenario in which the run-\n",
            "The AVL balance condition, known also as the node balance factor represents\n",
            "present in the nodes are not changed.\n",
            "The algorithm that we present in this section veriﬁes that the left and right\n",
            "subtrees diﬀer at most in height by 1. If this property is not present then we\n",
            "Notice that we use two new algorithms that represent double rotations.\n",
            "maxKeySize ≥0 and represents the largest key size in the list\n",
            "representation of 10011102.\n",
            "Post: n has been converted into its base 2 representation\n",
            "represented as FFFFFF16 which yields 1677721510.\n",
            "cursive in nature, however here we present an iterative solution. The iterative\n",
            "In this chapter we have presented several numeric algorithms, most of which\n",
            "word contains a heavily compacted representation of the original string, each\n",
            "character of which is in its uppercase representation.\n",
            "or not at the present time we are within a word. If we are not currently hitting\n",
            "white space we are in a word, the opposite is true if at the present index we are\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "between any characters thus returning a non-negative index that represents the\n",
            "Post: index representing match location if occured, −1 otherwise\n",
            "visual representation of the problem as well as having a history of past values\n",
            "represented? A string is essentially a block of contiguous memory that consists\n",
            "odd or even” Now we know how the string data structure is represented, and\n",
            "Before we jump into showing you a diagrammtic representation of the algo-\n",
            "cases. Figure A.2 shows a diagrammtic representation of the recursive call chain.\n",
            "return values are represented as annotations to the red arrows.\n"
        ],
        "label": 0
    },
    "list pivot list pivot": {
        "abstracts": [
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "Pivot\n",
            "list\n"
        ],
        "label": 0
    },
    "problem algorithm use": {
        "abstracts": [
            "algorithms.\n",
            "You are discussing prototype algorithms for node discovery in massive networks.\n",
            "All algorithms start with a simple algorithm signature, e.g.\n",
            "Part 2: Provides algorithms of varying purposes from sorting to string operations.\n",
            "Astute readers will have noticed that the FindNode algorithm is exactly the\n",
            "When using the preorder algorithm, you visit the root ﬁrst, then traverse the left\n",
            "Figure 4.6 shows the Remove algorithm visually, removing 1 from a heap\n",
            "Algorithms\n",
            "The algorithms discussed can easily be translated into generic sorting algo-\n",
            "Figure 8.6 shows the members of queues from the algorithm described above\n",
            "quadratic, or slower algorithm using recursion would be a very bad idea.\n",
            "implementing recursive algorithms see Appendix C.\n",
            "A simple algorithm that determines whether or not a given integer is a prime\n",
            "A simple algorithm that search for a speciﬁc item inside a list.\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "In the IsPalindrome algorithm we call a method by the name of Strip. This\n",
            "allows us to design a simple algorithm while making our algorithm fairly robust\n",
            "recursive algorithms using the technique outlined.\n",
            "We will trace the IsPalindrome algorithm (deﬁned in §11.2) as our example\n",
            "iterative walkthrough. Before we even look at the variables the algorithm uses,\n",
            "The IsPalindrome algorithm uses the following list of variables in some form\n",
            "Now, using the IsPalindrome algorithm execute each statement updating\n"
        ],
        "label": 0
    },
    "chapter 11 string algorithm": {
        "abstracts": [
            "Chapter 1\n",
            "algorithms.\n",
            "sentially discard things like hardware. If you have two sorting algorithms, one\n",
            "the sorting algorithms.\n",
            "Chapter 2\n",
            "Chapter 3\n",
            "Chapter 4\n",
            "Chapter 5\n",
            "Chapter 6\n",
            "Chapter 7\n",
            "Algorithms\n",
            "Chapter 8\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "Insertion sort is a somewhat interesting algorithm with an expensive runtime of\n",
            "CHAPTER 8. SORTING\n",
            "ﬁrst as it diﬀers from other sorting algorithms in the way it selects items to\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "CHAPTER 8. SORTING\n",
            "Chapter 9\n",
            "the reader should gain from this chapter is that algorithms can be applied to\n",
            "Chapter 10\n",
            "We decided not to cover a searching algorithm known as binary chop (another\n",
            "Chapter 11\n",
            "Strings\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "CHAPTER 11. STRINGS\n",
            "structured approach to tracing its behaviour. In most cases tracing an algorithm\n",
            "variables whose values change during the algorithm. We recommend that you\n"
        ],
        "label": 0
    },
    "root root node bst": {
        "abstracts": [
            "that root is a reference to the root node of the tree.\n",
            "CheckBalance(path.Pop()) // we trackback to the root node check balance\n"
        ],
        "label": 0
    },
    "string number": {
        "abstracts": [
            "which takes a single numeric parameter n. The pre and post conditions follow\n",
            "Numeric\n",
            "denominator of two integers, what we are essentially after is the greatest number\n",
            "Strings\n",
            "value ̸= ∅, sb is a string buﬀer\n",
            "// append chars from start + 1 to length + 1 to string buﬀer sb\n",
            "Figure 11.3: String with varying number of white space delimiting the words\n",
            "simple Google search on string nuances between languages and encodings will\n",
            "an array. The picture should be presenting itself - a string can be thought of as\n",
            "For our example we will use IsPalindrome to operate on the string “Never\n"
        ],
        "label": 0
    },
    "left nodetoremove right": {
        "abstracts": [
            "2. the node to remove is the only node in the linked list; or\n",
            "5. the node to remove is somewhere in between the head and tail; or\n",
            "2. the value to remove has a right subtree, but no left subtree; or\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "parent.Left ←nodeToRemove.Right\n",
            "parent.Right ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "parent.Left ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "Right\n",
            "Left\n",
            "nodeToRemove ←root\n",
            "while nodeToRemove ̸= ∅and nodeToRemove.V alue = V alue\n",
            "nodeToRemove ←nodeToRemove.Right\n",
            "if nodeToRemove = ∅\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right = null\n",
            "else if nodeToRemove.Left = ∅and nodeToRemove.Right ̸= ∅\n",
            "parent.Left ←nodeToRemove.Right\n",
            "parent.Right ←nodeToRemove.Right\n",
            "else if nodeToRemove.Left ̸= ∅and nodeToRemove.Right = ∅\n",
            "parent.Left ←nodeToRemove.Left\n",
            "largestV alue ←nodeToRemove.Left\n",
            "// ﬁnd the largest value in the left subtree of nodeToRemove\n",
            "left\n",
            "right\n",
            "4. right\n",
            "left\n",
            "right\n"
        ],
        "label": 0
    },
    "introduction book outline": {
        "abstracts": [
            "Introduction\n",
            "Book outline\n"
        ],
        "label": 0
    },
    "item deque respect algorithmic": {
        "abstracts": [
            "themselves based on the concepts by which the respective algorithms are based\n",
            "algorithms.\n",
            "Queues\n",
            "With respect to algorithmic run time complexities a deque is the same as\n",
            "Algorithms\n"
        ],
        "label": 0
    },
    "summary summary summary summary": {
        "abstracts": [
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n",
            "Summary\n"
        ],
        "label": 0
    },
    "oh notation run": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "1. Big Oh notation\n",
            "Big Oh notation\n",
            "For run time complexity analysis we use big Oh notation extensively so it is vital\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "The following list explains some of the most common big Oh notations:\n",
            "The biggest asset that big Oh notation gives us is that it allows us to es-\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "Big Oh notation also acts as a communication tool. Picture the scene: you\n",
            "The notation A = {4, 7, 9, 12, 0} deﬁnes a set A whose values are listed within\n",
            "Rotation\n",
            "Rotation\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n"
        ],
        "label": 0
    },
    "27 28": {
        "abstracts": [],
        "label": 0
    },
    "height current left height": {
        "abstracts": [
            "if current.Left = ∅\n",
            "of eight.\n",
            "Left\n",
            "current.Height = Max(Height(current.Left),Height(current.Right)) + 1\n",
            "if Height(current.Left) - Height(current.Right) > 1\n",
            "else if Height(current.Left) - Height(current.Right) < −1\n",
            "if current.Left = ∅\n",
            "left\n",
            "left\n"
        ],
        "label": 0
    },
    "recursive algorithm operating": {
        "abstracts": [
            "algorithms.\n",
            "When dealing with recursive algorithm traces we recommend you do the\n",
            "operation.\n",
            "Algorithms\n",
            "implementing recursive algorithms see Appendix C.\n",
            "It operates\n",
            "IsPalindrome algorithm in operation on the string “Was it Eliot’s toilet I saw?”\n",
            "want to use a diagram of the data structure your algorithm operates on. This\n",
            "recursive algorithms using the technique outlined.\n",
            "Iterative algorithms\n",
            "ﬁrst we will look at the actual data structure the algorithm operates on. It\n",
            "Recursive Algorithms\n",
            "For the most part working through recursive algorithms is as simple as walking\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "Recursive algorithms are much easier to demonstrate diagrammatically as\n",
            "Figure A.2 demonstrates. When you come across a recursive algorithm draw\n",
            "a recursive algorithms has two main properties:\n",
            "For now we will brieﬂy cover these two aspects of recursive algorithms. With\n",
            "Now that we have brieﬂy described what a recursive algorithm is and why\n",
            "ﬁnd uses little or no recursive algorithms whatsoever. The latter property can\n",
            "contains no recursive algorithms. Normally it is systems level code that has this\n",
            "zero tolerance policy for recursive algorithms.\n",
            "In many recursive algorithms operating on large data structures, or algo-\n",
            "Recursive algorithms can exhaust the stack size\n",
            "When using recursive algorithms on tree’s it makes sense as you are simply\n"
        ],
        "label": 0
    },
    "set eﬃciently implemented": {
        "abstracts": [
            "An unordered set can be eﬃciently implemented using a hash table as its backing\n",
            "front of the queue. The queue data structure can be eﬃciently implemented\n",
            "eﬃcient.\n"
        ],
        "label": 0
    },
    "11 11 11": {
        "abstracts": [],
        "label": 0
    },
    "ordered set": {
        "abstracts": [
            "considered the norm.\n",
            "ordered type, no value can simultaneously satisfy the conditions to place it in\n",
            "Figure 3.3: Preorder visit binary search tree example\n",
            "Figure 3.4: Postorder visit binary search tree example\n",
            "Figure 3.5: Inorder visit binary search tree example\n",
            "inorder strategy, the yielded sequence would have property xi ≤xi+1∀i.\n",
            "ordered according to some custom rules inherent to that type. With logarithmic\n",
            "by product of verifying heap order as the ﬁrst part of the algorithm (the actual\n",
            "to the selected ordering strategy. These strategies are referred to as min-heap,\n",
            "Sets\n",
            "Unordered\n",
            "Most libraries provide implementations of unordered sets and so DSA does\n",
            "not; we simply mention it here to disambiguate between an unordered set and\n",
            "ordered set.\n",
            "We will only look at insertion for an unordered set and cover brieﬂy why a\n",
            "An unordered set can be eﬃciently implemented using a hash table as its backing\n",
            "Ordered\n",
            "An ordered set is similar to an unordered set in the sense that its members are\n",
            "distinct, but an ordered set enforces some predeﬁned comparison on each of its\n",
            "members to produce a set whose members are ordered appropriately.\n",
            "internal backing data structure for our ordered set. From versions 0.6 onwards\n",
            "The ordered set has its order realised by performing an inorder traversal\n",
            "upon its backing tree data structure which yields the correct ordered sequence\n",
            "Because an ordered set in DSA is simply a wrapper for an AVL tree that\n",
            "Sets provide a way of having a collection of unique objects, either ordered or\n",
            "unordered.\n",
            "When implementing a set (either ordered or unordered) it is key to select\n",
            "this check to be as quick as possible. For unordered sets we can rely on the use\n",
            "constant run time complexity. Ordered sets cost a little more for this check,\n",
            "tion, for a hash table this run time complexity should be near constant. Ordered\n",
            "less clear in their implementation. For example in §11.4 we use an unordered\n",
            "Unlike a standard queue where items are ordered in terms of who arrived ﬁrst,\n",
            "priority queue being ordered by priority it remains the same as a normal queue:\n",
            "Note: the function MergeOrdered simply takes two ordered lists and makes\n",
            "return MergeOrdered(left, right)\n",
            "the intent of building up an ordered set of cards in your hand.\n",
            "In the following algorithm numberBase should be considered restricted to\n",
            "With the help of an unordered set, and an algorithm that can split the words\n",
            "desired sets for the unique set respectively.\n"
        ],
        "label": 0
    },
    "property deque denoted": {
        "abstracts": [],
        "label": 0
    },
    "pre list pre": {
        "abstracts": [
            "The previous list represents what we believe in the vast majority of cases to\n",
            "Post: value is removed from the list, true; otherwise false\n",
            "Traversing the list in reverse order\n",
            "Doubly linked lists are very similar to singly linked lists. The only diﬀerence is\n",
            "The following algorithms for the doubly linked list are exactly the same as\n",
            "those listed previously for the singly linked list:\n",
            "Post: value is removed from the list, true; otherwise false\n",
            "Figure 2.6: Doubly linked list reverse traversal\n",
            "Linked lists are good to use when you have an unknown number of items to\n",
            "What linked lists are not very good for is random insertion, accessing nodes\n",
            "sertions. In general doubly linked lists are more accommodating for non-trivial\n",
            "heap order is preserved after each insertion. Generally this is a post-insertion\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "item at the head of a singly linked list, removal is simply a case of returning\n",
            "Pre: list ̸= ∅\n",
            "Pre: list ̸= ∅\n",
            "Pre: list ̸= ∅\n",
            "Pre: list ̸= ∅\n",
            "Pre: list ̸= ∅\n",
            "list\n"
        ],
        "label": 0
    },
    "false case case case": {
        "abstracts": [],
        "label": 0
    },
    "implementation factorial": {
        "abstracts": [
            "This book provides implementations of common and uncommon algorithms in\n",
            "upon so it is more than possible that our implementations diﬀer from those\n",
            "implementations in this book.\n",
            "systematic way to make your time studying the implementations far easier.\n",
            "Part 1: Provides discussion and pseudo-implementations of common and uncom-\n",
            "The only type of testing that we use in the implementation of all that is\n",
            "actively maintain an open source project1 that houses a C# implementation of\n",
            "In DSA our implementations of linked lists always maintain head and tail\n",
            "implementation of the heap: we only care about the items in the heap, not the\n",
            "Generally set implementations tend to check that a value is not in the set\n",
            "tem.Linq.Enumerable2, as a result DSA does not provide implementations of\n",
            "Most libraries provide implementations of unordered sets and so DSA does\n",
            "hash table is an eﬃcient data structure to use for its implementation.\n",
            "less clear in their implementation. For example in §11.4 we use an unordered\n",
            "A sensible implementation of a priority queue is to use a heap data structure\n",
            "One implementation of a priority queue is to use a heap data structure as its\n",
            "For this reason in our actual implementation\n",
            "checks to determine the correct base to use. For our implementation we cast the\n",
            "factorial ←1\n",
            "return factorial\n",
            "a table based approach. In this section we will use a recursive implementation\n",
            "implementation of algorithms. At any one stage you only have a single goal, to\n",
            "have coded up your implementation. We, as the authors of this book ourselves\n"
        ],
        "label": 0
    },
    "order deque property deque": {
        "abstracts": [
            "Ordered\n"
        ],
        "label": 0
    },
    "algorithm add value": {
        "abstracts": [
            "themselves based on the concepts by which the respective algorithms are based\n",
            "algorithms.\n",
            "If an algorithm has a return type it will often be presented in the post-\n",
            "tell the caller why the algorithm has failed to execute normally.\n",
            "used within our algorithms and their meaning. One keyword that we would like\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Add(value)\n",
            "1) algorithm Add(value)\n",
            "invocations of the resizing algorithm and various mutations on the deque later\n",
            "These algorithms are named LeftAndRightRotation, and RightAndLeftRotation.\n",
            "Algorithms\n",
            "mentation. Some algorithms are very nicely expressed in a recursive fashion,\n",
            "1) algorithm MaxValue(numberBase, n)\n",
            "logarithmic searching algorithm that AVL and BST tree’s use (deﬁned in §3.2).\n",
            "Searching algorithms and their eﬃciency largely depends on the underlying\n",
            "value\n",
            "1. value\n",
            "value\n",
            "of though is which method call returns to who. Most recursive algorithms are\n",
            "you add or tweak algorithms and then run your suite of tests you will be quickly\n"
        ],
        "label": 0
    },
    "problem author": {
        "abstracts": [
            "intuitively identify areas which may cause problems for your algorithms imple-\n",
            "and sub-divide the problem into smaller problems. Solving the smaller problems\n",
            "The problem with the previous algorithm is that we don’t take advantage\n",
            "they can make many problems a lot simpler.\n",
            "A fairly routine problem in mathematics is that of ﬁnding the greatest common\n",
            "diagram will be used to visualise the problem more eﬀectively. Seeing things\n",
            "domain and keeping track of changing data makes problems a lot easier to solve.\n",
            "While constantly splitting problems into smaller problems is good\n",
            "Some problems are recursive in nature\n",
            "or\n"
        ],
        "label": 0
    },
    "oh notation big oh": {
        "abstracts": [
            "the abstract big Oh notation to depict the run time complexity of algorithms\n",
            "1. Big Oh notation\n",
            "algorithm for you in certain scenarios. We have chosen to use big Oh notation\n",
            "The biggest asset that big Oh notation gives us is that it allows us to es-\n",
            "chine that is far faster than the latter. Why? Because big Oh notation isolates\n",
            "Big Oh notation also acts as a communication tool. Picture the scene: you\n",
            "right rotations both of them decrease the height of a BST by moving smaller\n",
            "Rotation\n",
            "Rotation\n",
            "attain the factorial of. Our algorithm doesn’t use such notation but it is handy\n"
        ],
        "label": 0
    },
    "number consists digit": {
        "abstracts": [
            "Numeric\n",
            "Post: the maximum value for numberBase consisting of n digits is computed\n"
        ],
        "label": 0
    },
    "list index": {
        "abstracts": [
            "The following list explains some of the most common big Oh notations:\n",
            "last node’s case a null pointer representing that there are no more nodes in the\n",
            "operation. As such, linked lists in DSA have the following characteristics:\n",
            "node(s) at the head and tail of the linked list and so performing a traditional\n",
            "insertion to either the front or back of the linked list is an O(1) operation. An\n",
            "1. the list is dynamically resized, thus it incurs no copy penalty like an array\n",
            "Figure 2.1: Singly linked list node\n",
            "algorithm listed in this section is very similar to that used for traversal in §2.1.4.\n",
            "1. the list is empty; or\n",
            "where within a list irrespective of whether the node is the head etc. If you know\n",
            "the front of the linked list deletion becomes an O(1) operation.\n",
            "list (deﬁned in §2.2). You start at the head of the list and continue until you\n",
            "Traversing the list in reverse order\n",
            "Traversing a singly linked list in a forward manner (i.e. left to right) is simple\n",
            "the linked list in reverse order for some reason? The algorithm to perform such\n",
            "as you will soon see that doubly linked lists (deﬁned in §2.2) make reverse list\n",
            "Figure 2.4: Doubly linked list node\n",
            "In this scenario a doubly linked list is best as its design makes\n",
            "reached the last node.\n",
            "Because we are using an array we need some way to calculate the index of a\n",
            "deﬁned as follows for a node at index:\n",
            "1. (index −1)/2 (parent index)\n",
            "and b) calculates the index of the parent of 3 ((3 −1)/2).\n",
            "1. ﬁnd the index of the value to delete\n",
            "2. put the last value in the heap at the index location of the item to delete\n",
            "if index < 0\n",
            "Swap(heap, left, index)\n",
            "Swap(heap, right, index)\n",
            "For this example we can further assume that at some point the items in indexes\n",
            "ing the mutations upon the queue data structure. The following list describes\n",
            "using a singly linked list (deﬁned in §2.1). A singly linked list provides O(1)\n",
            "returning the item at index 0 within the heap array. A heap provides us with the\n",
            "of EnqueueFront. The following list identiﬁes operations that are commonly\n",
            "linked list. Using an array as the backing data structure would require the pro-\n",
            "a list, into two similar sized lists (left, and right) and sorting each list and then\n",
            "Note: the function MergeOrdered simply takes two ordered lists and makes\n",
            "algorithm to work out the index of an array of queues to enqueue the item into.\n",
            "queues[GetQueueIndex(item, indexOfKey)].Enqueue(item)\n",
            "Unless stated otherwise the alias n denotes a standard 32 bit integer.\n",
            "list\n",
            "1) algorithm SequentialSearch(list, item)\n",
            "Post: return index of item if found, otherwise −1\n",
            "index ←0\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index < list.Count and list[index] = item\n",
            "return index\n",
            "notice how the searched items have had their search probability increased after\n",
            "1) algorithm ProbabilitySearch(list, item)\n",
            "index ←0\n",
            "while index < list.Count and list[index] ̸= item\n",
            "if index ≥list.Count or list[index] ̸= item\n",
            "if index > 0\n",
            "Swap(list[index], list[index −1])\n",
            "// march down to the index before the beginning of the word\n",
            "1. index\n",
            "Of the previously listed index keeps track of the current index we are at in\n",
            "white space we are in a word, the opposite is true if at the present index we are\n",
            "In Figure 11.2 we present a string indexed as an array. Typically the pattern\n",
            "index ←0\n",
            "if index = value.Length and value[index] = whitespace\n",
            "while index < value.Length\n",
            "between any characters thus returning a non-negative index that represents the\n",
            "index\n",
            "index\n",
            "index\n",
            "Post: index representing match location if occured, −1 otherwise\n",
            "return index\n",
            "• The top-of-stack index is incremented by the total amount of memory\n",
            "1. The top-of-stack index is decremented by the total amount of memory\n",
            "3. The top-of-stack index is decremented by the total amount of memory\n",
            "The following list identiﬁes testing frameworks which are popular:\n",
            "Don’t worry if you think that the list is very sparse, there are far more on\n",
            "it would be somewhat of an injustice to not list, and describe the mantra that\n"
        ],
        "label": 0
    },
    "value delete algorithm remove": {
        "abstracts": [
            "algorithms.\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Remove(value)\n",
            "1) algorithm Remove(value)\n",
            "Algorithms\n",
            "value\n",
            "value\n"
        ],
        "label": 0
    }
}